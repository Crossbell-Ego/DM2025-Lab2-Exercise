{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:\n",
    "\n",
    "Student ID: NTUT_113568519\n",
    "\n",
    "GitHub ID: Crossbell-Ego\n",
    "\n",
    "Kaggle name: NTUT_113568519\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](.\\pics\\pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)\n",
    "\n",
    "本次實驗的作業分為**三個階段/部分**。前兩個階段指的是[DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git)中的「主筆記本」內的練習。第三階段指的是我們將要為所有資料探勘專業的學生舉辦的「內部Kaggle競賽」。這兩項作業加起來佔總成績的100分。此外，完成實驗中的「額外練習」（額外加15分）和Kaggle競賽報告（額外加5分）還能獲得一些「加分」。\n",
    "\n",
    "**實驗 2 的環境建議：**\n",
    "\n",
    "- **第一階段練習：** 需要 GPU 來訓練該部分中解釋的模型。如果您的筆記型電腦沒有 GPU，建議在 Colab 或 Kaggle 上運行以獲得更快的體驗。雖然也可以使用 CPU 完成，但速度會較慢。\n",
    "\n",
    "- **第二階段練習：** 我們使用 Gemini 的 API，因此所有練習都可以只使用 CPU 運行，不會有問題。\n",
    "\n",
    "- **第三階段練習：** 參加比賽時，您可能需要 GPU 來訓練模型。因此，如果您沒有配備獨立 GPU 的筆記型電腦，建議使用 Colab 或 Kaggle。\n",
    "\n",
    "- **可選的 Ollama Notebook（不計分）：** 您需要 GPU、至少 4GB 顯存和 16GB 記憶體才能運行本地開源 LLM 模型。\n",
    "\n",
    "## **第一階段（30 分）：**\n",
    "\n",
    "1. __主要練習（25 分）：__ 完成 [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb) 中「1. UMAP」章節的**課後練習**。共 8 道練習。請在截止日期（11 月 3 日，星期一，晚上 11:59）之前提交程式碼並將程式碼庫連結提交至 NTU Cool。\n",
    "\n",
    "2. **程式碼註解（5 分）：** **整理筆記本中的程式碼。 **\n",
    "\n",
    "## **第二階段（30 分）：**\n",
    "\n",
    "1. **主要練習（25 分）：** 完成 [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.i 章節後的大型語言模式總共需要完成 5 道練習，分別來自 2.1、2.2、2.4 和 2.6 章節。請在截止日期（11 月 24 日，星期一，晚上 11:59）之前提交程式碼並將程式碼庫連結上傳至 NTU Cool。\n",
    "\n",
    "2. **程式碼註解（5 分）：** **整理筆記本中的程式碼。 **\n",
    "\n",
    "3. **`附加問題（15 分）：`** 完成 [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bon. Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) 中的附加練習，其中主筆記本第 2.3 節和第 2.5 節中的 2 道計入附加題。總計：`7 道練習`。請提交您的程式碼並將程式碼庫連結提交至 NTU Cool **`截止日期前（11 月 24 日，星期一，晚上 11:59）`**\n",
    "\n",
    "## **第三階段（40 分）：**\n",
    "\n",
    "1. **Kaggle 競賽參與（30 分）：** 參與課堂上關於 Twitter 情緒識別的 **Kaggle 競賽**，點擊此連結：**[資料探勘課程 Kaggle 競賽](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)。得分將根據您在私有排行榜中的排名進行評定：\n",
    "\n",
    "- **後 40%**：獲得此競賽參與部分 30 分中的 20 分。\n",
    "\n",
    "- **前 41% - 100%**：獲得 (0.6N + 1 - x) / (0.6N) * 10 + 20 分，其中 N 為參賽總人數，x 為你的排名。 （例如，如果有 100 名參賽者，你的排名為第 3 名，則你的得分為 (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67%（滿分 30%）。）\n",
    "\n",
    "請在截止日期（11 月 24 日，星期一，晚上 11:59）之前提交你的最終成績。比賽結束後，請務必截取你的排名截圖，並將其儲存為本倉庫 `pics` 資料夾下的 `pic_ranking.png` 文件，然後重新執行「學生資訊」儲存格。\n",
    "\n",
    "2. **競賽報告（10 分）** 請在本 Jupyter Notebook 中以 Markdown 格式填寫報告部分，我們已在下方提供模板。您需要描述您為競賽開發模型的工作。報告應包含一個簡要描述以下要素的部分：\n",
    "\n",
    "* 您的預處理步驟。\n",
    "\n",
    "* 特徵工程步驟。\n",
    "\n",
    "* 模型說明。\n",
    "\n",
    "* **附加題（5 分）：**\n",
    "\n",
    "* 您需要更詳細地描述先前的步驟。\n",
    "\n",
    "* 提及您嘗試過的不同方法。\n",
    "\n",
    "* 提及您所獲得的洞見。\n",
    "\n",
    "[Markdown 指南 - 基本語法](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**第三階段注意事項：**\n",
    "\n",
    "* **競賽使用的程式碼應位於此 Jupyter Notebook 檔案「DM2025-Lab2-Homework.ipynb」中。 **\n",
    "\n",
    "* **將比賽使用的代碼推送到您的代碼倉庫**。\n",
    "\n",
    "* **程式碼應清楚區分報告、預處理和特徵工程等相同部分。 **\n",
    "工程和模型解釋。請簡要註釋您的程式碼以便於理解，我們在本筆記本末尾提供了一個範本。 **\n",
    "\n",
    "* 在本筆記本中展示 Kaggle 排名截圖以及程式碼，將確保您的參賽資格和報告的有效性，從而獲得相應的分數。\n",
    "\n",
    "比賽結束後，您還有兩天時間提交 `DM2025-Lab2-Homework.ipynb` 文件，其中包含 Markdown 格式的報告和程式碼。 **「務必在截止日期（11 月 26 日，星期三，晚上 11:59）之前完成所有工作，以獲得 100% 的可用分數。」**\n",
    "\n",
    "將您的文件上傳到您的程式碼倉庫，然後將連結提交到對應的 NTU Cool 作業中。\n",
    "\n",
    "## **截止日期：**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---\n",
    "\n",
    "接下來你會看到一個範本報告，其中包含一些簡單的 Markdown 語法說明，你可以用它來組織你的內容。\n",
    "\n",
    "使用後，你可以刪除這些語法建議。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **專案報告**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 模型開發（10 分）\n",
    "\n",
    "本專案採用了BERT 模型 Fine-tuning與XGBoost相結合的策略。流程包含資料清洗、任務適應性預訓練（TAPT）、特徵提取以及混合模型投票。\n",
    "\n",
    "### 1.1 預處理步驟\n",
    "\n",
    "資料預處理旨在提升資料品質並減少雜訊，主要執行了以下四個關鍵步驟：\n",
    "\n",
    "* **資料整合與格式化：**\n",
    "    * 將原始 `JSON` 格式的貼文內容解析為 DataFrame，並與 `data_identification.csv` 及 `emotion.csv` 進行合併，區分訓練集與測試集。\n",
    "    * **填補缺失值：** 將空值填補為空字串，並移除無標籤的訓練資料。\n",
    "\n",
    "* **去重複處理：**\n",
    "    * 針對 `text` 欄位執行去重，保留第一筆出現的資料。這能防止模型記憶重複樣本，確保評估的公正性。\n",
    "\n",
    "* **異常值偵測與移除 ：**\n",
    "    * 利用 **Z-Score** 統計方法檢測文本長度異常。\n",
    "    * 設定閾值為 `3`（即保留標準差在 $\\pm 3$ 以內的資料），移除極端過長或過短的貼文，避免離群值影響模型收斂。\n",
    "\n",
    "* **標籤編碼 ：**\n",
    "    * 將六種情緒標籤（如 *joy*, *anger* 等）映射為整數 ID（0-5），以符合模型輸入需求。\n",
    "\n",
    "### 1.2 特徵工程步驟\n",
    "\n",
    "針對不同的模型架構，我們採用了兩種截然不同的特徵工程策略：\n",
    "\n",
    "* **針對DistilBERT模型 ：**\n",
    "    * **Tokenizer：** 使用 `DistilBertTokenizerFast` 進行斷詞。\n",
    "    * **截斷與填充：** 設定最大長度為 128 tokens，統一輸入維度。\n",
    "    * **任務適應性特徵學習 (TAPT)：** 不直接使用預訓練權重，而是先將所有文本（訓練集 + 測試集）視為無標籤語料，進行 **Masked Language Modeling (MLM)** 訓練。這讓模型在提取特徵前，先學習該特定資料集的「行話」與語法結構。\n",
    "\n",
    "* **針對XGBoost模型：**\n",
    "    * **TF-IDF 向量化：** 計算單詞與雙詞（Unigram + Bigram）的 TF-IDF 值，過濾掉停用詞（Stop words）。\n",
    "    * **特徵選擇 (Feature Selection)：** 評估每個詞彙與情緒標籤的相關性，選取最顯著的前 $K$ 個特徵（如 Top 4000），有效降低維度並去除無效雜訊。\n",
    "\n",
    "### 1.3 模型說明\n",
    "\n",
    "本系統採用 **集成學習 (Ensemble Learning)** 架構，結合了經 TAPT 增強的 TAPT-DistilBERT 模型與XGBoost：\n",
    "\n",
    "* **模型 A：TAPT-DistilBERT (主要模型)**\n",
    "    * **架構：** 基於 `distilbert-base-uncased`。\n",
    "    * **第一階段訓練 (TAPT)：** 在無標籤的領域文本上進行自監督學習 (Self-supervised Learning)，優化模型的語言理解能力。\n",
    "    * **第二階段訓練 (Fine-tuning)：** 接上分類層，在標註數據上進行監督式學習。此模型擅長捕捉上下文語境與複雜語意。\n",
    "\n",
    "* **模型 B：XGBoost (輔助模型)**\n",
    "    * **輸入：** 經過篩選的 TF-IDF 特徵向量。\n",
    "    * **設定：** 使用 `multi:softmax` 目標函數，設定樹的深度 (`max_depth=6`) 與 樹的數量 (`n_estimators=200`)。\n",
    "    * **優勢：** 對於特定關鍵字（Keywords）特徵具有極強的敏感度，能彌補深度學習模型偶爾忽略顯著關鍵字的問題。\n",
    "\n",
    "* **整合策略 ：**\n",
    "    * 採用 **優先級投票機制**。比較兩模型的預測結果，若一致則直接輸出；若不一致，則優先採用泛化能力較強的 **TAPT-DistilBERT** 預測結果，以此在穩健性與準確性之間取得平衡。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 附加部分（5 分可選）\n",
    "\n",
    "### 2.1 提及您嘗試過的不同方法\n",
    "\n",
    "(以下說的分數是Kaggle pulic的分數)\n",
    "\n",
    "我嘗試了很多方式從一開始的SVM到BERT，然後將BERT與SVM聯合投票預測，第一次重大的分數提升從(0.5到0.67)，是使用了BERT，然後再使用BERT與SVM聯合投票預測後分數達到了0.68，在0.68致這階段停止了很久嘗試過很多方法 ，例如 : \n",
    "\n",
    "  * 使用權種平衡數量較少的情緒（fear、disgust），結果更慘，發現將數量少情緒提升時，結果減少較多數量的情緒預測（joy、anger）\n",
    "  * 把SVM改成XGBOOT，結果發現都沒有差別都是0.68分\n",
    "  * 增加BERT的epoch從5增加到50與調整學習率，結果分數更慘\n",
    "  * 自動化搜尋最佳的閥值與特徵數量，結果都發現F1分數都差不多\n",
    "  * 然後，使用了TAPT先移除LABEL，訓練一次BERT，然後在微調BERT，分數終於提升到0.6810\n",
    "  * 在階段剛好老師上課講到SNN，就使用SNN先分成5群(調整參數都分不出6群)，結果也是更低分\n",
    "  * 最後模型改使用RoBERTa，還是更低分\n",
    "\n",
    "### 2.2 提及您的見解已獲得\n",
    "\n",
    "我的洞察 : \n",
    "\n",
    "  * BERT 與傳統模型的落差，說明語意表徵對情緒任務的重要性。​\n",
    "  * TAPT 雖然只有 0.01 左右提升，顯示將預訓練模型適配到特定 domain（社群情緒貼文）仍能帶來可量測的改善。​\n",
    "  * 別不平衡不是簡單 reweight 就能解決，反而可能損害高頻情緒的預測品質。​\n",
    "  * 度 fine-tuning、大 epoch 會讓預訓練優勢流失，適當的正則化與早停較關鍵。​\n",
    "  * TAPT 顯示 domain adaptation 在情緒貼文任務上有價值，即使提升有限，也具有實務意義。​\n",
    "  * SNN聚類與換 RoBERTa ，表示「模型結構越複雜不等於分數越高」，資料特性、標籤品質、訓練策略才是關鍵瓶頸。\n",
    "\n",
    "---\n",
    "# **Project Report**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Model Development (10 points)\n",
    "\n",
    "This project adopts a strategy combining BERT model Fine-tuning and XGBoost. The process includes data cleaning, Task-Adaptive Pre-training (TAPT), feature extraction, and hybrid model voting.\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "Data preprocessing aims to improve data quality and reduce noise, primarily executing the following four key steps:\n",
    "\n",
    "* **Data Integration and Formatting:**\n",
    "    * Parse the raw `JSON` format post content into a DataFrame, merge it with `data_identification.csv` and `emotion.csv`, and distinguish between training and testing sets.\n",
    "    * **Fill Missing Values:** Fill null values with empty strings and remove unlabeled training data.\n",
    "\n",
    "* **De-duplication Processing:**\n",
    "    * Execute deduplication on the `text` field, keeping the first occurrence. This prevents the model from memorizing duplicate samples and ensures the fairness of the evaluation.\n",
    "\n",
    "* **Outlier Detection and Removal:**\n",
    "    * Utilize the **Z-Score** statistical method to detect text length anomalies.\n",
    "    * Set the threshold to `3` (i.e., retain data within $\\pm 3$ standard deviations), removing extremely long or short posts to avoid outliers affecting model convergence.\n",
    "\n",
    "* **Label Encoding:**\n",
    "    * Map the six emotion labels (such as *joy*, *anger*, etc.) to integer IDs (0-5) to meet model input requirements.\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "Targeting different model architectures, we adopted two distinct feature engineering strategies:\n",
    "\n",
    "* **Targeting the DistilBERT model:**\n",
    "    * **Tokenizer:** Use `DistilBertTokenizerFast` for tokenization.\n",
    "    * **Truncation and Padding:** Set the maximum length to 128 tokens to unify input dimensions.\n",
    "    * **Task-Adaptive Pre-training (TAPT):** Instead of using pre-trained weights directly, treat all text (training set + testing set) as unlabeled corpus first and perform **Masked Language Modeling (MLM)** training. This allows the model to learn the \"jargon\" and grammatical structure of this specific dataset before extracting features.\n",
    "\n",
    "* **Targeting the XGBoost model:**\n",
    "    * **TF-IDF Vectorization:** Calculate TF-IDF values for Unigrams and Bigrams, filtering out Stop words.\n",
    "    * **Feature Selection:** Evaluate the correlation between each vocabulary word and emotion labels, selecting the most significant top $K$ features (e.g., Top 4000) to effectively reduce dimensionality and remove invalid noise.\n",
    "\n",
    "### 1.3 Model Description\n",
    "\n",
    "The system adopts an **Ensemble Learning** architecture, combining the TAPT-enhanced TAPT-DistilBERT model with XGBoost:\n",
    "\n",
    "* **Model A: TAPT-DistilBERT (Main Model)**\n",
    "    * **Architecture:** Based on `distilbert-base-uncased`.\n",
    "    * **First Stage Training (TAPT):** Perform Self-supervised Learning on unlabeled domain text to optimize the model's language understanding capability.\n",
    "    * **Second Stage Training (Fine-tuning):** Connect a classification layer and perform supervised learning on labeled data. This model excels at capturing context and complex semantics.\n",
    "\n",
    "* **Model B: XGBoost (Auxiliary Model)**\n",
    "    * **Input:** Filtered TF-IDF feature vectors.\n",
    "    * **Settings:** Use the `multi:softmax` objective function, setting tree depth (`max_depth=6`) and number of trees (`n_estimators=200`).\n",
    "    * **Advantage:** Has strong sensitivity to specific keyword features, compensating for the issue where deep learning models occasionally ignore significant keywords.\n",
    "\n",
    "* **Integration Strategy:**\n",
    "    * Adopt a **Priority Voting Mechanism**. Compare the predictions of both models; if they match, output directly; if inconsistent, prioritize the prediction of the **TAPT-DistilBERT** (which has stronger generalization capabilities) to achieve a balance between robustness and accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Additional Section (5 points optional)\n",
    "\n",
    "### 2.1 Mentioning Different Approaches Tried\n",
    "\n",
    "(The scores mentioned below are Kaggle public scores)\n",
    "\n",
    "I tried many methods, starting from SVM to BERT, and then a joint voting prediction using BERT and SVM. The first major score improvement (from 0.5 to 0.67) was using BERT, and then after using the BERT and SVM joint voting prediction, the score reached 0.68. I stopped at the 0.68 stage for a long time and tried many methods, such as:\n",
    "\n",
    "* Using weights to balance emotions with smaller quantities (fear, disgust) resulted in worse performance. I found that improving the recall of low-quantity emotions significantly reduced the prediction of higher-quantity emotions (joy, anger).\n",
    "* Changing SVM to XGBoost revealed no difference; both were 0.68 points.\n",
    "* Increasing BERT epochs from 5 to 50 and adjusting the learning rate resulted in even worse scores.\n",
    "* Automated search for the optimal threshold and feature quantity revealed that the F1 scores were all about the same.\n",
    "* Then, I used TAPT by first removing the LABELs to train BERT once, and then fine-tuning BERT. The score finally improved to 0.6810.\n",
    "* At this stage, the teacher happened to mention SNN in class, so I used SNN to cluster into 5 groups (couldn't separate into 6 groups despite parameter adjustments), but the result was also a lower score.\n",
    "* Finally, the model was changed to RoBERTa, but the score was still lower.\n",
    "\n",
    "### 2.2 Mentioning Insights Gained\n",
    "\n",
    "My insights:\n",
    "\n",
    "* The gap between BERT and traditional models demonstrates the importance of semantic representation for emotion tasks.\n",
    "* Although TAPT only improved by about 0.01, it shows that adapting pre-trained models to a specific domain (social media emotion posts) can still bring measurable improvements.\n",
    "* Class imbalance cannot be solved by simple reweighting; instead, it might damage the prediction quality of high-frequency emotions.\n",
    "* Excessive fine-tuning or large epochs cause the loss of pre-training advantages; appropriate regularization and early stopping are more critical.\n",
    "* TAPT shows that domain adaptation has value in emotion post tasks; even if the improvement is limited, it has practical significance.\n",
    "* SNN clustering and switching to RoBERTa indicate that \"more complex model structures do not equal higher scores\"; data characteristics, label quality, and training strategies are the critical bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---\n",
    "接下來是比賽的程式碼編寫部分。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "**我是使用我的電腦GPU訓練，完整的程式碼與CSV檔，我放在Kaggle 資料夾內**\n",
    "\n",
    "**I trained it using my computer's GPU. The complete code, CSV file are in Kaggle folder.**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from xgboost import XGBClassifier\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast, \n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertForMaskedLM,  \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "def print_section(title):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "def print_df_info(name, df):\n",
    "    print(f\"[Info] {name} 概況:\")\n",
    "    print(f\" Shape: {df.shape}\")\n",
    "    print(f\" Columns: {list(df.columns)}\")\n",
    "    if 'emotion' in df.columns:\n",
    "        print(f\" Emotion 分佈:\\n{df['emotion'].value_counts().head().to_string(header=False)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 初始設定 (Initial Setup)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 1-0: 環境設定\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"使用裝置: {device}\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 資料讀取 (Data Loading)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 1-1: 資料讀取\")\n",
    "    try:\n",
    "        # 讀取 JSON 檔案 (Read JSON file)\n",
    "        with open(\"final_posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data_json = json.load(f)\n",
    "        \n",
    "        extracted_data = []\n",
    "        for entry in data_json:\n",
    "            post = entry.get(\"root\", {}).get(\"_source\", {}).get(\"post\", {})\n",
    "            extracted_data.append({\n",
    "                \"id\": post.get(\"post_id\"),\n",
    "                \"text\": post.get(\"text\")\n",
    "            })\n",
    "        df_text_raw = pd.DataFrame(extracted_data)\n",
    "        \n",
    "        df_emotion = pd.read_csv(\"emotion.csv\")\n",
    "        df_id = pd.read_csv(\"data_identification.csv\")\n",
    "        \n",
    "        print(f\"原始資料讀取成功: (Raw data loaded successfully:)\")\n",
    "        print(f\"      - JSON Posts: {len(df_text_raw)} 筆\")\n",
    "        print(f\"      - Emotion Labels: {len(df_emotion)} 筆\")\n",
    "        print(f\"      - ID Map: {len(df_id)} 筆\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"錯誤: 找不到檔案 {e.filename}。 (Error: File not found)\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 合併資料 (Merge data)\n",
    "    df_merged = df_id.merge(df_text_raw, on=\"id\", how=\"left\")\n",
    "    \n",
    "    train_df_raw = df_merged[df_merged[\"split\"] == \"train\"].copy()\n",
    "    test_df_raw = df_merged[df_merged[\"split\"] == \"test\"].copy()\n",
    "    \n",
    "    # 合併情緒標籤 (Merge emotion labels)\n",
    "    train_df = train_df_raw.merge(df_emotion, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 資料前處理 (Data Preprocessing)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 1-2: 資料清潔與前處理\")\n",
    "    \n",
    "    # 基礎清潔 (Basic cleaning)\n",
    "    print(\"執行基礎清潔...\")\n",
    "    train_df[\"text\"] = train_df[\"text\"].fillna(\"\").astype(str).str.strip()\n",
    "    test_df_raw[\"text\"] = test_df_raw[\"text\"].fillna(\"\").astype(str).str.strip() # Test set 也要清 (Also clean test set)\n",
    "    train_df.dropna(subset=[\"emotion\"], inplace=True)\n",
    "    \n",
    "    initial_count = len(train_df)\n",
    "    \n",
    "    # 去除重複資料 (Remove duplicate data)\n",
    "    train_df.drop_duplicates(subset=[\"text\"], keep=\"first\", inplace=True)\n",
    "    print(f\"去除重複貼文: 移除 {initial_count - len(train_df)} 筆\")\n",
    "\n",
    "    # 異常值偵測 (Outlier detection)\n",
    "    train_df[\"text_len\"] = train_df[\"text\"].apply(len)\n",
    "    z_scores = stats.zscore(train_df[\"text_len\"])\n",
    "    train_df = train_df[np.abs(z_scores) < 3] # 保留 Z-Score < 3 (Keep Z-Score < 3)\n",
    "    \n",
    "    print(f\"異常值移除後，訓練集剩餘: {len(train_df)} 筆\")\n",
    "    print_df_info(\"最終訓練集\", train_df)\n",
    "\n",
    "    # Label Mapping\n",
    "    emotions = sorted(train_df[\"emotion\"].unique())\n",
    "    label2id = {label: i for i, label in enumerate(emotions)}\n",
    "    id2label = {i: label for i, label in enumerate(emotions)}\n",
    "    train_df[\"label\"] = train_df[\"emotion\"].map(label2id)\n",
    "    \n",
    "    print(f\"Label Map: {label2id}\")\n",
    "\n",
    "    # 分割驗證集 (Split validation set)\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_df, test_size=0.2, random_state=SEED, stratify=train_df[\"label\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "    # TAPT: 任務適應性預訓練 (Task-Adaptive Pre-training)\n",
    "# ---------------------------------------------------------\n",
    "    print_section(\"階段 2: TAPT (Task-Adaptive Pre-training)\")\n",
    "\n",
    "    # 準備 TAPT 語料 (Train + Test 的所有文本) (Prepare TAPT corpus)\n",
    "    tapt_texts = pd.concat([train_df[\"text\"], test_df_raw[\"text\"]]).unique()\n",
    "    tapt_dataset = Dataset.from_dict({\"text\": tapt_texts})\n",
    "    print(f\"TAPT 語料庫大小: {len(tapt_texts)} 句獨特文本 (TAPT corpus size: unique texts)\")\n",
    "\n",
    "    # 初始化 Tokenizer (Initialize Tokenizer)\n",
    "    model_checkpoint = \"distilbert-base-uncased\"\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    print(\"Tokenizing TAPT corpus...\")\n",
    "    tokenized_tapt = tapt_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    # 設定 MLM Data Collator  (Set MLM Data Collator)\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "\n",
    "    # 初始化 MLM 模型 (Initialize MLM model)\n",
    "    model_tapt = DistilBertForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "    # TAPT 訓練參數 (TAPT training parameters)\n",
    "    tapt_args = TrainingArguments(\n",
    "        output_dir=\"./tapt_model\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=5,          \n",
    "        per_device_train_batch_size=16,\n",
    "        save_strategy=\"no\",          \n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        fp16=torch.cuda.is_available(), \n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer_tapt = Trainer(\n",
    "        model=model_tapt,\n",
    "        args=tapt_args,\n",
    "        train_dataset=tokenized_tapt,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    print(\"開始 TAPT 訓練 (MLM)... (Start TAPT training)\")\n",
    "    trainer_tapt.train()\n",
    "    \n",
    "    # 評估 Perplexity  (Evaluate Perplexity )\n",
    "    eval_results = trainer_tapt.evaluate()\n",
    "    perplexity = math.exp(eval_results['eval_loss'])\n",
    "    print(f\"TAPT 完成! Perplexity: {perplexity:.2f} (TAPT completed!)\")\n",
    "\n",
    "    # 儲存 TAPT 後的模型 (Save TAPT-enhanced model)\n",
    "    tapt_model_path = \"./tapt_finetuned_distilbert\"\n",
    "    trainer_tapt.save_model(tapt_model_path)\n",
    "    print(f\"TAPT 模型已儲存至: {tapt_model_path} (Model saved to:)\")\n",
    "\n",
    "    # 清理記憶體 (Clear memory)\n",
    "    del model_tapt, trainer_tapt\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 特徵工程 (Feature Engineering)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 3: 傳統特徵工程 (For XGBoost)\")\n",
    "    \n",
    "    print(\"建立 TF-IDF 特徵... (Build TF-IDF features)\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True, stop_words=\"english\", ngram_range=(1, 2), \n",
    "        max_df=0.9, min_df=2, max_features=8000\n",
    "    )\n",
    "    \n",
    "    \n",
    "    X_train_tfidf = vectorizer.fit_transform(train_split[\"text\"])\n",
    "    X_val_tfidf = vectorizer.transform(val_split[\"text\"])\n",
    "    X_test_tfidf = vectorizer.transform(test_df_raw[\"text\"])\n",
    "    \n",
    "    print(\"特徵選擇 (Chi2)... (Feature selection)\")\n",
    "    k_best = min(4000, X_train_tfidf.shape[1])\n",
    "    selector = SelectKBest(chi2, k=k_best)\n",
    "    X_train_sel = selector.fit_transform(X_train_tfidf, train_split[\"label\"])\n",
    "    X_val_sel = selector.transform(X_val_tfidf)\n",
    "    X_test_sel = selector.transform(X_test_tfidf)\n",
    "    \n",
    "    print(f\"XGBoost 輸入特徵維度: {X_train_sel.shape} (XGBoost input feature dimensions:)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ---------------------------------------------------------\n",
    "    # 模型 A: TAPT 強化的 BERT (主模型) (Main Model - TAPT-enhanced BERT)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 4: 監督式微調 (Supervised Fine-tuning)\")\n",
    "\n",
    "    # 準備 Dataset (Prepare Dataset)\n",
    "    hf_train = Dataset.from_pandas(train_split[[\"text\", \"label\"]])\n",
    "    hf_val = Dataset.from_pandas(val_split[[\"text\", \"label\"]])\n",
    "    hf_test = Dataset.from_pandas(test_df_raw[[\"text\"]])\n",
    "\n",
    "    tokenized_train = hf_train.map(tokenize_function, batched=True)\n",
    "    tokenized_val = hf_val.map(tokenize_function, batched=True)\n",
    "    tokenized_test = hf_test.map(tokenize_function, batched=True)\n",
    "\n",
    "    # 載入 TAPT 後的模型  (Load TAPT model )\n",
    "    print(f\"載入 TAPT 預訓練權重: {tapt_model_path} (Load TAPT weights:)\")\n",
    "    model_cls = DistilBertForSequenceClassification.from_pretrained(\n",
    "        tapt_model_path, \n",
    "        num_labels=len(emotions)\n",
    "    )\n",
    "\n",
    "    # 設定分類訓練參數 (Set classification training parameters)\n",
    "    cls_args = TrainingArguments(\n",
    "        output_dir=\"./cls_results\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return {\"f1\": f1_score(labels, predictions, average=\"macro\")}\n",
    "\n",
    "    trainer_cls = Trainer(\n",
    "        model=model_cls,\n",
    "        args=cls_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    print(\"開始分類模型微調... (Start classification model fine-tuning)\")\n",
    "    trainer_cls.train()\n",
    "    \n",
    "    # 預測 (Prediction)\n",
    "    print(\"取得 BERT 預測結果... (Get BERT prediction results)\")\n",
    "    pred_output = trainer_cls.predict(tokenized_test)\n",
    "    y_pred_bert = np.argmax(pred_output.predictions, axis=1)\n",
    "    \n",
    "    val_output = trainer_cls.predict(tokenized_val)\n",
    "    y_val_bert = np.argmax(val_output.predictions, axis=1)\n",
    "    \n",
    "    print(f\"BERT (TAPT-Enhanced) Val F1: {f1_score(val_split['label'], y_val_bert, average='macro'):.4f}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 模型 B: XGBoost (輔助模型) (Auxiliary Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 5: 訓練 XGBoost (特徵輔助) (Train XGBoost)\")\n",
    "    \n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(emotions),\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "    \n",
    "    xgb_clf.fit(X_train_sel, train_split[\"label\"], eval_set=[(X_val_sel, val_split[\"label\"])], verbose=False)\n",
    "    \n",
    "    y_pred_xgb = xgb_clf.predict(X_test_sel)\n",
    "    y_val_xgb = xgb_clf.predict(X_val_sel)\n",
    "    print(f\"      XGBoost Val F1: {f1_score(val_split['label'], y_val_xgb, average='macro'):.4f}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 模式整合 (Ensemble) (Model Ensemble)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 6: 模式整合 (Ensemble)\")\n",
    "    \n",
    "    y_ensemble = []\n",
    "    conflict_count = 0\n",
    "    \n",
    "    for b, x in zip(y_pred_bert, y_pred_xgb):\n",
    "        if b == x:\n",
    "            y_ensemble.append(b)\n",
    "        else:\n",
    "            y_ensemble.append(b) \n",
    "            conflict_count += 1\n",
    "            \n",
    "    print(f\"整合完成。BERT 與 XGBoost 不一致筆數: {conflict_count}/{len(y_ensemble)} (Ensemble complete. Mismatches:)\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 評估與輸出 (Evaluation and Output)\n",
    "    # ---------------------------------------------------------\n",
    "    print_section(\"階段 7: 評估與生成提交檔\")\n",
    "    \n",
    "    # 混淆矩陣 (基於 BERT) (Confusion matrix - based on BERT)\n",
    "    cm = confusion_matrix(val_split[\"label\"], y_val_bert)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=emotions, yticklabels=emotions)\n",
    "    plt.title('Validation Confusion Matrix (TAPT-DistilBERT)')\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Pred')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_tapt.png')\n",
    "    print(\"混淆矩陣已存: confusion_matrix_tapt.png (Confusion matrix saved:)\")\n",
    "    \n",
    "    print(\"\\nTAPT-BERT 詳細報告: (Detailed report:)\")\n",
    "    print(classification_report(val_split[\"label\"], y_val_bert, target_names=emotions))\n",
    "    \n",
    "    # 生成提交檔 (Generate submission file)\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test_df_raw[\"id\"],\n",
    "        \"emotion\": [id2label[i] for i in y_ensemble]\n",
    "    })\n",
    "    \n",
    "    output_filename = \"submission_tapt_xgboost.csv\"\n",
    "    submission.to_csv(output_filename, index=False)\n",
    "    print(f\"提交檔案已建立: {output_filename} (Submission file created:)\")\n",
    "    print(f\"預測分布: (Prediction distribution:)\\n{submission['emotion'].value_counts()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
