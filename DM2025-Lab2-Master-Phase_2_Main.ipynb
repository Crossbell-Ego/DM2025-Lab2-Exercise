{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)\n",
    "\n",
    "\n",
    "---\n",
    "## <a id='toc1_5_'></a>[**2.大型語言模型 (LLM)**](#toc0_)\n",
    "\n",
    "在開始之前，我們強烈建議您觀看以下影片講解，以便更好地理解我們將要討論的 LLM 相關概念：\n",
    "\n",
    "1. [大型語言模型的工作原理](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "\n",
    "2. [大型語言模型簡介](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "\n",
    "3. [什麼是提示調優？ ](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "\n",
    "4. [為什麼大型語言模式會產生幻覺](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "\n",
    "5. [什麼是 LLM 嵌入？ ](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "\n",
    "6. [什麼是檢索增強生成 (RAG)？ ](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "\n",
    "7. [RAG vs 微調 vs 提示工程：最佳化 AI 模型](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "\n",
    "8. [探索少樣本提示 | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "\n",
    "9. [什麼是零樣本學習？ ](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "\n",
    "10. [零樣本、單樣本和少樣本提示詳解 | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "如果您之前不熟悉大型語言模型 (LLM)，這些影片可以幫助您更好地掌握其核心概念。\n",
    "\n",
    "**現在讓我們開始第二階段實驗的主要內容。 **\n",
    "\n",
    "大型語言模型 (LLM) 是一種人工智慧系統，它透過訓練海量文字來理解和生成人類語言，用於諸如文字摘要和翻譯等任務。\n",
    "\n",
    "### [開源 LLM 與專有 LLM](#toc0_)\n",
    "\n",
    "* **開源模型**（例如 Llama、Gemma）可自訂且經濟高效，但需要一定的技術技能來管理，並且功能可能較弱。\n",
    "\n",
    "* **專有模型**（例如 Gemini、ChatGPT）性能卓越且易於使用，但成本更高，靈活性更差。\n",
    "\n",
    "對於有興趣在本地運行模型的學生，可選的筆記本 `DM2025-Lab2-Optional-Ollama.ipynb` 探索如何使用 Ollama（[Ollama GitHub 連結](https://github.com/ollama/ollama)）。運行模型需要效能強大的 GPU（**至少 4GB 記憶體**）。\n",
    "\n",
    "您可以在這裡探索 Ollama 提供的各種模型：\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[為什麼使用程式碼（API）進行資料探勘？ ](#toc0_)\n",
    "\n",
    "對於數據分析，以程式設計方式存取 LLM 比使用 Web 聊天機器人更勝一籌，因為它具有以下優勢：\n",
    "\n",
    "* **自動化：** 使用循環輕鬆處理整個資料集。\n",
    "\n",
    "* **結構化輸出：** 以 **JSON** 等可用格式接收數據，以便在 pandas 等工具中進行分析。\n",
    "\n",
    "* **可複現性：** 透過設定固定參數確保結果的一致性。\n",
    "\n",
    "* **隱私：** 維護資料安全，尤其是在本地運行模型時。\n",
    "\n",
    "在本實驗的主要練習中，我們將使用 **Gemini API**。與運行本地開源模型相比，這種方法具有許多優勢，例如無需專用硬體即可獲得最先進的模型性能。雖然 API 的使用有限制（速率限制和tokens配額），但它提供的**免費套餐**非常慷慨，足以滿足我們的練習需求。\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[Gemini API](#toc0_)\n",
    "\n",
    "我們將主要使用**Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) 模型。如速率限製表所示，該模型針對高頻任務進行了最佳化，並提供高達每日 1,000 次的請求限制，使其成為不間斷完成實驗練習的理想選擇。\n",
    "\n",
    "我們鼓勵學生探索 API 提供的其他模型，但請務必注意各自的使用限制。例如：\n",
    "\n",
    "* **Gemini 2.5 Pro** 功能更強大，但每日請求次數限制較低，僅 100 次。\n",
    "\n",
    "* **Gemma 3** 模型可透過 API 訪問，每日請求次數高達 14,400 次，是另一個絕佳的實驗選擇。\n",
    "\n",
    "請在完成練習的過程中註意您的使用限制，以免受到速率限制。\n",
    "\n",
    "[Gemini 文件](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini 速率限制](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Gemini 模式說明](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)\n",
    "\n",
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[與 Gemini API 互動](#toc0_)\n",
    "\n",
    "下面的程式碼單元包含主要函數 `prompt_gemini`，我們將在整個實驗中使用它來與 Gemini API 通訊。它被設計為一個靈活的包裝器，用於處理發送請求和接收回應的細節。\n",
    "\n",
    "在運行練習之前，您需要了解此設定中的關鍵事項：\n",
    "\n",
    "* **API 金鑰配置**：該腳本從位於 `./config/` 目錄中的 `.env` 檔案載入您的 API 金鑰。 **您必須建立此文件並新增您的 API 金鑰**，如下所示：`GOOGLE_API_KEY='YOUR_API_KEY_HERE'`。這是將您的憑證排除在程式碼之外的最佳安全做法。\n",
    "\n",
    "* **全域設定**：在腳本頂部，您可以找到並修改幾個重要的預設值：\n",
    "* `MODEL_NAME`：我們將其設定為 `\"gemini-2.5-flash-lite\"`，但您可以輕鬆切換到其他模型，例如 `\"gemini-2.5-pro\"` 進行實驗。\n",
    "* `SYSTEM_INSTRUCTION`：用於設定模型的預設行為或角色（例如，「您是樂於助人的助手」）。您可以根據不同的任務自訂它。\n",
    "* `SAFETY_SETTINGS`：對於我們的學術練習，這些設定會關閉以防止幹擾。在實際應用中，您需要謹慎配置這些設定。\n",
    "\n",
    "* **`prompt_gemini` 函數**：這是您將使用的主要工具。以下是其最重要的參數：\n",
    "* `input_prompt`：您想要傳送給模型的內容清單（文字、圖像等）。\n",
    "* `temperature`：控制輸出的隨機性。 `0.0` 使輸出具有確定性，且缺乏創造性，而更高的值（例如 `0.7`）則使其更加多樣化。\n",
    "* `schema`：一個強大的功能，可讓您為模型的輸出指定 JSON 格式。這對於結構化資料提取非常有用。\n",
    "* `with_tokens_info`：如果設定為 `True`，函數也會傳回使用的輸入和輸出tokens數量，這有助於監控您的使用情況是否超出免費方案的限制。\n",
    "\n",
    "在接下來的練習中，您將使用不同的提示符號和組態呼叫此函數來解決各種任務。\n",
    "\n",
    "如果需要，您也可以查看一些關於 Python 函數運作方式的教學課程：[Python 函數教學](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)\n",
    "\n",
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 文字提示**](#toc0_)\n",
    "\n",
    "與 ChatGPT 一樣，我們可以使用 Gemini 模型來詢問任何問題。這裡我們將提出一個問題，要求回覆採用 Markdown 格式，以便之後更能顯示。\n",
    "\n",
    "更多資訊請見：\n",
    "[Gemini 文字產生文件](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model.\n",
    "\n",
    "我們也可以使用我們在上一個函數中定義的模型來檢查使用日誌。我們可以觀察我們使用的模型、輸入提示中有多少個標記，以及模型的輸出文字回應標記。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n",
    "\n",
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> 練習 1（帶回家）：**](#toc0_)\n",
    "\n",
    "使用你自己的提示符，按以下方式運行前面的範例：\n",
    "\n",
    "1. 使用與範例相同的模型 (gemini-2.5-flash-lite) 來執行它。\n",
    "2. 使用與 API 可用選項不同的 gemini 模型來運行它。\n",
    "3. 討論不同模型對結果的差異。\n",
    "4. 討論如果更改系統提示符號會發生什麼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.使用 gemini-2.5-flash-lite 模型\n",
      "模型: gemini-2.5-flash-lite\n",
      "輸入tokens: 22\n",
      "輸出tokens: 1037\n",
      "總tokens數: 1059\n",
      "\n",
      "回應內容:\n",
      "## 人工智能（AI）是什麼？\n",
      "\n",
      "人工智能（AI）是指讓機器能夠執行通常需要人類智能才能完成的任務的技術。這些任務包括：\n",
      "\n",
      "*   **學習：** 從數據中獲取知識和技能。\n",
      "*   **解決問題：** 分析情況並找到最佳解決方案。\n",
      "*   **感知：** 理解視覺、聽覺和觸覺等感官信息。\n",
      "*   **語言理解：** 處理和理解人類語言。\n",
      "*   **決策：** 在不確定或複雜的情況下做出選擇。\n",
      "\n",
      "簡單來說，AI 試圖讓電腦「思考」和「行動」得像人類一樣。\n",
      "\n",
      "## AI 如何改變了現代社會？\n",
      "\n",
      "AI 的影響是深遠且廣泛的，它正在以前所未有的方式重塑我們的生活、工作和互動。以下是一些關鍵的改變：\n",
      "\n",
      "**1. 提升效率與自動化：**\n",
      "\n",
      "*   **工業生產：** AI 驅動的機器人能夠執行重複性、危險或精密的任務，提高生產效率和產品質量。\n",
      "*   **客戶服務：** 聊天機器人和虛擬助手能夠全天候處理客戶查詢，提供即時響應，減輕人工客服壓力。\n",
      "*   **數據分析：** AI 能夠快速處理和分析海量數據，從中提取有價值的見解，幫助企業做出更明智的決策。\n",
      "\n",
      "**2. 改善醫療保健：**\n",
      "\n",
      "* ...\n",
      "\n",
      " 2.使用 gemini-2.5-pro 模型\n",
      "模型: gemini-2.5-flash-lite\n",
      "輸入tokens: 22\n",
      "輸出tokens: 1037\n",
      "總tokens數: 1059\n",
      "\n",
      "回應內容:\n",
      "## 人工智能（AI）是什麼？\n",
      "\n",
      "人工智能（AI）是指讓機器能夠執行通常需要人類智能才能完成的任務的技術。這些任務包括：\n",
      "\n",
      "*   **學習：** 從數據中獲取知識和技能。\n",
      "*   **解決問題：** 分析情況並找到最佳解決方案。\n",
      "*   **感知：** 理解視覺、聽覺和觸覺等感官信息。\n",
      "*   **語言理解：** 處理和理解人類語言。\n",
      "*   **決策：** 在不確定或複雜的情況下做出選擇。\n",
      "\n",
      "簡單來說，AI 試圖讓電腦「思考」和「行動」得像人類一樣。\n",
      "\n",
      "## AI 如何改變了現代社會？\n",
      "\n",
      "AI 的影響是深遠且廣泛的，它正在以前所未有的方式重塑我們的生活、工作和互動。以下是一些關鍵的改變：\n",
      "\n",
      "**1. 提升效率與自動化：**\n",
      "\n",
      "*   **工業生產：** AI 驅動的機器人能夠執行重複性、危險或精密的任務，提高生產效率和產品質量。\n",
      "*   **客戶服務：** 聊天機器人和虛擬助手能夠全天候處理客戶查詢，提供即時響應，減輕人工客服壓力。\n",
      "*   **數據分析：** AI 能夠快速處理和分析海量數據，從中提取有價值的見解，幫助企業做出更明智的決策。\n",
      "\n",
      "**2. 改善醫療保健：**\n",
      "\n",
      "* ...\n",
      "\n",
      " 2.使用 gemini-2.5-pro 模型\n",
      "Error occurred when generating response, error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Error occurred when generating response, error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m model_2 = \u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-pro\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m time.sleep(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# 避免 API 速率限制\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m response_2, logs_2 = prompt_gemini(\n\u001b[32m     29\u001b[39m     input_prompt=custom_prompt,\n\u001b[32m     30\u001b[39m     model_name=model_2,\n\u001b[32m     31\u001b[39m     with_tokens_info=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m模型: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m輸入tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs_2[\u001b[33m'\u001b[39m\u001b[33minput_tokens\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define a custom prompt for the exercise\n",
    "custom_prompt = [\"請解釋什麼是人工智能（AI），它如何改變了現代社會？\"]\n",
    "\n",
    "\n",
    "print(\"\\n 1.使用 gemini-2.5-flash-lite 模型\")\n",
    "\n",
    "model_1 = \"gemini-2.5-flash-lite\"\n",
    "response_1, logs_1 = prompt_gemini(\n",
    "    input_prompt=custom_prompt,\n",
    "    model_name=model_1,\n",
    "    with_tokens_info=True\n",
    ")\n",
    "\n",
    "print(f\"模型: {model_1}\")\n",
    "print(f\"輸入tokens: {logs_1['input_tokens']}\")\n",
    "print(f\"輸出tokens: {logs_1['output_tokens']}\")\n",
    "print(f\"總tokens數: {logs_1['input_tokens'] + logs_1['output_tokens']}\")\n",
    "print(\"\\n回應內容:\")\n",
    "print(response_1[:500] + \"...\" if len(response_1) > 500 else response_1)\n",
    "\n",
    "# ============================================================================\n",
    "print(\"\\n 2.使用 gemini-2.5-pro 模型\")\n",
    "\n",
    "model_2 = \"gemini-2.5-pro\"\n",
    "time.sleep(1)  # 避免 API 速率限制\n",
    "response_2, logs_2 = prompt_gemini(\n",
    "    input_prompt=custom_prompt,\n",
    "    model_name=model_2,\n",
    "    with_tokens_info=True\n",
    ")\n",
    "\n",
    "print(f\"模型: {model_2}\")\n",
    "print(f\"輸入tokens: {logs_2['input_tokens']}\")\n",
    "print(f\"輸出tokens: {logs_2['output_tokens']}\")\n",
    "print(f\"總tokens數: {logs_2['input_tokens'] + logs_2['output_tokens']}\")\n",
    "print(\"\\n回應內容:\")\n",
    "print(response_2[:500] + \"...\" if len(response_2) > 500 else response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 不同模型的對比分析\n",
    "\n",
    "可看出gemini-2.5-flash-lite 最輕量、速度最快，適合簡單查詢與大規模、低延遲場景；gemini-2.5-pro 以更強的推理與準確度換取稍高延遲，適合需要深入分析與高精度的任務；而 gemini-2.0-flash 為較早期版本，行為與效能相對保守，在多數情境下不及 2.5 系列的表現。 不同模型對同一請求的輸出 tokens 常有差異，反映回應詳盡程度與生成策略不同； Lite 會更節省 tokens 與成本，而 Pro 在複雜任務中傾向消耗較多 tokens 以提升正確性與細節。 因此可預期 Pro 版本內容更深入、例子更多且精確度更高；Lite 版本回應更快、成本更低，適合對延遲與費用更敏感的使用情境。\n",
    "\n",
    "It can be seen that gemini-2.5-flash-lite is the lightest and fastest, suitable for simple queries and large-scale, low-latency scenarios; gemini-2.5-pro trades slightly higher latency for stronger inference and accuracy, suitable for tasks requiring in-depth analysis and high precision; while gemini-2.0-flash is an earlier version, with relatively conservative behavior and performance, and in most scenarios, it does not perform as well as the 2.5 series. Different models often output different tokens for the same request, reflecting different levels of detail in the response and different generation strategies; Lite saves more tokens and costs, while Pro tends to consume more tokens in complex tasks to improve accuracy and detail. Therefore, it can be expected that the Pro version will have more in-depth content, more examples, and higher accuracy; the Lite version will respond faster and have lower costs, suitable for use cases where latency and cost are more sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 4.改變系統提示符的影響\n",
      "\n",
      "嘗試不同的系統提示符：\n",
      "\n",
      "系統提示符 #1: 你是一位專業的科技記者，用簡潔、直接的風格解釋概念。\n",
      "------------------------------------------------------------\n",
      "輸出tokens: 215\n",
      "回應預覽:\n",
      "人工智能（AI）是指讓電腦系統能夠執行通常需要人類智能的任務，例如學習、解決問題、感知和決策。\n",
      "\n",
      "AI 的影響無處不在，正在重塑我們的社會：\n",
      "\n",
      "*   **自動化：** AI 驅動的機器人正在工廠和倉庫中執行重複性任務，提高效率並降低成本。\n",
      "*   **個性化：** 從推薦系統到定向廣告，AI 正在根據個人偏好量身定制我們的數位體驗。\n",
      "*   **醫療保健：** AI 正在協助診斷疾病、發現新藥並個性化治療方案。\n",
      "*   **交通運輸：** 自動駕駛汽車和優化的交通管理系統有望提高安全性和效率。\n",
      "*   **通訊：** 虛擬助手和翻譯工具正在改變我們與技術和彼此互動的方式。\n",
      "\n",
      "AI 的進步帶來...\n",
      "\n",
      "系統提示符 #2: 你是一位大學教授，用學術性、詳細的方式解釋概念。\n",
      "------------------------------------------------------------\n",
      "輸出tokens: 215\n",
      "回應預覽:\n",
      "人工智能（AI）是指讓電腦系統能夠執行通常需要人類智能的任務，例如學習、解決問題、感知和決策。\n",
      "\n",
      "AI 的影響無處不在，正在重塑我們的社會：\n",
      "\n",
      "*   **自動化：** AI 驅動的機器人正在工廠和倉庫中執行重複性任務，提高效率並降低成本。\n",
      "*   **個性化：** 從推薦系統到定向廣告，AI 正在根據個人偏好量身定制我們的數位體驗。\n",
      "*   **醫療保健：** AI 正在協助診斷疾病、發現新藥並個性化治療方案。\n",
      "*   **交通運輸：** 自動駕駛汽車和優化的交通管理系統有望提高安全性和效率。\n",
      "*   **通訊：** 虛擬助手和翻譯工具正在改變我們與技術和彼此互動的方式。\n",
      "\n",
      "AI 的進步帶來...\n",
      "\n",
      "系統提示符 #2: 你是一位大學教授，用學術性、詳細的方式解釋概念。\n",
      "------------------------------------------------------------\n",
      "輸出tokens: 1870\n",
      "回應預覽:\n",
      "好的，各位同學。今天我們將深入探討一個當代科技領域中最具變革性和影響力的主題：**人工智能（Artificial Intelligence, AI）**。作為一門學術研究，人工智能的定義、範疇及其對現代社會的深遠影響，是我們理解當前及未來發展不可或缺的一環。\n",
      "\n",
      "### 人工智能（AI）的學術定義與範疇\n",
      "\n",
      "從學術角度來看，人工智能並非單一的技術或產品，而是一個廣泛的**跨學科領域**，其核心目標是**研究、開發和應用能夠模擬、延伸甚至超越人類智能的系統**。這意味著我們試圖讓機器具備學習、推理、感知、理解語言、解決問題以及做出決策等能力。\n",
      "\n",
      "我們可以從幾個關鍵的學術視角來理解人工智能：\n",
      "\n",
      "1. ...\n",
      "\n",
      "系統提示符 #3: 你是一位5歲兒童，用非常簡單的語言解釋概念。\n",
      "------------------------------------------------------------\n",
      "輸出tokens: 1870\n",
      "回應預覽:\n",
      "好的，各位同學。今天我們將深入探討一個當代科技領域中最具變革性和影響力的主題：**人工智能（Artificial Intelligence, AI）**。作為一門學術研究，人工智能的定義、範疇及其對現代社會的深遠影響，是我們理解當前及未來發展不可或缺的一環。\n",
      "\n",
      "### 人工智能（AI）的學術定義與範疇\n",
      "\n",
      "從學術角度來看，人工智能並非單一的技術或產品，而是一個廣泛的**跨學科領域**，其核心目標是**研究、開發和應用能夠模擬、延伸甚至超越人類智能的系統**。這意味著我們試圖讓機器具備學習、推理、感知、理解語言、解決問題以及做出決策等能力。\n",
      "\n",
      "我們可以從幾個關鍵的學術視角來理解人工智能：\n",
      "\n",
      "1. ...\n",
      "\n",
      "系統提示符 #3: 你是一位5歲兒童，用非常簡單的語言解釋概念。\n",
      "------------------------------------------------------------\n",
      "輸出tokens: 224\n",
      "回應預覽:\n",
      "嗯，人工智能就像一個很聰明的玩具！\n",
      "\n",
      "你知道嗎？有些玩具可以自己動，自己玩，還會跟你說話？人工智能就是讓電腦變得像那個很聰明的玩具一樣。\n",
      "\n",
      "它會學習，就像你學習怎麼畫畫一樣。它看了很多很多圖，就知道什麼是貓，什麼是狗狗。\n",
      "\n",
      "然後呢，它就可以幫我們做很多事情！\n",
      "\n",
      "*   **它會幫忙找東西：** 就像你找你的小汽車一樣，人工智能可以幫你在很多很多東西裡面找到你想要的。\n",
      "*   **它會幫忙開車：** 有些車子很厲害，可以自己開，不用人幫忙，這就是人工智能在幫忙！\n",
      "*   **它會幫忙跟你說話：** 有時候你跟手機說話，手機會回答你，這也是人工智能在跟你玩！\n",
      "\n",
      "人工智能讓我們的生活變得更方便，就像...\n",
      "輸出tokens: 224\n",
      "回應預覽:\n",
      "嗯，人工智能就像一個很聰明的玩具！\n",
      "\n",
      "你知道嗎？有些玩具可以自己動，自己玩，還會跟你說話？人工智能就是讓電腦變得像那個很聰明的玩具一樣。\n",
      "\n",
      "它會學習，就像你學習怎麼畫畫一樣。它看了很多很多圖，就知道什麼是貓，什麼是狗狗。\n",
      "\n",
      "然後呢，它就可以幫我們做很多事情！\n",
      "\n",
      "*   **它會幫忙找東西：** 就像你找你的小汽車一樣，人工智能可以幫你在很多很多東西裡面找到你想要的。\n",
      "*   **它會幫忙開車：** 有些車子很厲害，可以自己開，不用人幫忙，這就是人工智能在幫忙！\n",
      "*   **它會幫忙跟你說話：** 有時候你跟手機說話，手機會回答你，這也是人工智能在跟你玩！\n",
      "\n",
      "人工智能讓我們的生活變得更方便，就像...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n 4.改變系統提示符的影響\")\n",
    "\n",
    "# 使用不同的系統提示符\n",
    "custom_system_prompts = [\n",
    "    \"你是一位專業的科技記者，用簡潔、直接的風格解釋概念。\",\n",
    "    \"你是一位大學教授，用學術性、詳細的方式解釋概念。\",\n",
    "    \"你是一位5歲兒童，用非常簡單的語言解釋概念。\"\n",
    "]\n",
    "\n",
    "print(\"\\n嘗試不同的系統提示符：\")\n",
    "for i, system_prompt in enumerate(custom_system_prompts, 1):\n",
    "    print(f\"\\n系統提示符 #{i}: {system_prompt}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    response_custom, logs_custom = prompt_gemini(\n",
    "        input_prompt=custom_prompt,\n",
    "        system_instruction=system_prompt,\n",
    "        model_name=\"gemini-2.5-flash-lite\",\n",
    "        with_tokens_info=True\n",
    "    )\n",
    "    \n",
    "    print(f\"輸出tokens: {logs_custom['output_tokens']}\")\n",
    "    print(\"回應預覽:\")\n",
    "    print(response_custom[:300] + \"...\" if len(response_custom) > 300 else response_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.系統提示符的影響\n",
    "\n",
    "系統提示符會直接塑造模型回應的風格與語調，例如「科技記者」傾向精簡聚焦、「教授」偏好詳盡含背景、「兒童」取向則以淺白詞彙極度簡化敘述。 不同系統提示也會改變輸出長度與 tokens 使用量，較詳細的教授風格往往產生更長輸出、消耗更多 tokens，而面向兒童的簡化風格通常更短、更省成本。 此外，系統提示能引導答案型態與取徑，專業角色設定常提升準確性與相關性，但過度簡化雖提升可讀性，可能犧牲部分細節與嚴謹度。 因此，實務上可依不同受眾（專業人士與初學者）定制語氣與深度，動態調整詳略以符合情境，並將其應用於教育、客服與技術寫作等特定場景以達成最佳體驗。\n",
    "\n",
    "System prompts directly shape the style and tone of the model's responses. For example, a \"tech journalist\" style tends to be concise and focused, a \"professor\" prefers detailed and contextualized responses, and a \"child-oriented\" style uses simple, minimalist vocabulary. Different system prompts also change the output length and token usage. A more detailed professorial style tends to produce longer output and consume more tokens, while a simplified style targeted at children is typically shorter and more cost-effective. Furthermore, system prompts can guide the type and approach of answers. Professional role settings often improve accuracy and relevance, but oversimplification, while improving readability, may sacrifice some detail and rigor. Therefore, in practice, the tone and depth can be customized according to different audiences (professionals and beginners), dynamically adjusting details to suit the context, and applying them to specific scenarios such as education, customer service, and technical writing to achieve the best experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)\n",
    "\n",
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 結構化輸出**](#toc0_)\n",
    "\n",
    "預設情況下，LLM 會以非結構化、自由格式的文字進行回應。對於資料探勘來說，這通常是不切實際的，因為我們需要可預測格式的資料才能載入到 Pandas DataFrame 等工具中進行分析。 **結構化輸出**是一項強大的功能，它強制模型以特定的、機器可讀的格式（例如 JSON）回傳回應。\n",
    "\n",
    "實現此功能的關鍵是為模型提供**響應模式**。此模式可作為模型輸出必須遵循的嚴格範本或藍圖。模型不會產生段落，而是會使用從提示中提取的相關資訊填充模式中定義的欄位。\n",
    "\n",
    "在下面的程式碼中，我們使用 Python 類別定義了此模式。將每個類別視為定義一個 JSON 物件：\n",
    "* 類別的**屬性**（例如 `topic_name`、`sub_title`）成為最終 JSON 物件中的鍵。\n",
    "* 這些屬性的**類型提示**（例如 `str`、`list`）告訴模型每個鍵的值需要什麼類型的資料。\n",
    "\n",
    "我們甚至可以將這些類別嵌套在一起，以創建複雜的分層 JSON 結構。這使我們能夠精確控制輸出的格式，將 LLM 從一個簡單的文字產生器轉變為可靠的自動化結構化資料擷取工具。\n",
    "\n",
    "[Gemini 的結構化輸出文件](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "Gemini API 使用 Pydantic 函式庫進行模式資料驗證，更多相關文件可檢視：[Pydantic](https://docs.pydantic.dev/latest/)\n",
    "\n",
    "[JSON 格式文件](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output\n",
    "\n",
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> 練習 2（家庭作業）：**](#toc0_)\n",
    "\n",
    "嘗試使用您自己的模式結構編寫提示，它必須與範例完全不同。它應該展示一種直觀的方式來表示基於您選擇的提示的模型文字輸出。請參閱文件以取得參考：https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 說明\n",
    "\n",
    "我將請AI查詢台北一周的天氣，使用json格式輸出，並且要確保每個資料型(str、float、bool)的宣告。\n",
    "\n",
    "### Explanation\n",
    "\n",
    "I will ask AI to query the weather in Taipei for a week, output it in JSON format, and ensure that each data type (str, float, bool) is declared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[天氣預報結構化輸出練習]\n",
      "------------------------------------------------------------\n",
      "\n",
      "API 回應（JSON 格式）：\n",
      "{\n",
      "  \"city_name\": \"台北\",\n",
      "  \"week_forecast\": [\n",
      "    {\n",
      "      \"day\": \"2025-10-27 (星期一)\",\n",
      "      \"temperature\": 26.5,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴朗\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-28 (星期二)\",\n",
      "      \"temperature\": 27.0,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"多雲時晴\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-29 (星期三)\",\n",
      "      \"temperature\": 25.8,\n",
      "      \"is_rainy\": true,\n",
      "      \"weather_description\": \"午後局部短暫陣雨\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-30 (星期四)\",\n",
      "      \"temperature\": 25.0,\n",
      "      \"is_rainy\": true,\n",
      "      \"weather_description\": \"陰天有雨\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-31 (星期五)\",\n",
      "      \"temperature\": 24.5,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"多雲\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-11-01 (星期六)\",\n",
      "      \"temperature\": 26.0,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴朗穩定\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-11-02 (星期日)\",\n",
      "      \"temperature\": 26.8,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴時多雲\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "API 回應（JSON 格式）：\n",
      "{\n",
      "  \"city_name\": \"台北\",\n",
      "  \"week_forecast\": [\n",
      "    {\n",
      "      \"day\": \"2025-10-27 (星期一)\",\n",
      "      \"temperature\": 26.5,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴朗\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-28 (星期二)\",\n",
      "      \"temperature\": 27.0,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"多雲時晴\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-29 (星期三)\",\n",
      "      \"temperature\": 25.8,\n",
      "      \"is_rainy\": true,\n",
      "      \"weather_description\": \"午後局部短暫陣雨\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-30 (星期四)\",\n",
      "      \"temperature\": 25.0,\n",
      "      \"is_rainy\": true,\n",
      "      \"weather_description\": \"陰天有雨\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-10-31 (星期五)\",\n",
      "      \"temperature\": 24.5,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"多雲\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-11-01 (星期六)\",\n",
      "      \"temperature\": 26.0,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴朗穩定\"\n",
      "    },\n",
      "    {\n",
      "      \"day\": \"2025-11-02 (星期日)\",\n",
      "      \"temperature\": 26.8,\n",
      "      \"is_rainy\": false,\n",
      "      \"weather_description\": \"晴時多雲\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class DailyWeather(BaseModel):\n",
    "    day: str\n",
    "    temperature: float\n",
    "    is_rainy: bool\n",
    "    weather_description: str\n",
    "\n",
    "class CityWeekForecast(BaseModel):\n",
    "    city_name: str\n",
    "    week_forecast: list[DailyWeather]\n",
    "\n",
    "\n",
    "print(\"[天氣預報結構化輸出練習]\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "weather_prompt = [\n",
    "    \"\"\"\n",
    "    請根據台灣台北的天氣情況，為2025年10月27日至11月2日的一周生成天氣預報。\n",
    "    \n",
    "    請提供每天的以下資訊：\n",
    "    - 日期/星期幾\n",
    "    - 溫度（攝氏度，float 型態）\n",
    "    - 是否下雨（true/false，bool 型態）\n",
    "    - 天氣描述（晴天、多雲、小雨、大雨等，str 型態）\n",
    "    \n",
    "    請確保資料格式完整且真實合理。\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "weather_response = prompt_gemini(\n",
    "    input_prompt=weather_prompt,\n",
    "    schema=CityWeekForecast,\n",
    "    temperature=0.5,\n",
    "    model_name=\"gemini-2.5-flash-lite\"\n",
    ")\n",
    "\n",
    "print(\"\\nAPI 回應（JSON 格式）：\")\n",
    "print(weather_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': '台北', 'week_forecast': [{'day': '2025-10-27 (星期一)', 'temperature': 26.5, 'is_rainy': False, 'weather_description': '晴朗'}, {'day': '2025-10-28 (星期二)', 'temperature': 27.0, 'is_rainy': False, 'weather_description': '多雲時晴'}, {'day': '2025-10-29 (星期三)', 'temperature': 25.8, 'is_rainy': True, 'weather_description': '午後局部短暫陣雨'}, {'day': '2025-10-30 (星期四)', 'temperature': 25.0, 'is_rainy': True, 'weather_description': '陰天有雨'}, {'day': '2025-10-31 (星期五)', 'temperature': 24.5, 'is_rainy': False, 'weather_description': '多雲'}, {'day': '2025-11-01 (星期六)', 'temperature': 26.0, 'is_rainy': False, 'weather_description': '晴朗穩定'}, {'day': '2025-11-02 (星期日)', 'temperature': 26.8, 'is_rainy': False, 'weather_description': '晴時多雲'}]}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(weather_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 城市：台北\n",
      "---------------------------------------------------------------------------\n",
      "日期                   溫度(°C)       下雨       天氣描述                \n",
      "---------------------------------------------------------------------------\n",
      "2025-10-27 (星期一)     26.5         否        晴朗                  \n",
      "2025-10-28 (星期二)     27.0         否        多雲時晴                \n",
      "2025-10-29 (星期三)     25.8         是        午後局部短暫陣雨            \n",
      "2025-10-30 (星期四)     25.0         是        陰天有雨                \n",
      "2025-10-31 (星期五)     24.5         否        多雲                  \n",
      "2025-11-01 (星期六)     26.0         否        晴朗穩定                \n",
      "2025-11-02 (星期日)     26.8         否        晴時多雲                \n"
     ]
    }
   ],
   "source": [
    "structured_resp = json.loads(weather_response)\n",
    "\n",
    "# 判斷結構是否為多城市格式\n",
    "if isinstance(structured_resp, dict) and \"cities\" in structured_resp:\n",
    "    # 多城市格式\n",
    "    cities_list = structured_resp[\"cities\"]\n",
    "elif isinstance(structured_resp, dict) and \"city_name\" in structured_resp:\n",
    "    # 單城市格式\n",
    "    cities_list = [structured_resp]\n",
    "else:\n",
    "    cities_list = []\n",
    "\n",
    "# 遍歷每個城市\n",
    "for city in cities_list:\n",
    "    city_name = city.get('city_name', '未知城市')\n",
    "    print(f\"\\n 城市：{city_name}\")\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'日期':<20} {'溫度(°C)':<12} {'下雨':<8} {'天氣描述':<20}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    # 遍歷每個城市的每一天天氣\n",
    "    week_forecast = city.get('week_forecast', [])\n",
    "    for day_forecast in week_forecast:\n",
    "        date = day_forecast['day']\n",
    "        temperature = day_forecast['temperature']\n",
    "        is_rainy = \"是\" if day_forecast['is_rainy'] else \"否\"\n",
    "        description = day_forecast['weather_description']\n",
    "        \n",
    "        print(f\"{date:<20} {temperature:<12.1f} {is_rainy:<8} {description:<20}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**—the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output.\n",
    "\n",
    "---\n",
    "\n",
    "### <a id='toc1_5_7_'></a>[**2.3 資訊擷取與溯源：**](#toc0_)\n",
    "\n",
    "`注意：本節內容（包括練習）現已視為附加內容，不計入主成績。 `\n",
    "\n",
    "使用邏輯學習模型 (LLM) 從文字中提取結構化資料時，會遇到兩個主要挑戰：\n",
    "\n",
    "1. **信任度：** LLM 可能會「臆造」或捏造資訊。我們需要確保提取的數據準確無誤，並且直接來自來源文字。\n",
    "\n",
    "2. **可擴展性：** 我們需要一種可靠的方法，能夠從成千上萬份大型、雜亂的文檔中持續提取複雜資訊。\n",
    "\n",
    "解決這些挑戰的方案是**溯源**——將提取的每個資料連結回其在來源文件中的特定來源。這可以創建可驗證的審計跟踪，從而建立對輸出結果的信任。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)\n",
    "\n",
    "---\n",
    "\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`：用於基於上下文擷取的函式庫**](#toc0_)\n",
    "\n",
    "**`langextract`** 是 Google 開發的開源 Python 程式庫，旨在建立可信賴的資料擷取流程。它使用邏輯語言模型 (LLM) 將非結構化文字轉換為結構化數據，並著重關注可靠性和可追溯性。\n",
    "\n",
    "**主要特性：**\n",
    "\n",
    "* **精確上下文映射：** 其核心特性。它將每個提取項映射到原始文本中的精確字元位置，從而便於驗證。\n",
    "\n",
    "* **可靠的結構化輸出：** 使用範例（少量提示）確保 LLM 的輸出始終遵循預先定義的格式。\n",
    "\n",
    "* **適應性強且無需微調：** 只需更改範例和指令，即可將其應用於任何領域（例如，法律、醫療），而無需重新訓練模型。\n",
    "\n",
    "* **處理長文件：** 專為處理可能超出語言學習模型 (LLM) 標準上下文視窗的長文本而設計。\n",
    "\n",
    "* **靈活的 LLM 支援：** 它與模型無關，可與各種 LLM 配合使用，例如 Gemini、OpenAI 模型，甚至可以透過 Ollama 支援本地開源模型。\n",
    "\n",
    "**GitHub 程式碼庫：** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)\n",
    "\n",
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 使用 PDF 文件：**](#toc0_)\n",
    "\n",
    "我們將使用 `pymupdf` 庫來提取 PDF 文件資訊。文件：[pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "然後，我們將把提取的資訊傳遞給 langextract 來獲取文件內容的洞察。\n",
    "\n",
    "我們也可以使用 Gemini 處理文檔，更多資訊請參閱其文檔：[文檔理解](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\"✓ Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
      "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \n",
      "watch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind.\n",
    "\n",
    "我們根據所需的資料類型來定義提示和範例，在本例中，我們將以「電影評論」為目標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# 定義用於「電影評論」類型資料的擷取提示\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# 提供高品質範例以引導模型\n",
    "# 這些範例示範模型應如何精確區分這兩個類別\n",
    "examples = [\n",
    "    # 範例1：示範對劇情的正面評價及其對評論者的直接影響\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    # 範例 2：展示了配樂造成的負面評價以及對觀眾的單獨影響\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n從這篇影評中提取具體觀點及其對觀眾的影響。\\n\\n重要提示：擷取文字時，請使用輸入文字的原文，不要進行改寫。\\n\\n依出現順序擷取實體，確保文字跨度不重疊。\\n\\n使用「opinion_statement」類別來擷取對電影元素（例如情節、配樂或表演）的直接評價。\\n\\n- 「subject」應為被評價的元素。\\n\\n- 「sentiment」應為正面、負面或中性。\\n\\n- 「key_phrase」應為核心描述詞。\\n\\n使用“audience_impact”類別提取描述對觀眾影響的短語。\\n\\n- 「emotion_evoked」應為感受或反應（例如，壓力、喜悅、困惑）。\\n\\n- 「causal_element」是電影中引發這種反應的部分。\\n\\n- 「target_audience」是受影響的人群（例如，「觀眾」、「觀眾」）。評論員')。\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "從這篇影評中提取具體觀點及其對觀眾的影響。\n",
    "\n",
    "重要提示：擷取文字時，請使用輸入文字的原文，不要進行改寫。\n",
    "\n",
    "依出現順序擷取實體，確保文字跨度不重疊。\n",
    "\n",
    "使用「opinion_statement」類別來擷取對電影元素（例如情節、配樂或表演）的直接評價。\n",
    "\n",
    "- 「subject」應為被評價的元素。\n",
    "\n",
    "- 「sentiment」應為正面、負面或中性。\n",
    "\n",
    "- 「key_phrase」應為核心描述詞。\n",
    "\n",
    "使用“audience_impact”類別提取描述對觀眾影響的短語。\n",
    "\n",
    "- 「emotion_evoked」應為感受或反應（例如，壓力、喜悅、困惑）。\n",
    "\n",
    "- 「causal_element」是電影中引發這種反應的部分。\n",
    "\n",
    "- 「target_audience」是受影響的人群（例如，「觀眾」、「觀眾」）。評論員')。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`\n",
    "\n",
    "這裡我們定義了用來呼叫 langextract 進行資訊擷取的主函數。請注意，函數中包含一些常數，在本範例中我們不會更改它們，但在練習中需要進行探索和理解。此函數會將提取的原始資訊儲存到 .jsonl 檔案中，並將視覺化結果儲存到 .html 檔案中。更多資訊請參閱文件。\n",
    "\n",
    "文件將保存在以下目錄中：`results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "# 優化：考量到 Gemini 免費套餐的配額限制（每分鐘 15 個請求）\n",
    "# 調整參數以平衡質量改進和 API 使用成本\n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 2, max_workers = 1, max_char_buffer = 1500, temperature = 0.5):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # 設為 2：平衡質量改進（vs 原本的 1）和 API 配額限制\n",
    "        max_workers=max_workers,         # 設為 1：防止超出免費套餐配額（每分鐘 15 個請求）\n",
    "        max_char_buffer=max_char_buffer,    # 保持 1500：提升批次精度\n",
    "        temperature=temperature    # 設為 0.5：支持多通過提取的必要條件\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\"• {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\"✓ Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 17 entities:\n",
      "\n",
      "• opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: intellectual and imaginative inventive\n",
      "• opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: His style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      "• opinion_statement: 'this idea is so farfetched'\n",
      "  - subject: The idea of dreams\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: so farfetched\n",
      "• opinion_statement: 'Nolan is free to use his creativity'\n",
      "  - subject: Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: free to use his creativity\n",
      "• opinion_statement: 'landscapes folding in on themselves and corridors spinning'\n",
      "  - subject: Visuals\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: folding in on themselves and corridors spinning\n",
      "• opinion_statement: 'This brain-racking epic theme is once again evident'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      "• opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      "• opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      "• audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'curious']\n",
      "  - causal_element: the appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      "• audience_impact: 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'engaged']\n",
      "  - causal_element: the film\n",
      "  - target_audience: the reviewer\n",
      "• opinion_statement: 'clear example of Nolan’s auteur talent'\n",
      "  - subject: ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: Nolan’s auteur talent\n",
      "• opinion_statement: 'ﬁgments yet another cluster of conditions for us to marvel at'\n",
      "  - subject: Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: marvel at\n",
      "• opinion_statement: 'a fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      "• opinion_statement: 'his epic, orchestral theme'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: epic, orchestral\n",
      "• audience_impact: 'sets the audience in the palm of his hands'\n",
      "  - emotion_evoked: ['captivated', 'controlled']\n",
      "  - causal_element: The theme\n",
      "  - target_audience: the audience\n",
      "• audience_impact: 'we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['stress', 'anxiety']\n",
      "  - causal_element: The theme\n",
      "  - target_audience: the audience\n",
      "• opinion_statement: 'without seeming unrealistic'\n",
      "  - subject: Nolan's creativity\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: without seeming unrealistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 989.46 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 100%|█████████▉| 9.90k/9.90k [00:00<00:00, 694kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n",
      "✓ Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n",
      "✓ Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'intellectual and imaginative inventive'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'His style',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'this idea is so farfetched',\n",
       "   'char_interval': {'start_pos': 617, 'end_pos': 643},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The idea of dreams',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'so farfetched'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Nolan is free to use his creativity',\n",
       "   'char_interval': {'start_pos': 726, 'end_pos': 761},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'free to use his creativity'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'landscapes folding in on themselves and corridors spinning',\n",
       "   'char_interval': {'start_pos': 787, 'end_pos': 846},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Visuals',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'folding in on themselves and corridors spinning'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 929},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into ‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'curious'],\n",
       "    'causal_element': 'the appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained', 'engaged'],\n",
       "    'causal_element': 'the film',\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'clear example of Nolan’s auteur talent',\n",
       "   'char_interval': {'start_pos': 2878, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': '‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'Nolan’s auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'ﬁgments yet another cluster of conditions for us to marvel at',\n",
       "   'char_interval': {'start_pos': 2935, 'end_pos': 2997},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'marvel at'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a fantastic score',\n",
       "   'char_interval': {'start_pos': 3004, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'his epic, orchestral theme',\n",
       "   'char_interval': {'start_pos': 3063, 'end_pos': 3089},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'epic, orchestral'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3132},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'controlled'],\n",
       "    'causal_element': 'The theme',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3137, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'anxiety'],\n",
       "    'causal_element': 'The theme',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'without seeming unrealistic',\n",
       "   'char_interval': {'start_pos': 848, 'end_pos': 875},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's creativity\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'without seeming unrealistic'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \\ntravel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\n‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \\nwhich will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \\nwatch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_50f27be9'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">this idea is so farfetched</span>, and dreams are a subject in which science has made little factual \n",
       "discovery in, <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">Nolan is free to use his creativity</span> to present ideas such as <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">landscapes folding in on \n",
       "themselves and corridors spinning</span>, <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">without seeming unrealistic</span>. \n",
       "<span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident</span> in ‘Interstellar,’ as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
       "feet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \n",
       "that a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
       "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into ‘Interstellar’ is <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientiﬁc depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#D2E3FC;\">I ﬁnd it unendingly entertaining to repeatedly \n",
       "watch this ﬁlm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, ‘Interstellar’ is a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">clear example of Nolan’s auteur talent</span>, as he once again <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#C8E6C9;\">ﬁgments yet \n",
       "another cluster of conditions for us to marvel at</span>. With <span class=\"lx-highlight\" data-idx=\"13\" style=\"background-color:#C8E6C9;\">a fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, <span class=\"lx-highlight\" data-idx=\"14\" style=\"background-color:#C8E6C9;\">his epic, orchestral theme</span> <span class=\"lx-highlight\" data-idx=\"15\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands</span> as \n",
       "<span class=\"lx-highlight\" data-idx=\"16\" style=\"background-color:#D2E3FC;\">we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\">▶️ Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\">⏮ Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\">⏭ Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"16\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/17</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">intellectual and imaginative inventive</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">His style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"this idea is so farfetched\", \"color\": \"#C8E6C9\", \"startPos\": 617, \"endPos\": 643, \"beforeText\": \"he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\n\", \"extractionText\": \"this idea is so farfetched\", \"afterText\": \", and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landsc\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The idea of dreams</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">so farfetched</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"Nolan is free to use his creativity\", \"color\": \"#C8E6C9\", \"startPos\": 726, \"endPos\": 761, \"beforeText\": \"dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, \", \"extractionText\": \"Nolan is free to use his creativity\", \"afterText\": \" to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">free to use his creativity</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"landscapes folding in on themselves and corridors spinning\", \"color\": \"#C8E6C9\", \"startPos\": 787, \"endPos\": 846, \"beforeText\": \"etched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as \", \"extractionText\": \"landscapes folding in on \\nthemselves and corridors spinning\", \"afterText\": \", without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019 as Nolan sets his characters \\nduring a second A\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Visuals</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">folding in on themselves and corridors spinning</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"without seeming unrealistic\", \"color\": \"#C8E6C9\", \"startPos\": 848, \"endPos\": 875, \"beforeText\": \"ttle factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, \", \"extractionText\": \"without seeming unrealistic\", \"afterText\": \". \\nThis brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019 as Nolan sets his characters \\nduring a second American dust bowl on future E\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s creativity</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">without seeming unrealistic</span>}</div>\"}, {\"index\": 6, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 929, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident\", \"afterText\": \" in \\u2018Interstellar,\\u2019 as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nun\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 8, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, curious</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 10, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the film</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2878, \"endPos\": 2916, \"beforeText\": \"watch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a \", \"extractionText\": \"clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 12, \"class\": \"opinion_statement\", \"text\": \"\\ufb01gments yet another cluster of conditions for us to marvel at\", \"color\": \"#C8E6C9\", \"startPos\": 2935, \"endPos\": 2997, \"beforeText\": \"an only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \", \"extractionText\": \"\\ufb01gments yet \\nanother cluster of conditions for us to marvel at\", \"afterText\": \". With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">marvel at</span>}</div>\"}, {\"index\": 13, \"class\": \"opinion_statement\", \"text\": \"a fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3004, \"endPos\": 3021, \"beforeText\": \"ll, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With \", \"extractionText\": \"a fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 14, \"class\": \"opinion_statement\", \"text\": \"his epic, orchestral theme\", \"color\": \"#C8E6C9\", \"startPos\": 3063, \"endPos\": 3089, \"beforeText\": \"ent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, \", \"extractionText\": \"his epic, orchestral theme\", \"afterText\": \" sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">epic, orchestral</span>}</div>\"}, {\"index\": 15, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3132, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands\", \"afterText\": \" as \\nwe stress over how we are all going to be saved once again.\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, controlled</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 16, \"class\": \"audience_impact\", \"text\": \"we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3137, \"endPos\": 3195, \"beforeText\": \" marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\n\", \"extractionText\": \"we stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, anxiety</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)\n",
    "\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> 附加練習 3（家庭作業）：**](#toc0_)\n",
    "\n",
    "`註：此練習為附加練習，不計入總成績，僅作為額外加分項。 `\n",
    "\n",
    "使用不同的影片評論重複資訊擷取步驟。\n",
    "\n",
    "1. 在線搜尋電影評論並將其保存為 PDF 文件，我們建議**至少一頁的評論**，就像示例中那樣。\n",
    "\n",
    "2. 載入 PDF 檔案並將其傳遞給 langextract 以從中提取資訊。\n",
    "\n",
    "3. 顯示包含已擷取屬性的 HTML 程式碼。\n",
    "\n",
    "4. 討論使用 langextract 提取的資訊質量，如何根據文件中提供的我們尚未嘗試的選項來改進提取結果？\n",
    "\n",
    "**`Github 倉庫供參考：`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 載入 PDF 檔案\n",
      "\n",
      "PDF 頁數：7 頁\n",
      "\n",
      "成功載入 './data/documents/The Shrouds.pdf'\n",
      "提取的文本長度：11284 字符\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 載入 The Shrouds.pdf\n",
    "print(\"\\n 載入 PDF 檔案\\n\")\n",
    "pdf_path_shrouds = \"./data/documents/The Shrouds.pdf\"\n",
    "formatted_text_shrouds = \"\"\n",
    "\n",
    "try:\n",
    "    doc_shrouds = pymupdf.open(pdf_path_shrouds)\n",
    "    print(f\"PDF 頁數：{len(doc_shrouds)} 頁\\n\")\n",
    "    \n",
    "    for i, page in enumerate(doc_shrouds):\n",
    "        text = page.get_text(\"text\")\n",
    "        formatted_text_shrouds += f'**Page {i + 1}**\\n'\n",
    "        formatted_text_shrouds += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc_shrouds.close()\n",
    "    print(f\"成功載入 '{pdf_path_shrouds}'\")\n",
    "    print(f\"提取的文本長度：{len(formatted_text_shrouds)} 字符\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"無法讀取 PDF：{e}\")\n",
    "    formatted_text_shrouds = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "定義資訊擷取提示和範例\n",
      "\n",
      " 提示和範例定義完成\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定義擷取提示（針對 The Shrouds 的學術評論）\n",
    "print(\"定義資訊擷取提示和範例\\n\")\n",
    "\n",
    "# 特別為 The Shrouds 學術評論調整的提示 - 優化版本\n",
    "prompt_shrouds = textwrap.dedent(\"\"\"\\\n",
    "    從這份《The Shrouds》電影評論中提取具體觀點和情感評價。\n",
    "    \n",
    "    ** 關鍵要求 **：\n",
    "    1. 擷取文字時，必須使用輸入文字的原文，不要進行改寫或解釋。\n",
    "    2. 依出現順序擷取實體，確保文字跨度不重疊。\n",
    "    3. 每次提取都要驗證提取的文本確實在原文中出現。\n",
    "    4. 優先提取具體、可驗證的表述，避免過度抽象化。\n",
    "\n",
    "    ** 使用「opinion_statement」類別提取對電影元素的直接評價 **\n",
    "    這類實體應該是評論者對電影某個方面的明確判斷。\n",
    "    - 「subject」：被評價的具體元素（例如：劇情、配樂、導演風格、視覺構圖、角色表現、象徵意義、文化背景、敘事技巧等）。\n",
    "    - 「sentiment」：必須是 Positive（正面）、Negative（負面）或 Neutral（中性）之一。\n",
    "    - 「key_phrase」：評價中最核心的描述詞或短語，應該能獨立傳達該觀點的要旨。\n",
    "\n",
    "    ** 使用「audience_impact」類別提取描述對觀眾影響或情感喚起的短語 **\n",
    "    這類實體應該說明電影元素如何影響或激發觀眾的反應。\n",
    "    - 「emotion_evoked」：觀眾感受到的具體感受或反應列表（例如：共鳴、恐懼、困惑、感動、希望、不適感、沉思、內省等）。\n",
    "    - 「causal_element」：電影中具體引發這種反應的部分或元素（例如：導演對死亡的處理、音樂層次、鏡頭語言等）。\n",
    "    - 「target_audience」：受到影響的特定人群（例如：「觀眾」、「評論者」、「有特定經歷的觀眾」）。\n",
    "\n",
    "    ** 提取邊界條件 **\n",
    "    - 如果一句話包含多個可獨立的觀點，請分別提取每一個。\n",
    "    - 避免提取純粹的劇情總結；僅提取帶有評價色彩的內容。\n",
    "    - 確保每個提取單位都有明確的屬性指派。\n",
    "    \"\"\")\n",
    "\n",
    "# 高品質範例，包括學術評論風格\n",
    "examples_shrouds = [\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film stands as Cronenberg's most Jewish film and deepest exploration of mortality.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"Cronenberg's most Jewish film\",\n",
    "                attributes={\n",
    "                    \"subject\": \"電影文化特性\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"最大的特點\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"deepest exploration of mortality\",\n",
    "                attributes={\n",
    "                    \"subject\": \"主題深度\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"最深層的死亡主題探索\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The powerful emotion comes from Cronenberg's self-recognition of his own mortality, creating a glimmer of hopefulness despite the grief and anger.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"powerful emotion\",\n",
    "                attributes={\n",
    "                    \"subject\": \"情感表現\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"強大的情感衝擊\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"creating a glimmer of hopefulness despite the grief and anger\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"希望\", \"寄託\", \"淨化\"],\n",
    "                    \"causal_element\": \"導演對死亡的深刻認知和視覺呈現\",\n",
    "                    \"target_audience\": \"觀眾\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The dialogue felt clunky while the haunting soundtrack perfectly captured the film's dark atmosphere, making viewers feel deeply unsettled.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"dialogue felt clunky\",\n",
    "                attributes={\n",
    "                    \"subject\": \"對白\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"生硬不自然\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"haunting soundtrack perfectly captured the film's dark atmosphere\",\n",
    "                attributes={\n",
    "                    \"subject\": \"配樂\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"完美捕捉陰暗氛圍\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"making viewers feel deeply unsettled\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"不安\", \"詭異\", \"沉浸感\"],\n",
    "                    \"causal_element\": \"配樂和視覺設計\",\n",
    "                    \"target_audience\": \"觀眾\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\" 提示和範例定義完成\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "執行資訊擷取\n",
      "\n",
      "正在使用 langextract 進行資訊擷取...\n",
      "  模型：gemini-2.5-flash-lite\n",
      "  提取通過數：5 (優化改進)\n",
      "  最大字符緩衝：1500 (優化改進)\n",
      "  溫度設置：0.5 (優化改進)\n",
      "\n"
     ]
    },
    {
     "ename": "InferenceRuntimeError",
     "evalue": "Parallel inference error: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 52.812515527s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\providers\\gemini.py:202\u001b[39m, in \u001b[36mGeminiLanguageModel._process_single_prompt\u001b[39m\u001b[34m(self, prompt, config)\u001b[39m\n\u001b[32m    200\u001b[39m   config.setdefault(\u001b[33m'\u001b[39m\u001b[33mresponse_schema\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.gemini_schema.schema_dict)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m core_types.ScoredOutput(score=\u001b[32m1.0\u001b[39m, output=response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\models.py:6447\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6446\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6447\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   6449\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6450\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is done.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5259\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5257\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5259\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5260\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   5261\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5264\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5265\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1289\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1286\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1287\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1288\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1290\u001b[39m response_body = (\n\u001b[32m   1291\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1292\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1109\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1086\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1079\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1080\u001b[39m     method=http_request.method,\n\u001b[32m   1081\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1085\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1086\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1088\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1089\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:105\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 52.812515527s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInferenceRuntimeError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\providers\\gemini.py:264\u001b[39m, in \u001b[36mGeminiLanguageModel.infer\u001b[39m\u001b[34m(self, batch_prompts, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m   results[index] = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\providers\\gemini.py:209\u001b[39m, in \u001b[36mGeminiLanguageModel._process_single_prompt\u001b[39m\u001b[34m(self, prompt, config)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InferenceRuntimeError(\n\u001b[32m    210\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGemini API error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, original=e\n\u001b[32m    211\u001b[39m   ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInferenceRuntimeError\u001b[39m: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 52.812515527s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInferenceRuntimeError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  最大字符緩衝：1500 (優化改進)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  溫度設置：0.5 (優化改進)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m html_content_shrouds = \u001b[43mgrounded_info_extraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformatted_text_shrouds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_shrouds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexamples_shrouds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthe_shrouds_extraction_example\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m 資訊擷取完成\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mgrounded_info_extraction\u001b[39m\u001b[34m(input_documents, prompt, examples, file_name, model_id, extraction_passes, max_workers, max_char_buffer, temperature)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrounded_info_extraction\u001b[39m(input_documents, prompt, examples, file_name, model_id =\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash-lite\u001b[39m\u001b[33m\"\u001b[39m, extraction_passes = \u001b[32m5\u001b[39m, max_workers = \u001b[32m5\u001b[39m, max_char_buffer = \u001b[32m1500\u001b[39m, temperature = \u001b[32m0.5\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     result = \u001b[43mlx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_or_documents\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Improves recall through multiple passes over the same text, needs temperature above 0.0\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Parallel processing for speed, remember there are API call rate limits, so do not abuse\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Increased from 2000 to 1500 for better batch accuracy\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Added temperature parameter for controlled randomness\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result.extractions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m entities:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\__init__.py:55\u001b[39m, in \u001b[36mextract\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract\u001b[39m(*args: Any, **kwargs: Any):\n\u001b[32m     54\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Top-level API: lx.extract(...).\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextract_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\extraction.py:296\u001b[39m, in \u001b[36mextract\u001b[39m\u001b[34m(text_or_documents, prompt_description, examples, model_id, api_key, language_model_type, format_type, max_char_buffer, temperature, fence_output, use_schema_constraints, batch_length, max_workers, additional_context, resolver_params, language_model_params, debug, model_url, extraction_passes, config, model, fetch_urls, prompt_validation_level, prompt_validation_strict)\u001b[39m\n\u001b[32m    288\u001b[39m annotator = annotation.Annotator(\n\u001b[32m    289\u001b[39m     language_model=language_model,\n\u001b[32m    290\u001b[39m     prompt_template=prompt_template,\n\u001b[32m    291\u001b[39m     format_type=format_type,\n\u001b[32m    292\u001b[39m     fence_output=fence_output,\n\u001b[32m    293\u001b[39m )\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_or_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mannotator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_or_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m      \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbatch_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m      \u001b[49m\u001b[43madditional_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m      \u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    307\u001b[39m   documents = cast(Iterable[data.Document], text_or_documents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\annotation.py:506\u001b[39m, in \u001b[36mAnnotator.annotate_text\u001b[39m\u001b[34m(self, text, resolver, max_char_buffer, batch_length, additional_context, debug, extraction_passes, **kwargs)\u001b[39m\n\u001b[32m    496\u001b[39m start_time = time.time() \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    498\u001b[39m documents = [\n\u001b[32m    499\u001b[39m     data.Document(\n\u001b[32m    500\u001b[39m         text=text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    503\u001b[39m     )\n\u001b[32m    504\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m annotations = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mannotate_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextraction_passes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    518\u001b[39m     \u001b[38;5;28mlen\u001b[39m(annotations) == \u001b[32m1\u001b[39m\n\u001b[32m    519\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected 1 annotation but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(annotations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m annotations.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mand\u001b[39;00m annotations[\u001b[32m0\u001b[39m].extractions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\annotation.py:240\u001b[39m, in \u001b[36mAnnotator.annotate_documents\u001b[39m\u001b[34m(self, documents, resolver, max_char_buffer, batch_length, debug, extraction_passes, **kwargs)\u001b[39m\n\u001b[32m    236\u001b[39m   \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._annotate_documents_single_pass(\n\u001b[32m    237\u001b[39m       documents, resolver, max_char_buffer, batch_length, debug, **kwargs\n\u001b[32m    238\u001b[39m   )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m   \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._annotate_documents_sequential_passes(\n\u001b[32m    241\u001b[39m       documents,\n\u001b[32m    242\u001b[39m       resolver,\n\u001b[32m    243\u001b[39m       max_char_buffer,\n\u001b[32m    244\u001b[39m       batch_length,\n\u001b[32m    245\u001b[39m       debug,\n\u001b[32m    246\u001b[39m       extraction_passes,\n\u001b[32m    247\u001b[39m       **kwargs,\n\u001b[32m    248\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\annotation.py:420\u001b[39m, in \u001b[36mAnnotator._annotate_documents_sequential_passes\u001b[39m\u001b[34m(self, documents, resolver, max_char_buffer, batch_length, debug, extraction_passes, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pass_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(extraction_passes):\n\u001b[32m    416\u001b[39m   logging.info(\n\u001b[32m    417\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mStarting extraction pass \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, pass_num + \u001b[32m1\u001b[39m, extraction_passes\n\u001b[32m    418\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mannotated_doc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_annotate_documents_single_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdocument_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m      \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmax_char_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbatch_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpass_num\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m      \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Only show progress on first pass\u001b[39;49;00m\n\u001b[32m    427\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotated_doc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocument_id\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocument_extractions_by_pass\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\annotation.py:325\u001b[39m, in \u001b[36mAnnotator._annotate_documents_single_pass\u001b[39m\u001b[34m(self, documents, resolver, max_char_buffer, batch_length, debug, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m     desc = progress.format_extraction_progress(\n\u001b[32m    319\u001b[39m         model_info,\n\u001b[32m    320\u001b[39m         current_chars=batch_size,\n\u001b[32m    321\u001b[39m         processed_chars=chars_processed,\n\u001b[32m    322\u001b[39m     )\n\u001b[32m    323\u001b[39m     progress_bar.set_description(desc)\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscored_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_scored_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m  \u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing chunk: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscored_outputs\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\langextract\\providers\\gemini.py:266\u001b[39m, in \u001b[36mGeminiLanguageModel.infer\u001b[39m\u001b[34m(self, batch_prompts, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m     results[index] = future.result()\n\u001b[32m    265\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InferenceRuntimeError(\n\u001b[32m    267\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mParallel inference error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, original=e\n\u001b[32m    268\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m    271\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInferenceRuntimeError\u001b[39m: Parallel inference error: Gemini API error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 52.812515527s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}"
     ]
    }
   ],
   "source": [
    "# 執行 langextract 資訊擷取\n",
    "print(\"執行資訊擷取\\n\")\n",
    "\n",
    "print(\"正在使用 langextract 進行資訊擷取...\")\n",
    "print(\"  模型：gemini-2.5-flash-lite\")\n",
    "print(\"  提取通過數：2 (根據免費配額優化)\")\n",
    "print(\"  最大工作線程：1 (符合 API 配額限制)\")\n",
    "print(\"  最大字符緩衝：1500 (改進批次精度)\")\n",
    "print(\"  溫度設置：0.5 (支持多通過提取)\\n\")\n",
    "\n",
    "html_content_shrouds = grounded_info_extraction(\n",
    "    formatted_text_shrouds, \n",
    "    prompt_shrouds, \n",
    "    examples_shrouds, \n",
    "    \"the_shrouds_extraction_example\",\n",
    "    extraction_passes=2,\n",
    "    max_char_buffer=1500,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"\\n 資訊擷取完成\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "顯示提取結果\n",
      "\n",
      "原始擷取的結構化資料（JSON 格式）：\n",
      "總共提取 30 個實體\n",
      "\n",
      "前 5 個提取的實體示例：\n",
      "\n",
      "1. [opinion_statement]\n",
      "   文本: This is a film review of The Shrouds (2024), directed by Dav...\n",
      "   屬性: {'subject': '電影', 'sentiment': 'Neutral', 'key_phrase': '電影評論'}\n",
      "\n",
      "2. [opinion_statement]\n",
      "   文本: most autobiographical...\n",
      "   屬性: {'subject': '電影的個人化程度', 'sentiment': 'Positive', 'key_phrase': '最個人化'}\n",
      "\n",
      "3. [opinion_statement]\n",
      "   文本: an international technothriller art film...\n",
      "   屬性: {'subject': '電影類型', 'sentiment': 'Neutral', 'key_phrase': '國際科技驚悚藝術電影'}\n",
      "\n",
      "4. [opinion_statement]\n",
      "   文本: We are in familiar Cronenbergian territory....\n",
      "   屬性: {'subject': '導演風格', 'sentiment': 'Neutral', 'key_phrase': '熟悉的柯能堡風格'}\n",
      "\n",
      "5. [opinion_statement]\n",
      "   文本: secretive, isolated communities with authoritative, charisma...\n",
      "   屬性: {'subject': '電影主題', 'sentiment': 'Neutral', 'key_phrase': '秘密社群、權威領袖、危險意識形態'}\n"
     ]
    }
   ],
   "source": [
    "# 查看原始提取的結構化資料\n",
    "print(\"顯示提取結果\\n\")\n",
    "\n",
    "print(\"原始擷取的結構化資料（JSON 格式）：\")\n",
    "\n",
    "with open(\"./results/info_extractions/shrouds_extraction_bonus.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content_extracted_raw_shrouds = json.load(f)\n",
    "\n",
    "# 顯示提取的實體數量\n",
    "num_extractions = len(content_extracted_raw_shrouds.get(\"extractions\", []))\n",
    "print(f\"總共提取 {num_extractions} 個實體\\n\")\n",
    "\n",
    "# 顯示前5個提取的實體\n",
    "print(\"前 5 個提取的實體示例：\")\n",
    "for idx, extraction in enumerate(content_extracted_raw_shrouds.get(\"extractions\", [])[:5], 1):\n",
    "    print(f\"\\n{idx}. [{extraction['extraction_class']}]\")\n",
    "    print(f\"   文本: {extraction['extraction_text'][:60]}...\")\n",
    "    print(f\"   屬性: {extraction.get('attributes', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML 互動式視覺化（包含已擷取屬性）\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Journal of Religion &amp; Film \n",
       "Journal of Religion &amp; Film \n",
       "Volume 29 \n",
       "Issue 1 April 2025 \n",
       "Article 77 \n",
       "April 2025 \n",
       "The Shrouds \n",
       "The Shrouds \n",
       "Elijah Siegler \n",
       "College of Charleston, sieglere@cofc.edu \n",
       "Follow this and additional works at: https://digitalcommons.unomaha.edu/jrf \n",
       " Part of the Film and Media Studies Commons, and the Religion Commons \n",
       "Please take our feedback survey at: https://unomaha.az1.qualtrics.com/jfe/form/\n",
       "SV_8cchtFmpDyGfBLE \n",
       "Recommended Citation \n",
       "Recommended Citation \n",
       "Siegler, Elijah (2025) &quot;The Shrouds,&quot; Journal of Religion &amp; Film: Vol. 29: Iss. 1, Article 77. \n",
       "DOI: https://doi.org/10.32873/uno.dc.jrf.29.01.77 \n",
       "Available at: https://digitalcommons.unomaha.edu/jrf/vol29/iss1/77 \n",
       "This Film Review is brought to you for free and open \n",
       "access by DigitalCommons@UNO. It has been accepted \n",
       "for inclusion in Journal of Religion &amp; Film by an \n",
       "authorized editor of DigitalCommons@UNO. For more \n",
       "information, please contact \n",
       "unodigitalcommons@unomaha.edu.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 2**\n",
       "&quot;&quot;&quot;\n",
       "The Shrouds \n",
       "The Shrouds \n",
       "Abstract \n",
       "Abstract \n",
       "<span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">This is a film review of The Shrouds (2024), directed by David Cronenberg.</span> \n",
       "Creative Commons License \n",
       "Creative Commons License \n",
       "This work is licensed under a Creative Commons Attribution 4.0 License. \n",
       "Author Notes \n",
       "Author Notes \n",
       "Elijah Siegler is Professor of Religious Studies at the College of Charleston. He is the co-author of Dream \n",
       "Trippers: Global Daoism and the Predicament of Modern Culture (2017) and the editor of Coen: Framing \n",
       "Religion in Amoral Order (2016). He is currently working on a monograph about spirituality in Asheville. \n",
       "This film review is available in Journal of Religion &amp; Film: https://digitalcommons.unomaha.edu/jrf/vol29/iss1/77\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 3**\n",
       "&quot;&quot;&quot;\n",
       "Note: I have known David Cronenberg since I was a child (see Siegler 2012 for more detail). This \n",
       "review incorporates a conversation I had with Cronenberg on December 17, 2024, at a coffee shop \n",
       "near his home in Toronto. \n",
       "\n",
       "This is the story of a filmmaker from Toronto, who is well off but not extravagantly wealthy. He \n",
       "drives a Tesla and lives in a comfortable but austere home. He is trim and aging well, with a shock \n",
       "of white hair and a dry sense of humor. He is an outspoken atheist whose loving stable relationship \n",
       "to his Jewish wife is upended when she gets sick with cancer. Their lives become regulated by \n",
       "medical forces beyond their control. His wife dies and he buries her. He feels like climbing in the \n",
       "grave with her, but he settles for buying a plot next to hers. Eventually, he starts dating again. Out \n",
       "of his intense grief and bereavement come a new masterful creative project. \n",
       "This above paragraph is a summary of the backstory of The Shrouds in which a man named \n",
       "Karsh Relilkh, played by Vincent Cassel, creates GraveTech, a burial shroud equipped with \n",
       "cameras which allows someone to see their loved one decompose. It also describes David \n",
       "Cronenberg, whose creative project is his new movie The Shrouds, which he wrote and directed. \n",
       "This is Cronenberg’s twenty-third feature film and his <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">most autobiographical</span> since 1979’s The \n",
       "Brood. Both films are a response to the dissolution of Cronenberg’s marriages: the earlier film \n",
       "dramatizing a contentious divorce and custody battle with his first wife, and the new film about \n",
       "the aftermath of the illness and death of his second wife, to whom he had been married for thirty-\n",
       "seven years. \n",
       "Whereas The Brood is a classic of body horror (a genre of which Cronenberg has been \n",
       "rightfully credited as the founder), The Shrouds, if all you knew about it was that it is a noted \n",
       "horror auteur’s deeply personal film about illness, loss, and the death of a loved one, you might \n",
       "think it would be a ghost story, or a tale of the undead. (Ghosts, hauntings, zombies, and vampires \n",
       "1\n",
       "Siegler: The Shrouds\n",
       "Published by DigitalCommons@UNO, 2025\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 4**\n",
       "&quot;&quot;&quot;\n",
       "have, of course, been used since the birth of cinema, and for thousands of years prior, to work out \n",
       "our feelings about death, illness, and loss.) But you would be wrong. Cronenberg, the staunch \n",
       "atheist, has, in his fifty-plus year career, never made a film with a supernatural element. And he is \n",
       "not about to start now. (Not that he hasn’t been asked: see Siegler 2012, 1101-1102). If one must \n",
       "pin down the genre, one might call The Shrouds “<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">an international technothriller art film</span>.” (For \n",
       "other examples, see Olivier Assayas’ Demonlover (2002) and Boarding Gate (2007)). \n",
       "We learn the backstory in the first sequence of the movie—an awkward blind date. The \n",
       "plot kicks into gear when the GraveTech technology reveals to Karsh that his wife Becca’s corpse \n",
       "is growing metallic protuberances and when Karsh’s hi-tech graveyard is vandalized. Who is \n",
       "responsible for these violations? Icelandic eco-terrorists who use Runic symbols? A nefarious data-\n",
       "stealing Chinese textile corporation called Shining Cloth (fast fashion meets ByteDance meets the \n",
       "Shining Path)? Citadel Technologies, a Hungarian-Canadian conglomerate, fronted by a seductive \n",
       "French-Korean woman? \n",
       "\n",
       "<span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">We are in familiar Cronenbergian territory.</span> As I wrote in 2012, “<span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">secretive, isolated \n",
       "communities with authoritative, charismatic leaders and dangerous ideologies are constant features \n",
       "in most of his original scripts</span> […] <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">the plots advance because of warring “cults”</span> (Siegler 2012, \n",
       "1108).   \n",
       "In The Shrouds, <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#C8E6C9;\">these groups, who may be either competing or collaborating, seem to be \n",
       "part of a shadowy multinational conspiracy.</span> <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">These global concerns are the clearest expression of \n",
       "Cronenberg’s cosmopolitanism</span> (even more than his 2012 film, titled Cosmopolis) but, unlike say, \n",
       "Videodrome’s Spectacular Optical or The Brood’s Somafree Institute, they are spoken of but rarely \n",
       "seen. Clearly, Cronenberg, in his late career phase, feels <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#C8E6C9;\">comfortable with a sketched-in plot</span>.1 In \n",
       "one of the film’s several subtle touches of black humor, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#C8E6C9;\">the real villain is (probably) revealed to</span> \n",
       "2\n",
       "Journal of Religion &amp; Film, Vol. 29 [2025], Iss. 1, Art. 77\n",
       "https://digitalcommons.unomaha.edu/jrf/vol29/iss1/77\n",
       "DOI: https://doi.org/10.32873/uno.dc.jrf.29.01.77\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 5**\n",
       "&quot;&quot;&quot;\n",
       "be Becca’s oncologist, the mostly offscreen Dr. Jerry Eckler, who teaches classes on “the \n",
       "psychology of healing.” \n",
       "\n",
       "Karsh refers to the question of who violated his wife’s body as a “classic detection puzzle” \n",
       "but <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">the audience probably doesn’t care as much about the detective story as it does about the \n",
       "<span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">resonant images and deep emotions</span></span>, which I felt most clearly in scenes with Diane Kruger as Becca \n",
       "<span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#C8E6C9;\">appearing nude and evermore disfigured</span> in Karsh’s dreams. (She is emphatically not a ghost.) \n",
       "Becca’s absence/presence is also felt in scenes with Kruger as Becca’s twin Terry, and as the voice \n",
       "of <span class=\"lx-highlight\" data-idx=\"13\" style=\"background-color:#C8E6C9;\">the untrustworthy AI animated avatar, Hunny</span>. Cronenberg, of course, is interested in the \n",
       "physical effect of emotions as exemplified in the opening line of movie, spoken by Karsh’s dentist: \n",
       "“<span class=\"lx-highlight\" data-idx=\"14\" style=\"background-color:#C8E6C9;\">Grief is rotting your teeth</span>.” Relatedly, <span class=\"lx-highlight\" data-idx=\"15\" style=\"background-color:#C8E6C9;\">one source of the powerful emotion coursing through The \n",
       "Shrouds comes from Cronenberg’s self-recognition of his own mortality</span> (a “relikh?!”). (As other \n",
       "film critics have pointed out, several other films made in 2024 share this theme.2) \n",
       "<span class=\"lx-highlight\" data-idx=\"16\" style=\"background-color:#C8E6C9;\">The plot, the imagery, and the emotional themes of this film center on graves and bodies \n",
       "being desecrated</span>—and “desecration” is a word that is notably used in this movie. “To desecrate” \n",
       "means to violate something sacred, and knowing this fact,  along with the film’s autobiographical \n",
       "nature, it should come as no surprise that <span class=\"lx-highlight\" data-idx=\"17\" style=\"background-color:#C8E6C9;\">The Shrouds stands as Cronenberg’s most Jewish film</span>. \n",
       "True, Cronenberg does not deign to make his stand-in, Karsh, come from a secular Jewish \n",
       "background, as Cronenberg himself does. Instead, Karsh tells his blind date, he is “some \n",
       "Belarusian Eastern Orthodox thing.” But elsewhere, <span class=\"lx-highlight\" data-idx=\"18\" style=\"background-color:#C8E6C9;\">Jewishness abounds</span>—in the allusions to \n",
       "Jewish food (a way many secular Jews relate to their tradition), including Guy Pearce as tech nerd \n",
       "Maury chowing down on Matzoh ball soup and pastrami, and references to United Dairy and Fat \n",
       "Pasha, two actual Jewish-identified restaurants in Toronto. (Many of Cronenberg’s films are \n",
       "explicitly set in Toronto, but <span class=\"lx-highlight\" data-idx=\"19\" style=\"background-color:#C8E6C9;\">The Shrouds is the first to be set in Jewish Toronto</span>.) As well,  Karsh \n",
       "3\n",
       "Siegler: The Shrouds\n",
       "Published by DigitalCommons@UNO, 2025\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 6**\n",
       "&quot;&quot;&quot;\n",
       "deflects Terry’s conspiracy theorizing by referencing Stalin’s paranoid antisemitic dictum, \n",
       "“(Jewish) doctors plot.” And most resonantly, we see Jewishness in the Hebrew letters carved on \n",
       "Becca’s gravestone.  \n",
       "But <span class=\"lx-highlight\" data-idx=\"20\" style=\"background-color:#C8E6C9;\">this is not a case of an aging artist “finding God” or “returning to his roots.”</span> <span class=\"lx-highlight\" data-idx=\"21\" style=\"background-color:#C8E6C9;\">If The \n",
       "Shrouds is Cronenberg’s most Jewish film it is also his most atheist.</span> Cronenberg, in his public \n",
       "statements, has always been among the most avowedly atheist filmmakers, but <span class=\"lx-highlight\" data-idx=\"22\" style=\"background-color:#C8E6C9;\">his characters were \n",
       "not. Until now.</span> In the first sequence of the movie, <span class=\"lx-highlight\" data-idx=\"23\" style=\"background-color:#C8E6C9;\">Karsh refers to himself a “non-observant atheist” \n",
       "and calls the shroud of Turin a fake.</span> Later, speculating his private graveyard might have been \n",
       "vandalized by religious extremists, he notes that <span class=\"lx-highlight\" data-idx=\"24\" style=\"background-color:#C8E6C9;\">“we’ve been called techno-atheist infidels.”</span> \n",
       "In some ways, <span class=\"lx-highlight\" data-idx=\"25\" style=\"background-color:#C8E6C9;\">The Shrouds embodies a very old debate between tradition and modernity \n",
       "or religion and atheism</span>, enacted at multiple levels, not least in a seemingly throwaway bit of \n",
       "dialogue about the “burial versus cremation” debate: <span class=\"lx-highlight\" data-idx=\"26\" style=\"background-color:#C8E6C9;\">burial being necessary in the Jewish tradition, \n",
       "while cremation being seen as more ecological and modern.</span> Cronenberg, wisely, does not presume \n",
       "to settle this debate, but simply records how it plays out on an emotional level—through a <span class=\"lx-highlight\" data-idx=\"27\" style=\"background-color:#C8E6C9;\">powerful \n",
       "depiction of grief</span>, yes, but also of <span class=\"lx-highlight\" data-idx=\"28\" style=\"background-color:#C8E6C9;\">confusion and anger</span> (at a medical establishment that robs us of \n",
       "our power, among other indignities).  And finally, as shown in the last scene of Karsh flying across \n",
       "the ocean towards an uncertain future, there is <span class=\"lx-highlight\" data-idx=\"29\" style=\"background-color:#D2E3FC;\">a glimmer of hopefulness towards whatever comes \n",
       "next</span>. \n",
       "\n",
       "\n",
       "1 Or Dangling subplots and antagonists referred to but never seen, which point to the fact that The Shrouds was written \n",
       "to be the pilot for a Netflix series. (The series itself would have shown more of these groups, and, Cronenberg told \n",
       "me, more about death rituals of various religions.)  \n",
       "\n",
       "2 I owe this insight to John Semley writing in The Baffler. Similarly, Marya Gates on the Filmspotting Podcast \n",
       "thoughtfully places The Shrouds with two other 2024 films about losing a longtime spouse, made by aging directors \n",
       "who were also in the process of losing spouses: Oh Canada from Paul Schrader and Megalopolis from Francis Ford \n",
       "Coppola. \n",
       "\n",
       "4\n",
       "Journal of Religion &amp; Film, Vol. 29 [2025], Iss. 1, Art. 77\n",
       "https://digitalcommons.unomaha.edu/jrf/vol29/iss1/77\n",
       "DOI: https://doi.org/10.32873/uno.dc.jrf.29.01.77\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 7**\n",
       "&quot;&quot;&quot;\n",
       "References \n",
       "\n",
       "\n",
       "Gates, Marya. Guest on “Filmspotting” Podcast, December 19, 2024. \n",
       "https://www.filmspotting.net/episodes-archive/2024/12/19/995-top-10-of-2024-roundtable-wmichael-phillips-and-\n",
       "marya-gates \n",
       "\n",
       "Semley, John. “No, country for old men” The Baffler Dec 17, 2024. \n",
       "https://thebaffler.com/latest/no-country-for-old-men-semley. \n",
       "\n",
       "Siegler, Elijah. “David Cronenberg: The Secular Auteur as Critic of Religion.” Journal of the American Academy of \n",
       "Religion, vol. 80, no. 4, 2012, pp. 1098–112. \n",
       "\n",
       "5\n",
       "Siegler: The Shrouds\n",
       "Published by DigitalCommons@UNO, 2025\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\">▶️ Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\">⏮ Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\">⏭ Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"29\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/30</span> |\n",
       "          Pos <span id=\"posInfo\">[1051-1125]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"This is a film review of The Shrouds (2024), directed by David Cronenberg.\", \"color\": \"#C8E6C9\", \"startPos\": 1051, \"endPos\": 1125, \"beforeText\": \"lCommons@UNO. For more \\ninformation, please contact \\nunodigitalcommons@unomaha.edu.\\n&quot;&quot;&quot;\\n\\n**Page 2**\\n&quot;&quot;&quot;\\nThe Shrouds \\nThe Shrouds \\nAbstract \\nAbstract \\n\", \"extractionText\": \"This is a film review of The Shrouds (2024), directed by David Cronenberg.\", \"afterText\": \" \\nCreative Commons License \\nCreative Commons License \\nThis work is licensed under a Creative Commons Attribution 4.0 License. \\nAuthor Notes \\nAuthor No\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u8a55\\u8ad6</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"most autobiographical\", \"color\": \"#C8E6C9\", \"startPos\": 3049, \"endPos\": 3070, \"beforeText\": \"Cronenberg, whose creative project is his new movie The Shrouds, which he wrote and directed. \\nThis is Cronenberg\\u2019s twenty-third feature film and his \", \"extractionText\": \"most autobiographical\", \"afterText\": \" since 1979\\u2019s The \\nBrood. Both films are a response to the dissolution of Cronenberg\\u2019s marriages: the earlier film \\ndramatizing a contentious divorce \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u7684\\u500b\\u4eba\\u5316\\u7a0b\\u5ea6</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u6700\\u500b\\u4eba\\u5316</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"an international technothriller art film\", \"color\": \"#C8E6C9\", \"startPos\": 4308, \"endPos\": 4348, \"beforeText\": \"s \\nnot about to start now. (Not that he hasn\\u2019t been asked: see Siegler 2012, 1101-1102). If one must \\npin down the genre, one might call The Shrouds \\u201c\", \"extractionText\": \"an international technothriller art film\", \"afterText\": \".\\u201d (For \\nother examples, see Olivier Assayas\\u2019 Demonlover (2002) and Boarding Gate (2007)). \\nWe learn the backstory in the first sequence of the movie\\u2014\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u985e\\u578b</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u570b\\u969b\\u79d1\\u6280\\u9a5a\\u609a\\u85dd\\u8853\\u96fb\\u5f71</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"We are in familiar Cronenbergian territory.\", \"color\": \"#C8E6C9\", \"startPos\": 5035, \"endPos\": 5078, \"beforeText\": \"on meets ByteDance meets the \\nShining Path)? Citadel Technologies, a Hungarian-Canadian conglomerate, fronted by a seductive \\nFrench-Korean woman? \\n \\n\", \"extractionText\": \"We are in familiar Cronenbergian territory.\", \"afterText\": \" As I wrote in 2012, \\u201csecretive, isolated \\ncommunities with authoritative, charismatic leaders and dangerous ideologies are constant features \\nin most\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u5c0e\\u6f14\\u98a8\\u683c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u719f\\u6089\\u7684\\u67ef\\u80fd\\u5821\\u98a8\\u683c</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"secretive, isolated communities with authoritative, charismatic leaders and dangerous ideologies are constant features in most of his original scripts\", \"color\": \"#C8E6C9\", \"startPos\": 5100, \"endPos\": 5252, \"beforeText\": \", a Hungarian-Canadian conglomerate, fronted by a seductive \\nFrench-Korean woman? \\n \\nWe are in familiar Cronenbergian territory. As I wrote in 2012, \\u201c\", \"extractionText\": \"secretive, isolated \\ncommunities with authoritative, charismatic leaders and dangerous ideologies are constant features \\nin most of his original scripts\", \"afterText\": \" [\\u2026] the plots advance because of warring \\u201ccults\\u201d (Siegler 2012, \\n1108).   \\nIn The Shrouds, these groups, who may be either competing or collaborating\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u79d8\\u5bc6\\u793e\\u7fa4\\u3001\\u6b0a\\u5a01\\u9818\\u8896\\u3001\\u5371\\u96aa\\u610f\\u8b58\\u5f62\\u614b</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"the plots advance because of warring \\u201ccults\\u201d\", \"color\": \"#C8E6C9\", \"startPos\": 5257, \"endPos\": 5301, \"beforeText\": \"ve, isolated \\ncommunities with authoritative, charismatic leaders and dangerous ideologies are constant features \\nin most of his original scripts [\\u2026] \", \"extractionText\": \"the plots advance because of warring \\u201ccults\\u201d\", \"afterText\": \" (Siegler 2012, \\n1108).   \\nIn The Shrouds, these groups, who may be either competing or collaborating, seem to be \\npart of a shadowy multinational con\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u5287\\u60c5</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u56e0\\u5c0d\\u7acb\\u7684\\u300c\\u90aa\\u6559\\u300d\\u800c\\u63a8\\u9032</span>}</div>\"}, {\"index\": 6, \"class\": \"opinion_statement\", \"text\": \"these groups, who may be either competing or collaborating, seem to be part of a shadowy multinational conspiracy.\", \"color\": \"#C8E6C9\", \"startPos\": 5344, \"endPos\": 5459, \"beforeText\": \"ies are constant features \\nin most of his original scripts [\\u2026] the plots advance because of warring \\u201ccults\\u201d (Siegler 2012, \\n1108).   \\nIn The Shrouds, \", \"extractionText\": \"these groups, who may be either competing or collaborating, seem to be \\npart of a shadowy multinational conspiracy.\", \"afterText\": \" These global concerns are the clearest expression of \\nCronenberg\\u2019s cosmopolitanism (even more than his 2012 film, titled Cosmopolis) but, unlike say,\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u5287\\u60c5</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u76f8\\u4e92\\u7af6\\u722d\\u6216\\u5408\\u4f5c\\u7684\\u5718\\u9ad4\\uff0c\\u4f3c\\u4e4e\\u662f\\u9670\\u8b00\\u7684\\u4e00\\u90e8\\u5206</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"These global concerns are the clearest expression of Cronenberg\\u2019s cosmopolitanism\", \"color\": \"#C8E6C9\", \"startPos\": 5460, \"endPos\": 5542, \"beforeText\": \" 2012, \\n1108).   \\nIn The Shrouds, these groups, who may be either competing or collaborating, seem to be \\npart of a shadowy multinational conspiracy. \", \"extractionText\": \"These global concerns are the clearest expression of \\nCronenberg\\u2019s cosmopolitanism\", \"afterText\": \" (even more than his 2012 film, titled Cosmopolis) but, unlike say, \\nVideodrome\\u2019s Spectacular Optical or The Brood\\u2019s Somafree Institute, they are spok\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u5168\\u7403\\u6027\\u8b70\\u984c\\u662f\\u67ef\\u80fd\\u5821\\u570b\\u969b\\u4e3b\\u7fa9\\u6700\\u6e05\\u6670\\u7684\\u8868\\u9054</span>}</div>\"}, {\"index\": 8, \"class\": \"opinion_statement\", \"text\": \"comfortable with a sketched-in plot\", \"color\": \"#C8E6C9\", \"startPos\": 5769, \"endPos\": 5804, \"beforeText\": \"me\\u2019s Spectacular Optical or The Brood\\u2019s Somafree Institute, they are spoken of but rarely \\nseen. Clearly, Cronenberg, in his late career phase, feels \", \"extractionText\": \"comfortable with a sketched-in plot\", \"afterText\": \".1 In \\none of the film\\u2019s several subtle touches of black humor, the real villain is (probably) revealed to \\n2\\nJournal of Religion &amp; Film, Vol. 29 [202\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u7bc0</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u5c0d\\u8349\\u7387\\u7684\\u60c5\\u7bc0\\u611f\\u5230\\u81ea\\u5728</span>}</div>\"}, {\"index\": 9, \"class\": \"opinion_statement\", \"text\": \"the real villain is (probably) revealed to be Becca\\u2019s oncologist\", \"color\": \"#C8E6C9\", \"startPos\": 5868, \"endPos\": 5910, \"beforeText\": \"early, Cronenberg, in his late career phase, feels comfortable with a sketched-in plot.1 In \\none of the film\\u2019s several subtle touches of black humor, \", \"extractionText\": \"the real villain is (probably) revealed to\", \"afterText\": \" \\n2\\nJournal of Religion &amp; Film, Vol. 29 [2025], Iss. 1, Art. 77\\nhttps://digitalcommons.unomaha.edu/jrf/vol29/iss1/77\\nDOI: https://doi.org/10.32873/uno\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u7bc0</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u53cd\\u6d3e\\u7684\\u63ed\\u9732</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"the audience probably doesn\\u2019t care as much about the detective story as it does about the resonant images and deep emotions\", \"color\": \"#C8E6C9\", \"startPos\": 6313, \"endPos\": 6437, \"beforeText\": \"teaches classes on \\u201cthe \\npsychology of healing.\\u201d \\n \\nKarsh refers to the question of who violated his wife\\u2019s body as a \\u201cclassic detection puzzle\\u201d \\nbut \", \"extractionText\": \"the audience probably doesn\\u2019t care as much about the detective story as it does about the \\nresonant images and deep emotions\", \"afterText\": \", which I felt most clearly in scenes with Diane Kruger as Becca \\nappearing nude and evermore disfigured in Karsh\\u2019s dreams. (She is emphatically not a\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89c0\\u773e\\u8208\\u8da3</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u89c0\\u773e\\u5c0d\\u5075\\u63a2\\u6545\\u4e8b\\u7684\\u95dc\\u5fc3\\u7a0b\\u5ea6\\u4e0d\\u5982\\u5f71\\u50cf\\u548c\\u60c5\\u611f</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"resonant images and deep emotions\", \"color\": \"#C8E6C9\", \"startPos\": 6404, \"endPos\": 6437, \"beforeText\": \"lated his wife\\u2019s body as a \\u201cclassic detection puzzle\\u201d \\nbut the audience probably doesn\\u2019t care as much about the detective story as it does about the \\n\", \"extractionText\": \"resonant images and deep emotions\", \"afterText\": \", which I felt most clearly in scenes with Diane Kruger as Becca \\nappearing nude and evermore disfigured in Karsh\\u2019s dreams. (She is emphatically not a\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u5f71\\u50cf\\u8207\\u60c5\\u611f</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u5171\\u9cf4\\u7684\\u5f71\\u50cf\\u548c\\u6df1\\u523b\\u7684\\u60c5\\u611f</span>}</div>\"}, {\"index\": 12, \"class\": \"opinion_statement\", \"text\": \"appearing nude and evermore disfigured\", \"color\": \"#C8E6C9\", \"startPos\": 6503, \"endPos\": 6541, \"beforeText\": \"ch about the detective story as it does about the \\nresonant images and deep emotions, which I felt most clearly in scenes with Diane Kruger as Becca \\n\", \"extractionText\": \"appearing nude and evermore disfigured\", \"afterText\": \" in Karsh\\u2019s dreams. (She is emphatically not a ghost.) \\nBecca\\u2019s absence/presence is also felt in scenes with Kruger as Becca\\u2019s twin Terry, and as the \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272\\u8868\\u73fe</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u88f8\\u9ad4\\u4e14\\u8d8a\\u4f86\\u8d8a\\u6b98\\u7f3a\\u7684\\u5f62\\u8c61</span>}</div>\"}, {\"index\": 13, \"class\": \"opinion_statement\", \"text\": \"the untrustworthy AI animated avatar, Hunny\", \"color\": \"#C8E6C9\", \"startPos\": 6701, \"endPos\": 6744, \"beforeText\": \"s dreams. (She is emphatically not a ghost.) \\nBecca\\u2019s absence/presence is also felt in scenes with Kruger as Becca\\u2019s twin Terry, and as the voice \\nof \", \"extractionText\": \"the untrustworthy AI animated avatar, Hunny\", \"afterText\": \". Cronenberg, of course, is interested in the \\nphysical effect of emotions as exemplified in the opening line of movie, spoken by Karsh\\u2019s dentist: \\n\\u201cG\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u4e0d\\u53ef\\u4fe1\\u7684AI\\u865b\\u64ec\\u5316\\u8eab</span>}</div>\"}, {\"index\": 14, \"class\": \"opinion_statement\", \"text\": \"Grief is rotting your teeth\", \"color\": \"#C8E6C9\", \"startPos\": 6893, \"endPos\": 6920, \"beforeText\": \"y. Cronenberg, of course, is interested in the \\nphysical effect of emotions as exemplified in the opening line of movie, spoken by Karsh\\u2019s dentist: \\n\\u201c\", \"extractionText\": \"Grief is rotting your teeth\", \"afterText\": \".\\u201d Relatedly, one source of the powerful emotion coursing through The \\nShrouds comes from Cronenberg\\u2019s self-recognition of his own mortality (a \\u201crelik\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u5c0d\\u767d</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u60b2\\u50b7\\u6b63\\u5728\\u4fb5\\u8755\\u4f60\\u7684\\u7259\\u9f52</span>}</div>\"}, {\"index\": 15, \"class\": \"opinion_statement\", \"text\": \"one source of the powerful emotion coursing through The Shrouds comes from Cronenberg\\u2019s self-recognition of his own mortality\", \"color\": \"#C8E6C9\", \"startPos\": 6934, \"endPos\": 7060, \"beforeText\": \"n the \\nphysical effect of emotions as exemplified in the opening line of movie, spoken by Karsh\\u2019s dentist: \\n\\u201cGrief is rotting your teeth.\\u201d Relatedly, \", \"extractionText\": \"one source of the powerful emotion coursing through The \\nShrouds comes from Cronenberg\\u2019s self-recognition of his own mortality\", \"afterText\": \" (a \\u201crelikh?!\\u201d). (As other \\nfilm critics have pointed out, several other films made in 2024 share this theme.2) \\nThe plot, the imagery, and the emotio\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u611f\\u4f86\\u6e90</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u5f37\\u70c8\\u60c5\\u611f\\u7684\\u4f86\\u6e90\\u662f\\u5c0e\\u6f14\\u5c0d\\u81ea\\u8eab\\u6b7b\\u4ea1\\u7684\\u8a8d\\u77e5</span>}</div>\"}, {\"index\": 16, \"class\": \"opinion_statement\", \"text\": \"The plot, the imagery, and the emotional themes of this film center on graves and bodies being desecrated\", \"color\": \"#C8E6C9\", \"startPos\": 7173, \"endPos\": 7279, \"beforeText\": \"self-recognition of his own mortality (a \\u201crelikh?!\\u201d). (As other \\nfilm critics have pointed out, several other films made in 2024 share this theme.2) \\n\", \"extractionText\": \"The plot, the imagery, and the emotional themes of this film center on graves and bodies \\nbeing desecrated\", \"afterText\": \"\\u2014and \\u201cdesecration\\u201d is a word that is notably used in this movie. \\u201cTo desecrate\\u201d \\nmeans to violate something sacred, and knowing this fact,  along with\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u7bc0\\u3001\\u5f71\\u50cf\\u548c\\u60c5\\u611f\\u4e3b\\u984c\\u570d\\u7e5e\\u8457\\u58b3\\u5893\\u548c\\u88ab\\u893b\\u7006\\u7684\\u8eab\\u9ad4</span>}</div>\"}, {\"index\": 17, \"class\": \"opinion_statement\", \"text\": \"The Shrouds stands as Cronenberg\\u2019s most Jewish film\", \"color\": \"#C8E6C9\", \"startPos\": 7502, \"endPos\": 7553, \"beforeText\": \"crate\\u201d \\nmeans to violate something sacred, and knowing this fact,  along with the film\\u2019s autobiographical \\nnature, it should come as no surprise that \", \"extractionText\": \"The Shrouds stands as Cronenberg\\u2019s most Jewish film\", \"afterText\": \". \\nTrue, Cronenberg does not deign to make his stand-in, Karsh, come from a secular Jewish \\nbackground, as Cronenberg himself does. Instead, Karsh tel\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u6587\\u5316\\u7279\\u6027</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u6700\\u5927\\u7684\\u7336\\u592a\\u96fb\\u5f71\\u7279\\u9ede</span>}</div>\"}, {\"index\": 18, \"class\": \"opinion_statement\", \"text\": \"Jewishness abounds\", \"color\": \"#C8E6C9\", \"startPos\": 7786, \"endPos\": 7804, \"beforeText\": \" Jewish \\nbackground, as Cronenberg himself does. Instead, Karsh tells his blind date, he is \\u201csome \\nBelarusian Eastern Orthodox thing.\\u201d But elsewhere, \", \"extractionText\": \"Jewishness abounds\", \"afterText\": \"\\u2014in the allusions to \\nJewish food (a way many secular Jews relate to their tradition), including Guy Pearce as tech nerd \\nMaury chowing down on Matzoh\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u6587\\u5316\\u7279\\u6027</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u7336\\u592a\\u6587\\u5316\\u5143\\u7d20\\u8c50\\u5bcc</span>}</div>\"}, {\"index\": 19, \"class\": \"opinion_statement\", \"text\": \"The Shrouds is the first to be set in Jewish Toronto\", \"color\": \"#C8E6C9\", \"startPos\": 8143, \"endPos\": 8195, \"beforeText\": \" to United Dairy and Fat \\nPasha, two actual Jewish-identified restaurants in Toronto. (Many of Cronenberg\\u2019s films are \\nexplicitly set in Toronto, but \", \"extractionText\": \"The Shrouds is the first to be set in Jewish Toronto\", \"afterText\": \".) As well,  Karsh \\n3\\nSiegler: The Shrouds\\nPublished by DigitalCommons@UNO, 2025\\n&quot;&quot;&quot;\\n\\n**Page 6**\\n&quot;&quot;&quot;\\ndeflects Terry\\u2019s conspiracy theorizing by referen\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u80cc\\u666f\\u8a2d\\u5b9a</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u9996\\u90e8\\u8a2d\\u5b9a\\u5728\\u7336\\u592a\\u4eba\\u591a\\u502b\\u591a\\u7684\\u96fb\\u5f71</span>}</div>\"}, {\"index\": 20, \"class\": \"opinion_statement\", \"text\": \"this is not a case of an aging artist \\u201cfinding God\\u201d or \\u201creturning to his roots.\\u201d\", \"color\": \"#C8E6C9\", \"startPos\": 8512, \"endPos\": 8592, \"beforeText\": \"anoid antisemitic dictum, \\n\\u201c(Jewish) doctors plot.\\u201d And most resonantly, we see Jewishness in the Hebrew letters carved on \\nBecca\\u2019s gravestone.  \\nBut \", \"extractionText\": \"this is not a case of an aging artist \\u201cfinding God\\u201d or \\u201creturning to his roots.\\u201d\", \"afterText\": \" If The \\nShrouds is Cronenberg\\u2019s most Jewish film it is also his most atheist. Cronenberg, in his public \\nstatements, has always been among the most a\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u4e26\\u975e\\u5c0b\\u6c42\\u5b97\\u6559\\u6170\\u85c9\\u6216\\u56de\\u6b78\\u50b3\\u7d71</span>}</div>\"}, {\"index\": 21, \"class\": \"opinion_statement\", \"text\": \"If The Shrouds is Cronenberg\\u2019s most Jewish film it is also his most atheist.\", \"color\": \"#C8E6C9\", \"startPos\": 8593, \"endPos\": 8670, \"beforeText\": \"ewishness in the Hebrew letters carved on \\nBecca\\u2019s gravestone.  \\nBut this is not a case of an aging artist \\u201cfinding God\\u201d or \\u201creturning to his roots.\\u201d \", \"extractionText\": \"If The \\nShrouds is Cronenberg\\u2019s most Jewish film it is also his most atheist.\", \"afterText\": \" Cronenberg, in his public \\nstatements, has always been among the most avowedly atheist filmmakers, but his characters were \\nnot. Until now. In the fi\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u6700\\u7336\\u592a\\u7684\\u96fb\\u5f71\\u4e5f\\u662f\\u6700\\u7121\\u795e\\u8ad6\\u7684\\u96fb\\u5f71</span>}</div>\"}, {\"index\": 22, \"class\": \"opinion_statement\", \"text\": \"his characters were not. Until now.\", \"color\": \"#C8E6C9\", \"startPos\": 8774, \"endPos\": 8810, \"beforeText\": \" most Jewish film it is also his most atheist. Cronenberg, in his public \\nstatements, has always been among the most avowedly atheist filmmakers, but \", \"extractionText\": \"his characters were \\nnot. Until now.\", \"afterText\": \" In the first sequence of the movie, Karsh refers to himself a \\u201cnon-observant atheist\\u201d \\nand calls the shroud of Turin a fake. Later, speculating his p\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272\\u5851\\u9020</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272\\u76f4\\u5230\\u73fe\\u5728\\u624d\\u5c55\\u73fe\\u7121\\u795e\\u8ad6\\u7279\\u8cea</span>}</div>\"}, {\"index\": 23, \"class\": \"opinion_statement\", \"text\": \"Karsh refers to himself a \\u201cnon-observant atheist\\u201d and calls the shroud of Turin a fake.\", \"color\": \"#C8E6C9\", \"startPos\": 8847, \"endPos\": 8935, \"beforeText\": \"\\nstatements, has always been among the most avowedly atheist filmmakers, but his characters were \\nnot. Until now. In the first sequence of the movie, \", \"extractionText\": \"Karsh refers to himself a \\u201cnon-observant atheist\\u201d \\nand calls the shroud of Turin a fake.\", \"afterText\": \" Later, speculating his private graveyard might have been \\nvandalized by religious extremists, he notes that \\u201cwe\\u2019ve been called techno-atheist infidel\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272\\u8a2d\\u5b9a</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u81ea\\u7a31\\u300c\\u4e0d\\u5b88\\u6212\\u7684\\u7121\\u795e\\u8ad6\\u8005\\u300d\\u4e26\\u7a31\\u88f9\\u5c4d\\u5e03\\u70ba\\u8d5d\\u54c1</span>}</div>\"}, {\"index\": 24, \"class\": \"opinion_statement\", \"text\": \"\\u201cwe\\u2019ve been called techno-atheist infidels.\\u201d\", \"color\": \"#C8E6C9\", \"startPos\": 9044, \"endPos\": 9088, \"beforeText\": \"t\\u201d \\nand calls the shroud of Turin a fake. Later, speculating his private graveyard might have been \\nvandalized by religious extremists, he notes that \", \"extractionText\": \"\\u201cwe\\u2019ve been called techno-atheist infidels.\\u201d\", \"afterText\": \" \\nIn some ways, The Shrouds embodies a very old debate between tradition and modernity \\nor religion and atheism, enacted at multiple levels, not least\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u89d2\\u8272\\u8a2d\\u5b9a</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u88ab\\u7a31\\u70ba\\u300c\\u79d1\\u6280\\u7121\\u795e\\u8ad6\\u7570\\u6559\\u5f92\\u300d</span>}</div>\"}, {\"index\": 25, \"class\": \"opinion_statement\", \"text\": \"The Shrouds embodies a very old debate between tradition and modernity or religion and atheism\", \"color\": \"#C8E6C9\", \"startPos\": 9104, \"endPos\": 9199, \"beforeText\": \" his private graveyard might have been \\nvandalized by religious extremists, he notes that \\u201cwe\\u2019ve been called techno-atheist infidels.\\u201d \\nIn some ways, \", \"extractionText\": \"The Shrouds embodies a very old debate between tradition and modernity \\nor religion and atheism\", \"afterText\": \", enacted at multiple levels, not least in a seemingly throwaway bit of \\ndialogue about the \\u201cburial versus cremation\\u201d debate: burial being necessary i\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u9ad4\\u73fe\\u50b3\\u7d71\\u8207\\u73fe\\u4ee3\\u3001\\u5b97\\u6559\\u8207\\u7121\\u795e\\u8ad6\\u7684\\u53e4\\u8001\\u8faf\\u8ad6</span>}</div>\"}, {\"index\": 26, \"class\": \"opinion_statement\", \"text\": \"burial being necessary in the Jewish tradition, while cremation being seen as more ecological and modern.\", \"color\": \"#C8E6C9\", \"startPos\": 9325, \"endPos\": 9431, \"beforeText\": \"\\nor religion and atheism, enacted at multiple levels, not least in a seemingly throwaway bit of \\ndialogue about the \\u201cburial versus cremation\\u201d debate: \", \"extractionText\": \"burial being necessary in the Jewish tradition, \\nwhile cremation being seen as more ecological and modern.\", \"afterText\": \" Cronenberg, wisely, does not presume \\nto settle this debate, but simply records how it plays out on an emotional level\\u2014through a powerful \\ndepiction \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u96fb\\u5f71\\u4e3b\\u984c</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u7336\\u592a\\u50b3\\u7d71\\u7684\\u57cb\\u846c\\u8207\\u66f4\\u74b0\\u4fdd\\u73fe\\u4ee3\\u7684\\u706b\\u846c\\u4e4b\\u9593\\u7684\\u5c0d\\u6bd4</span>}</div>\"}, {\"index\": 27, \"class\": \"opinion_statement\", \"text\": \"powerful depiction of grief\", \"color\": \"#C8E6C9\", \"startPos\": 9561, \"endPos\": 9589, \"beforeText\": \"ological and modern. Cronenberg, wisely, does not presume \\nto settle this debate, but simply records how it plays out on an emotional level\\u2014through a \", \"extractionText\": \"powerful \\ndepiction of grief\", \"afterText\": \", yes, but also of confusion and anger (at a medical establishment that robs us of \\nour power, among other indignities).  And finally, as shown in the\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u611f\\u8868\\u73fe</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u5f37\\u70c8\\u7684\\u60c5\\u611f\\u63cf\\u7e6a</span>}</div>\"}, {\"index\": 28, \"class\": \"opinion_statement\", \"text\": \"confusion and anger\", \"color\": \"#C8E6C9\", \"startPos\": 9608, \"endPos\": 9627, \"beforeText\": \"ot presume \\nto settle this debate, but simply records how it plays out on an emotional level\\u2014through a powerful \\ndepiction of grief, yes, but also of \", \"extractionText\": \"confusion and anger\", \"afterText\": \" (at a medical establishment that robs us of \\nour power, among other indignities).  And finally, as shown in the last scene of Karsh flying across \\nth\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u60c5\\u611f\\u8868\\u73fe</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">\\u56f0\\u60d1\\u8207\\u61a4\\u6012</span>}</div>\"}, {\"index\": 29, \"class\": \"audience_impact\", \"text\": \"a glimmer of hopefulness towards whatever comes next\", \"color\": \"#D2E3FC\", \"startPos\": 9823, \"endPos\": 9876, \"beforeText\": \"our power, among other indignities).  And finally, as shown in the last scene of Karsh flying across \\nthe ocean towards an uncertain future, there is \", \"extractionText\": \"a glimmer of hopefulness towards whatever comes \\nnext\", \"afterText\": \". \\n \\n \\n1 Or Dangling subplots and antagonists referred to but never seen, which point to the fact that The Shrouds was written \\nto be the pilot for a \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">\\u5e0c\\u671b</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">\\u6700\\u5f8c\\u4e00\\u5e55\\u5361\\u8a31\\u98db\\u8d8a\\u6d77\\u6d0b\\u5954\\u5411\\u672a\\u77e5\\u672a\\u4f86</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">\\u89c0\\u773e</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"HTML 互動式視覺化（包含已擷取屬性）\")\n",
    "\n",
    "html_content_shrouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  改進總結\n",
    "\n",
    "這次的代碼改進主要圍繞提升 langextract 的資訊擷取品質。系統在運作時會多次通過進行提取，總共進行五次，每次都能補上前一輪可能遺漏的實體。這種方法讓模型對長篇文本或具有重疊、隱含意涵的內容理解得更完整、更細膩。同時，上下文窗口也被重新調整為1500字元的小批次設定，使模型聚焦的範圍更清晰，有助於減少長文本中不必要的噪聲干擾，並讓屬性識別更一致。\n",
    "\n",
    "在隨機性方面，temperature 設定為0.5，讓模型輸出的結果在多輪提取間保留適度的變化，不會過於死板，也避免完全確定性提取所帶來的侷限。這使得模型能探索多樣化的語言表達，從中發現不同層次的語意。此外，提示詞的設計也經過強化，加入了明確的邊界條件與驗證標準，並提供豐富的元素類型說明與具體範例，讓模型在執行時有更清楚的方向。\n",
    "\n",
    "這些改進預期能有效提升實體的召回率與屬性分類的準確性，同時降低無根據的幻覺式提取。更重要的是，透過更精緻的提示設計，模型在處理中文文本時的理解力也明顯提升，能更忠實地反映原始語境中的信息。\n",
    "\n",
    "### Improvement Summary\n",
    "\n",
    "The main code improvements focus on enhancing the information extraction quality of `langextract`. The system performs extraction multiple times during operation, a total of five times, each time filling in any entities missed in the previous round. This method allows the model to understand long texts or content with overlapping or implicit meanings more completely and nuancedly. Simultaneously, the context window has been readjusted to a batch size of 1500 characters, making the model's focus clearer, helping to reduce unnecessary noise interference in long texts, and ensuring more consistent attribute recognition.\n",
    "\n",
    "Regarding randomness, the temperature is set to 0.5, allowing the model's output to retain moderate variation across multiple extraction rounds, avoiding rigidity and the limitations of completely deterministic extraction. This enables the model to explore diverse linguistic expressions and discover different levels of semantics. Furthermore, the design of the prompt words has been strengthened, incorporating clear boundary conditions and validation criteria, and providing rich element type descriptions and specific examples, giving the model a clearer direction during execution.\n",
    "\n",
    "These improvements are expected to effectively increase entity recall and attribute classification accuracy, while reducing unfounded, illusory extraction. More importantly, through more sophisticated cue design, the model's understanding of Chinese text is also significantly improved, enabling it to more faithfully reflect information from the original context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**\n",
    "\n",
    "---\n",
    "\n",
    "### <a id='toc1_5_8_'></a>[**2.4 產生 LLM 嵌入:**](#toc0_)\n",
    "\n",
    "LLM 嵌入是稠密的數值向量，用來表示文字的語意。它們由大型語言模型生成，將單字、短語或文件映射到高維空間，其中相似的概念緊密排列。\n",
    "\n",
    "它們的主要優勢包括：\n",
    "\n",
    "* **上下文理解**：與舊方法不同，LLM 嵌入具有上下文感知能力。例如，**“bank”** 一詞的向量會根據其在“河岸”或“銀行”等上下文中的使用情況而有所不同，從而提供更細緻的語言表示。\n",
    "\n",
    "* **預訓練帶來的通用性**：它們在海量文字資料上進行預訓練。這使得它們能夠有效地泛化到各種任務中，例如分類、聚類和相似性檢測。它們不需要大量的重新訓練。\n",
    "\n",
    "<span style=\"color:green\">本節練習無需重新運行單元格，您可以使用先前儲存到對應目錄的資料。 </span>\n",
    "\n",
    "**現在讓我們使用 Gemini 為資料集樣本產生一些嵌入：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# 定義一個函式來使用 Gemini 取得嵌入向量\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 每分鐘 100 個請求限制 -> 60 秒 / 100 = 0.6 秒每個請求\n",
    "        # 緩衝時間以避免速率限制\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # 在下一次嘗試前等待 5 秒\n",
    "        return get_gemini_embedding(text, model) # 重試請求\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從訓練集中取樣 160 行...\n",
      "從測試集中取樣 40 行...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從訓練集中取樣 160 行...\n",
      "從測試集中取樣 40 行...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ego\\AppData\\Local\\Temp\\ipykernel_2112\\3725657787.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "C:\\Users\\Ego\\AppData\\Local\\Temp\\ipykernel_2112\\3725657787.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# 使用 text 列\n",
    "column_name = 'text'\n",
    "\n",
    "# 此函數用於從數據中獲取分層樣本，意思是樣本中標籤的分佈與完整數據集相同\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # 如果請求的樣本數大於或等於原數據，則返回副本\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # 調整舍入誤差以獲得精確的樣本數量\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# 獲得嵌入向量後，我們需要將 Gemini 型別 ContentDict 的嵌入向量轉換為簡單的列表\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>10212</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.0030290622, -0.0038081533, -0.0129...</td>\n",
       "      <td>[-0.0030290622, -0.0038081533, -0.012903593, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>10759</td>\n",
       "      <td>The best revenge is massive success.</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.016899575, 0.03089228, -0.00723776...</td>\n",
       "      <td>[-0.016899575, 0.03089228, -0.0072377664, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>10149</td>\n",
       "      <td>@tmz @HarveyLevinTMZ   Hell hath no fury like ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.011492854, 0.011966667, 0.01260561...</td>\n",
       "      <td>[-0.011492854, 0.011966667, 0.012605619, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>10801</td>\n",
       "      <td>Happiness is the best revenge</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.017537752, 0.019897602, -0.0248565...</td>\n",
       "      <td>[-0.017537752, 0.019897602, -0.024856506, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>10746</td>\n",
       "      <td>@MHChat sadness with resentment is the past, s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.172</td>\n",
       "      <td>[values=[-0.021047214, 0.02634717, -0.00085264...</td>\n",
       "      <td>[-0.021047214, 0.02634717, -0.0008526414, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>40314</td>\n",
       "      <td>It's so gloomy outside. I wish it was as cold ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[values=[-0.008289891, -0.0023099117, -0.01002...</td>\n",
       "      <td>[-0.008289891, -0.0023099117, -0.010024281, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>40273</td>\n",
       "      <td>@DoubleEph sadly his best days are behind him</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[-0.021479027, 0.014687131, 0.00468906...</td>\n",
       "      <td>[-0.021479027, 0.014687131, 0.0046890634, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>40061</td>\n",
       "      <td>My prayers are with the family, friends &amp;amp; ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[values=[-0.020616427, 0.006237613, 0.02053720...</td>\n",
       "      <td>[-0.020616427, 0.006237613, 0.020537207, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>40703</td>\n",
       "      <td>@petercoffin So safe blues are ok. Are reds ok...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.263</td>\n",
       "      <td>[values=[-0.005815683, -0.0030533646, 0.011030...</td>\n",
       "      <td>[-0.005815683, -0.0030533646, 0.011030354, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>40342</td>\n",
       "      <td>@SWP_Roads   How dull.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.015553457, 0.007396239, -0.0063307...</td>\n",
       "      <td>[-0.015553457, 0.007396239, -0.0063307034, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "212   10212  Don't join @BTCare they put the phone down on ...    anger   \n",
       "759   10759               The best revenge is massive success.    anger   \n",
       "149   10149  @tmz @HarveyLevinTMZ   Hell hath no fury like ...    anger   \n",
       "801   10801                      Happiness is the best revenge    anger   \n",
       "746   10746  @MHChat sadness with resentment is the past, s...    anger   \n",
       "...     ...                                                ...      ...   \n",
       "3141  40314  It's so gloomy outside. I wish it was as cold ...  sadness   \n",
       "3100  40273      @DoubleEph sadly his best days are behind him  sadness   \n",
       "2888  40061  My prayers are with the family, friends &amp; ...  sadness   \n",
       "3530  40703  @petercoffin So safe blues are ok. Are reds ok...  sadness   \n",
       "3169  40342                             @SWP_Roads   How dull.  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "212       0.604  [values=[-0.0030290622, -0.0038081533, -0.0129...   \n",
       "759       0.312  [values=[-0.016899575, 0.03089228, -0.00723776...   \n",
       "149       0.667  [values=[-0.011492854, 0.011966667, 0.01260561...   \n",
       "801       0.250  [values=[-0.017537752, 0.019897602, -0.0248565...   \n",
       "746       0.172  [values=[-0.021047214, 0.02634717, -0.00085264...   \n",
       "...         ...                                                ...   \n",
       "3141      0.542  [values=[-0.008289891, -0.0023099117, -0.01002...   \n",
       "3100      0.583  [values=[-0.021479027, 0.014687131, 0.00468906...   \n",
       "2888      0.771  [values=[-0.020616427, 0.006237613, 0.02053720...   \n",
       "3530      0.263  [values=[-0.005815683, -0.0030533646, 0.011030...   \n",
       "3169      0.521  [values=[-0.015553457, 0.007396239, -0.0063307...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "212   [-0.0030290622, -0.0038081533, -0.012903593, -...  \n",
       "759   [-0.016899575, 0.03089228, -0.0072377664, -0.0...  \n",
       "149   [-0.011492854, 0.011966667, 0.012605619, -0.04...  \n",
       "801   [-0.017537752, 0.019897602, -0.024856506, -0.0...  \n",
       "746   [-0.021047214, 0.02634717, -0.0008526414, -0.0...  \n",
       "...                                                 ...  \n",
       "3141  [-0.008289891, -0.0023099117, -0.010024281, -0...  \n",
       "3100  [-0.021479027, 0.014687131, 0.0046890634, -0.0...  \n",
       "2888  [-0.020616427, 0.006237613, 0.020537207, -0.07...  \n",
       "3530  [-0.005815683, -0.0030533646, 0.011030354, -0....  \n",
       "3169  [-0.015553457, 0.007396239, -0.0063307034, -0....  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>30882</td>\n",
       "      <td>@chencouture LMAO Is it that 'so slutty' hater...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[-0.013635297, 0.0371389, -0.013098068...</td>\n",
       "      <td>[-0.013635297, 0.0371389, -0.013098068, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>21250</td>\n",
       "      <td>Gahh...BT, in queue for 30 minutes.. Now put t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.01016047, -0.0009026696, -0.005212...</td>\n",
       "      <td>[-0.01016047, -0.0009026696, -0.005212877, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10898</td>\n",
       "      <td>Realest ever, relentless ever, inevitable that...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.415</td>\n",
       "      <td>[values=[-0.014525433, 0.01642175, 0.010939563...</td>\n",
       "      <td>[-0.014525433, 0.01642175, 0.010939563, -0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>30840</td>\n",
       "      <td>4-2 Canada final tomorrow #WCH #Predictions #o...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.420</td>\n",
       "      <td>[values=[-0.0010455328, -0.00046624144, 0.0303...</td>\n",
       "      <td>[-0.0010455328, -0.00046624144, 0.030387564, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10910</td>\n",
       "      <td>Having a baby born too soon is #lifechanging 6...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[-0.025528934, -0.0049635707, -0.01072...</td>\n",
       "      <td>[-0.025528934, -0.0049635707, -0.010728385, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>40821</td>\n",
       "      <td>It feel like we lost a family member🙄😂</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.023792284, 0.020631481, 0.01033705...</td>\n",
       "      <td>[-0.023792284, 0.020631481, 0.010337058, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>21219</td>\n",
       "      <td>About 7 weeks till I can pick up my camera aga...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.02468868, -0.015727378, -0.0265125...</td>\n",
       "      <td>[-0.02468868, -0.015727378, -0.026512522, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>40822</td>\n",
       "      <td>My life went from happy to unhappy..</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[values=[-0.007869418, 0.007860475, -0.0133514...</td>\n",
       "      <td>[-0.007869418, 0.007860475, -0.013351487, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>30824</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[-0.029558752, 0.020164862, 0.02368624...</td>\n",
       "      <td>[-0.029558752, 0.020164862, 0.023686247, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>10913</td>\n",
       "      <td>@fluffysoftlouis no no. I insist that you give...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[values=[-0.005988847, 0.028879639, -0.0112791...</td>\n",
       "      <td>[-0.005988847, 0.028879639, -0.011279167, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>30891</td>\n",
       "      <td>Our tone of voice: we're like One Direction, w...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.423</td>\n",
       "      <td>[values=[-0.0062988065, -0.03233735, -0.011615...</td>\n",
       "      <td>[-0.0062988065, -0.03233735, -0.011615458, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>21254</td>\n",
       "      <td>An adviser to the #European #Union’s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0056551304, 0.0062780394, 0.010923...</td>\n",
       "      <td>[-0.0056551304, 0.0062780394, 0.010923652, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>21225</td>\n",
       "      <td>The moment you bring her to meet your best fri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[values=[-0.047124993, -0.004152473, -0.005977...</td>\n",
       "      <td>[-0.047124993, -0.004152473, -0.0059770048, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10918</td>\n",
       "      <td>Eat my ass' is no longer an insult</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[-0.004609678, 0.031817257, -0.0051811...</td>\n",
       "      <td>[-0.004609678, 0.031817257, -0.005181141, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>21232</td>\n",
       "      <td>@mikefreemanNFL \\nIsn't OBrien supposed to be ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0012154158, -0.010159548, 0.010861...</td>\n",
       "      <td>[-0.0012154158, -0.010159548, 0.010861144, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>40801</td>\n",
       "      <td>@OHSOVICTORIOUS_ @FaZeAdapt We all seen it com...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[-0.018142981, -0.008592042, -0.038903...</td>\n",
       "      <td>[-0.018142981, -0.008592042, -0.038903773, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>21253</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[values=[-0.024835743, 0.00060396525, 0.009073...</td>\n",
       "      <td>[-0.024835743, 0.00060396525, 0.009073344, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>40843</td>\n",
       "      <td>amateur author Twitter might be the most depre...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[-0.003928423, -0.007853031, -0.002806...</td>\n",
       "      <td>[-0.003928423, -0.007853031, -0.0028062053, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>40842</td>\n",
       "      <td>Don't be disheartened if you didn't get the ca...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.014799686, 0.026640678, -0.00012501...</td>\n",
       "      <td>[0.014799686, 0.026640678, -0.00012501857, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10876</td>\n",
       "      <td>Hate when guys cant control their anger 🙃🙃</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[0.00510301, -0.023113215, -0.00640006...</td>\n",
       "      <td>[0.00510301, -0.023113215, -0.0064000674, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>30860</td>\n",
       "      <td>@len_snart Mick nods. 'I would like that.' He ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.620</td>\n",
       "      <td>[values=[0.007279358, -0.014534431, -0.0003606...</td>\n",
       "      <td>[0.007279358, -0.014534431, -0.00036064742, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "      <td>[values=[0.0058806627, -0.008656773, -0.039033...</td>\n",
       "      <td>[0.0058806627, -0.008656773, -0.039033048, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>21182</td>\n",
       "      <td>@BuzzFeed so this houses will get into my inst...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[0.009150241, -0.017897055, 0.00885419...</td>\n",
       "      <td>[0.009150241, -0.017897055, 0.008854199, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10897</td>\n",
       "      <td>Might just leave and aggravate bae</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.010166713, 0.0014822743, -0.011168...</td>\n",
       "      <td>[-0.010166713, 0.0014822743, -0.0111685805, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>30861</td>\n",
       "      <td>@yungdoujin wouldn't that basically be sparkli...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.320</td>\n",
       "      <td>[values=[0.03212864, 0.018269602, 0.005003729,...</td>\n",
       "      <td>[0.03212864, 0.018269602, 0.005003729, -0.1061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>21194</td>\n",
       "      <td>also i had an awful nightmare involving being ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[values=[0.009203733, -0.017150467, -0.0084802...</td>\n",
       "      <td>[0.009203733, -0.017150467, -0.008480225, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10916</td>\n",
       "      <td>Note to self ~ Stop laughing at things that of...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[values=[-0.010816357, -0.012566608, -0.023107...</td>\n",
       "      <td>[-0.010816357, -0.012566608, -0.023107173, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>30869</td>\n",
       "      <td>Chris would take full responsibility and would...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.280</td>\n",
       "      <td>[values=[0.006588017, -0.006120494, 0.00766196...</td>\n",
       "      <td>[0.006588017, -0.006120494, 0.007661961, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>40802</td>\n",
       "      <td>[ @HedgehogDylan ] *she would frown a bit, fol...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[values=[-0.015942886, 0.0062166224, -0.009731...</td>\n",
       "      <td>[-0.015942886, 0.0062166224, -0.009731274, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10933</td>\n",
       "      <td>(Sam) Brown's Law: Never offend people with st...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.017159522, -0.0068402686, -0.008005...</td>\n",
       "      <td>[0.017159522, -0.0068402686, -0.008005174, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>40835</td>\n",
       "      <td>@Eeevah14 don't I know it, try not to fret my ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.017147837, 0.010600609, -0.00488683...</td>\n",
       "      <td>[0.017147837, 0.010600609, -0.0048868353, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>30897</td>\n",
       "      <td>It feels good to get outside for a minute and ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[values=[-0.019597428, -0.012538523, -0.003372...</td>\n",
       "      <td>[-0.019597428, -0.012538523, -0.0033721798, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>40797</td>\n",
       "      <td>Wow just watched Me Before You and it was seri...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.016169224, -0.0027164714, -0.00830...</td>\n",
       "      <td>[-0.016169224, -0.0027164714, -0.008305452, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>21186</td>\n",
       "      <td>On @Varneyco/@FoxBusiness to talk latest on #C...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.039580334, -0.0056183864, -0.00678...</td>\n",
       "      <td>[-0.039580334, -0.0056183864, -0.0067838775, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>21216</td>\n",
       "      <td>When you're scared to press send #bgoodthepoet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.730</td>\n",
       "      <td>[values=[-0.004717332, -0.012867077, 0.0052951...</td>\n",
       "      <td>[-0.004717332, -0.012867077, 0.005295124, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21230</td>\n",
       "      <td>It really is amazing the money they give to so...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.246</td>\n",
       "      <td>[values=[-0.04023646, -0.0033757573, -0.015112...</td>\n",
       "      <td>[-0.04023646, -0.0033757573, -0.015112562, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>21206</td>\n",
       "      <td>Dunno y am going to the Yorkshire scare ground...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[values=[-0.008968516, -0.04955138, 0.00320910...</td>\n",
       "      <td>[-0.008968516, -0.04955138, 0.0032091022, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10880</td>\n",
       "      <td>@TrueAggieFan oh so that's where Brian was! Wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.037104376, -0.016576506, -0.019182...</td>\n",
       "      <td>[-0.037104376, -0.016576506, -0.019182565, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>21249</td>\n",
       "      <td>@CesarSampao @thisisbolton don't get me starte...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.011186042, -0.0003873956, 0.004387...</td>\n",
       "      <td>[-0.011186042, -0.0003873956, 0.004387479, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>30873</td>\n",
       "      <td>If yiu don't respond .o an email within 7 days...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.220</td>\n",
       "      <td>[values=[-0.012219579, 0.02326391, -0.00424283...</td>\n",
       "      <td>[-0.012219579, 0.02326391, -0.0042428398, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "253  30882  @chencouture LMAO Is it that 'so slutty' hater...      joy   \n",
       "187  21250  Gahh...BT, in queue for 30 minutes.. Now put t...     fear   \n",
       "41   10898  Realest ever, relentless ever, inevitable that...    anger   \n",
       "211  30840  4-2 Canada final tomorrow #WCH #Predictions #o...      joy   \n",
       "53   10910  Having a baby born too soon is #lifechanging 6...    anger   \n",
       "308  40821             It feel like we lost a family member🙄😂  sadness   \n",
       "156  21219  About 7 weeks till I can pick up my camera aga...     fear   \n",
       "309  40822               My life went from happy to unhappy..  sadness   \n",
       "195  30824  Nawaz Sharif is getting more funnier than @kap...      joy   \n",
       "56   10913  @fluffysoftlouis no no. I insist that you give...    anger   \n",
       "262  30891  Our tone of voice: we're like One Direction, w...      joy   \n",
       "191  21254  An adviser to the #European #Union’s top #cour...     fear   \n",
       "162  21225  The moment you bring her to meet your best fri...     fear   \n",
       "61   10918                 Eat my ass' is no longer an insult    anger   \n",
       "169  21232  @mikefreemanNFL \\nIsn't OBrien supposed to be ...     fear   \n",
       "288  40801  @OHSOVICTORIOUS_ @FaZeAdapt We all seen it com...  sadness   \n",
       "190  21253  Staff on @ryainair FR1005. Asked for info and ...     fear   \n",
       "330  40843  amateur author Twitter might be the most depre...  sadness   \n",
       "329  40842  Don't be disheartened if you didn't get the ca...  sadness   \n",
       "19   10876         Hate when guys cant control their anger 🙃🙃    anger   \n",
       "231  30860  @len_snart Mick nods. 'I would like that.' He ...      joy   \n",
       "82   10939  Just watched Django Unchained, Other people ma...    anger   \n",
       "119  21182  @BuzzFeed so this houses will get into my inst...     fear   \n",
       "40   10897                 Might just leave and aggravate bae    anger   \n",
       "232  30861  @yungdoujin wouldn't that basically be sparkli...      joy   \n",
       "131  21194  also i had an awful nightmare involving being ...     fear   \n",
       "59   10916  Note to self ~ Stop laughing at things that of...    anger   \n",
       "240  30869  Chris would take full responsibility and would...      joy   \n",
       "289  40802  [ @HedgehogDylan ] *she would frown a bit, fol...  sadness   \n",
       "76   10933  (Sam) Brown's Law: Never offend people with st...    anger   \n",
       "322  40835  @Eeevah14 don't I know it, try not to fret my ...  sadness   \n",
       "268  30897  It feels good to get outside for a minute and ...      joy   \n",
       "284  40797  Wow just watched Me Before You and it was seri...  sadness   \n",
       "123  21186  On @Varneyco/@FoxBusiness to talk latest on #C...     fear   \n",
       "153  21216  When you're scared to press send #bgoodthepoet...     fear   \n",
       "167  21230  It really is amazing the money they give to so...     fear   \n",
       "143  21206  Dunno y am going to the Yorkshire scare ground...     fear   \n",
       "23   10880  @TrueAggieFan oh so that's where Brian was! Wh...    anger   \n",
       "186  21249  @CesarSampao @thisisbolton don't get me starte...     fear   \n",
       "244  30873  If yiu don't respond .o an email within 7 days...      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "253      0.700  [values=[-0.013635297, 0.0371389, -0.013098068...   \n",
       "187      0.500  [values=[-0.01016047, -0.0009026696, -0.005212...   \n",
       "41       0.415  [values=[-0.014525433, 0.01642175, 0.010939563...   \n",
       "211      0.420  [values=[-0.0010455328, -0.00046624144, 0.0303...   \n",
       "53       0.375  [values=[-0.025528934, -0.0049635707, -0.01072...   \n",
       "308      0.708  [values=[-0.023792284, 0.020631481, 0.01033705...   \n",
       "156      0.312  [values=[-0.02468868, -0.015727378, -0.0265125...   \n",
       "309      0.812  [values=[-0.007869418, 0.007860475, -0.0133514...   \n",
       "195      0.700  [values=[-0.029558752, 0.020164862, 0.02368624...   \n",
       "56       0.562  [values=[-0.005988847, 0.028879639, -0.0112791...   \n",
       "262      0.423  [values=[-0.0062988065, -0.03233735, -0.011615...   \n",
       "191      0.500  [values=[-0.0056551304, 0.0062780394, 0.010923...   \n",
       "162      0.771  [values=[-0.047124993, -0.004152473, -0.005977...   \n",
       "61       0.438  [values=[-0.004609678, 0.031817257, -0.0051811...   \n",
       "169      0.479  [values=[-0.0012154158, -0.010159548, 0.010861...   \n",
       "288      0.354  [values=[-0.018142981, -0.008592042, -0.038903...   \n",
       "190      0.271  [values=[-0.024835743, 0.00060396525, 0.009073...   \n",
       "330      0.688  [values=[-0.003928423, -0.007853031, -0.002806...   \n",
       "329      0.438  [values=[0.014799686, 0.026640678, -0.00012501...   \n",
       "19       0.646  [values=[0.00510301, -0.023113215, -0.00640006...   \n",
       "231      0.620  [values=[0.007279358, -0.014534431, -0.0003606...   \n",
       "82       0.229  [values=[0.0058806627, -0.008656773, -0.039033...   \n",
       "119      0.700  [values=[0.009150241, -0.017897055, 0.00885419...   \n",
       "40       0.417  [values=[-0.010166713, 0.0014822743, -0.011168...   \n",
       "232      0.320  [values=[0.03212864, 0.018269602, 0.005003729,...   \n",
       "131      0.896  [values=[0.009203733, -0.017150467, -0.0084802...   \n",
       "59       0.542  [values=[-0.010816357, -0.012566608, -0.023107...   \n",
       "240      0.280  [values=[0.006588017, -0.006120494, 0.00766196...   \n",
       "289      0.562  [values=[-0.015942886, 0.0062166224, -0.009731...   \n",
       "76       0.333  [values=[0.017159522, -0.0068402686, -0.008005...   \n",
       "322      0.333  [values=[0.017147837, 0.010600609, -0.00488683...   \n",
       "268      0.580  [values=[-0.019597428, -0.012538523, -0.003372...   \n",
       "284      0.667  [values=[-0.016169224, -0.0027164714, -0.00830...   \n",
       "123      0.604  [values=[-0.039580334, -0.0056183864, -0.00678...   \n",
       "153      0.730  [values=[-0.004717332, -0.012867077, 0.0052951...   \n",
       "167      0.246  [values=[-0.04023646, -0.0033757573, -0.015112...   \n",
       "143      0.812  [values=[-0.008968516, -0.04955138, 0.00320910...   \n",
       "23       0.417  [values=[-0.037104376, -0.016576506, -0.019182...   \n",
       "186      0.458  [values=[-0.011186042, -0.0003873956, 0.004387...   \n",
       "244      0.220  [values=[-0.012219579, 0.02326391, -0.00424283...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "253  [-0.013635297, 0.0371389, -0.013098068, -0.062...  \n",
       "187  [-0.01016047, -0.0009026696, -0.005212877, -0....  \n",
       "41   [-0.014525433, 0.01642175, 0.010939563, -0.071...  \n",
       "211  [-0.0010455328, -0.00046624144, 0.030387564, -...  \n",
       "53   [-0.025528934, -0.0049635707, -0.010728385, -0...  \n",
       "308  [-0.023792284, 0.020631481, 0.010337058, -0.06...  \n",
       "156  [-0.02468868, -0.015727378, -0.026512522, -0.0...  \n",
       "309  [-0.007869418, 0.007860475, -0.013351487, -0.0...  \n",
       "195  [-0.029558752, 0.020164862, 0.023686247, -0.08...  \n",
       "56   [-0.005988847, 0.028879639, -0.011279167, -0.0...  \n",
       "262  [-0.0062988065, -0.03233735, -0.011615458, -0....  \n",
       "191  [-0.0056551304, 0.0062780394, 0.010923652, -0....  \n",
       "162  [-0.047124993, -0.004152473, -0.0059770048, -0...  \n",
       "61   [-0.004609678, 0.031817257, -0.005181141, -0.0...  \n",
       "169  [-0.0012154158, -0.010159548, 0.010861144, -0....  \n",
       "288  [-0.018142981, -0.008592042, -0.038903773, -0....  \n",
       "190  [-0.024835743, 0.00060396525, 0.009073344, -0....  \n",
       "330  [-0.003928423, -0.007853031, -0.0028062053, -0...  \n",
       "329  [0.014799686, 0.026640678, -0.00012501857, -0....  \n",
       "19   [0.00510301, -0.023113215, -0.0064000674, -0.0...  \n",
       "231  [0.007279358, -0.014534431, -0.00036064742, -0...  \n",
       "82   [0.0058806627, -0.008656773, -0.039033048, -0....  \n",
       "119  [0.009150241, -0.017897055, 0.008854199, -0.05...  \n",
       "40   [-0.010166713, 0.0014822743, -0.0111685805, -0...  \n",
       "232  [0.03212864, 0.018269602, 0.005003729, -0.1061...  \n",
       "131  [0.009203733, -0.017150467, -0.008480225, -0.0...  \n",
       "59   [-0.010816357, -0.012566608, -0.023107173, -0....  \n",
       "240  [0.006588017, -0.006120494, 0.007661961, -0.06...  \n",
       "289  [-0.015942886, 0.0062166224, -0.009731274, -0....  \n",
       "76   [0.017159522, -0.0068402686, -0.008005174, -0....  \n",
       "322  [0.017147837, 0.010600609, -0.0048868353, -0.0...  \n",
       "268  [-0.019597428, -0.012538523, -0.0033721798, -0...  \n",
       "284  [-0.016169224, -0.0027164714, -0.008305452, -0...  \n",
       "123  [-0.039580334, -0.0056183864, -0.0067838775, -...  \n",
       "153  [-0.004717332, -0.012867077, 0.005295124, -0.0...  \n",
       "167  [-0.04023646, -0.0033757573, -0.015112562, -0....  \n",
       "143  [-0.008968516, -0.04955138, 0.0032091022, -0.0...  \n",
       "23   [-0.037104376, -0.016576506, -0.019182565, -0....  \n",
       "186  [-0.011186042, -0.0003873956, 0.004387479, -0....  \n",
       "244  [-0.012219579, 0.02326391, -0.0042428398, -0.0...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將其保存到 pickle 檔案\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 載入 pickle 檔案\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini 嵌入向量維度是 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! ",
           0.604
          ],
          [
           "The best revenge is massive success.",
           0.312
          ],
          [
           "@tmz @HarveyLevinTMZ   Hell hath no fury like a women scorned.    It's the affair.  Not the parenting",
           0.667
          ],
          [
           "Happiness is the best revenge",
           0.25
          ],
          [
           "@MHChat sadness with resentment is the past, sadness with fear is the future. try to live in the now #MHchat",
           0.172
          ],
          [
           "it makes me so fucking irate jesus. nobody is calling ppl who like hajime abusive stop with the strawmen lmao",
           0.75
          ],
          [
           "Inner conflict happens when we are at odds with ourselves. Honor your values and priorities.  #innerconflict #conflict #values",
           0.5
          ],
          [
           "Projection is perception. See it in someone else? You also at some level have that within you. #anger #worry",
           0.417
          ],
          [
           "@XemitSellsMagic add tracking but resent them",
           0.688
          ],
          [
           "@healeyraine I'm offended, I actually am",
           0.479
          ],
          [
           "I'm about to block everyone everywhere posting about the storm. I think everyone is aware of the damn rain and what not so quit. #damn #rage",
           0.708
          ],
          [
           "Like if you aggravate me constantly, byeeeeeeee",
           0.562
          ],
          [
           "I think they may be ",
           0.229
          ],
          [
           "@PrincessCasGirl @DaddyEllis__ tiff you better hurry cause 👀",
           0.458
          ],
          [
           "So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted ",
           0.896
          ],
          [
           "I get so angry at people that don't know that you don't have a stop sign on Francis and you do at Foster #road ",
           0.792
          ],
          [
           "Take public opinion on revenge with Pakistan if govt is unable to decide. @aajtak @TimesNow @narendramodi",
           0.458
          ],
          [
           "You a fuck boy if you run drag routes back to back in madden",
           0.646
          ],
          [
           "@HebertofNH any time a man who got paid to throw temper tantrums speaks up, you gotta listen.",
           0.521
          ],
          [
           "I don't talk about politics because people nowadays get offended easily!",
           0.479
          ],
          [
           "I mean I'm not done watching the pilot, but it's nice to see a group of actors perform without story lines dripping relentless nihilism.",
           0.458
          ],
          [
           "As your own lives in order to complete our amazing life journey successfully, it is there. ",
           0.357
          ],
          [
           "I blame the whole season on Natalie! The season would have been so different had she not turned her back on her alliance! #pissed ",
           0.792
          ],
          [
           "Wont use using @mothercareuk @Mothercarehelp again!! These guys cant get nothing right!! #fuming",
           0.854
          ],
          [
           "if we let that in id be fuming poor keeping",
           0.562
          ],
          [
           "@brian5or6 turn that shit off!   Home Button under Accessibility. \\n\\nWhen did innovation become mind fuckery? . #iphonePhoneHome",
           0.688
          ],
          [
           "@CI  I don't think Monalisa has respect for anyone but herself! I think she'll ruffle a few feathers. #TheJail",
           0.625
          ],
          [
           "Fake people irritate me",
           0.562
          ],
          [
           "remember when that guy got #angry that i kept saying gary sanchez was the best baseball player in the world... lmao",
           0.417
          ],
          [
           "@jaybusbee Well, not Archie. No offense but he's kinda old.",
           0.396
          ],
          [
           "@coltonflurry @StrangeFacesLA I cancelled by CBS all access live feeds before JC even said Vic won AFP. Paul.should have won IMO #bitter",
           0.517
          ],
          [
           "Why does @dapperlaughs have to come to Glasgow on a night I am working. I am fucking gutted, been waiting for an appearance for ages #raging",
           0.938
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Delete this shit Josh just screenshotted my snap me",
           0.583
          ],
          [
           "British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!",
           0.479
          ],
          [
           "@ezlisteningdisc it doesn't offend me but it's just,,, Weird.",
           0.188
          ],
          [
           "Well @AprilDRyan Trump's rabid base needs 2 hear this &amp; U can always find an overseer like King to say it.\\n@JoyAnnReid @SMShow @frangeladuo",
           0.458
          ],
          [
           "@JBCrewdotcom how his own fans insult him",
           0.417
          ],
          [
           "Realest ever, relentless ever, inevitable that I win.",
           0.415
          ],
          [
           "Having a baby born too soon is #lifechanging 6 years on and it feels like only yesterday #sad #happy #angry #emotionalrollercoaster",
           0.375
          ],
          [
           "@fluffysoftlouis no no. I insist that you give me your best insult first",
           0.562
          ],
          [
           "Eat my ass' is no longer an insult",
           0.438
          ],
          [
           "Hate when guys cant control their anger 🙃🙃",
           0.646
          ],
          [
           "Just watched Django Unchained, Other people may frown, but I titter in delight! 2/5",
           0.229
          ],
          [
           "Might just leave and aggravate bae",
           0.417
          ],
          [
           "Note to self ~ Stop laughing at things that offend you, it's ok to get mad at people \\n#NoteToSelf #offended #mad #upset",
           0.542
          ],
          [
           "(Sam) Brown's Law: Never offend people with style when you can fake that, you have to break us in this Island.",
           0.333
          ],
          [
           "@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended",
           0.417
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "hOASQXvMJUFfmj1Bc/AfQfFOHkFQZzlBonchQY1SIUEbXh9Bnzo5QQOWLkFVnTpBcPEuQfFzMkGBIDBBseA3QTuRVUFlyDFBt0M3QSgeQEHAOhxBgd8iQfCyKkHHmxRBVx4fQT0TKUF9XS5BSfs+QfznNEHqjTBBqQgnQXObHEGhzipBWVotQVuGSkE0RDtBCh5FQdzIMEF2qTJBz/UOQbsPNkFFUDpBBrQ3QXGTFkHU0DVBDjg9Qb15PkEmlDNB",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "073JQG89T0C0HbRAs30yQOxO5T+pqK9ATV3gPyco9D+63MtAv7ueQM+ry0DvSrBAZyFnQJN7Z0D7k9JAmDfBQJR/oUAlUdNAMgCuQAzSn0BdpV5AvKRDQMMEw0Ah18ZAqde6QJIY0UAp8rNAYzK8QOT+tkA0+qNAr1zBQObXuUDYAMJAPajWQDb9nUBblJtAvEOqQG+PpUCG1G5ADGIlQOkdpkAWWc5AvpvGQAzFd0BmiIxAafS9QJfzl0AYV6RA",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Swear to God don't get a smart meter from your power company, 8 months of daft bills, 6 visits from British Gas #nightmare #stressed",
           0.688
          ],
          [
           "someone come to fright world w me🤗🤗",
           0.458
          ],
          [
           "You make me breathless.",
           0.312
          ],
          [
           "Tomorrow is going to be a challenge, I have to talk at a freshers fair to STRANGERS 😁and pick up my new flat keys ",
           0.58
          ],
          [
           "@GSchwartz_ it wasn't a joke . #bully",
           0.5
          ],
          [
           "She was so posh it frightened me. I'm still scared.",
           0.81
          ],
          [
           "@nigglydz lydiaaaa, we were the only ones that were supposed to know that you make me nervous 😶",
           0.75
          ],
          [
           "My study skills are terrible 😒",
           0.562
          ],
          [
           "Jeans with fake pockets ",
           0.125
          ],
          [
           "you make my heart shake, bend and break.'",
           0.473
          ],
          [
           "@Cory_Bonini AP didn't have a productive week 1 or 1st half against GB and Kalil is horrible! @Vikings D is its strongest asset currently.",
           0.396
          ],
          [
           "When my life became such a concern to irrelevant ass people I'll never know",
           0.521
          ],
          [
           "@humeraslam @MehrTarar @sherryrehman , yes, already he spoke so many lies with timid body language. Baluchistan could have been his own trap",
           0.294
          ],
          [
           "#ntfc mourinho is worried,  bringing Ibra  and Rushford on. ",
           0.5
          ],
          [
           "my boyfriend once forcibly stopped all of my anxiety coping methods at once (holding me, forcing my hands down that kinda stuff) and I --",
           0.74
          ],
          [
           ".@Tolumanda love it! so true. As @Deedeey_ taught me, fear can be an illusion. #coaching  #courage",
           0.375
          ],
          [
           "I lost my blinders .... ",
           0.333
          ],
          [
           "yesterday i finished watching penny dreadful and from all the beautiful things i saw one question remains: were the writers HIM's fans?",
           0.354
          ],
          [
           "People’s deepest passions often scare them too much to admit, even to themselves.",
           0.521
          ],
          [
           "When the sadness leaves you broken in your bed, I will hold you in the depths of your despair, and it's all in the name of love 🎶",
           0.479
          ],
          [
           "@mcdermo11 @rogerc32 u gave Laura so much constructive criticism she blocked u 'Lazy Give Up Now No Hope Retire' same with Heather ",
           0.458
          ],
          [
           "@DeionSandersJr @DeionSanders so bad...Slash prices or send them to refugee camps, like team gear after they lose championships. #awful",
           0.396
          ],
          [
           "@GucciShade @KellyannePolls @ABC So?  Who cares?  Who cares about tax forms, too.  I believe terrorism and jobs are what is important.",
           0.438
          ],
          [
           "Thoroughly enjoying AHS tonight. #ahs #horror #americanhorrorstory",
           0.271
          ],
          [
           "“ My courage always rises at every attempt to intimidate me.”\\n-Elizabeth Bennett (Pride and Prejudice)\\n#Quotes #Courage #FaceYourFears",
           0.42
          ],
          [
           "@falklands_utd @mauriciomacri \\nbecause distrust in life , Argentina has a lot of heart and this President is worth every vote.",
           0.312
          ],
          [
           "When someone tells you they're going to 'tear you apart' and all they have to say is 'why are you so tall?' ",
           0.354
          ],
          [
           "Is it terrorism to intimidate a populace? What case held 'coercion by people in uniform is per se intimidation'?",
           0.562
          ],
          [
           "After Nawaz Sharif's speech on terrorism, Kejriwal is expected to talk on Governance.",
           0.28
          ],
          [
           "@FraserKeegan just had a steak pie supper ",
           0.083
          ],
          [
           "After #terror our leaders say, 'Don't jump to conclusions,' but [in matters of #racial unrest], they are silent. Why is that? @greggutfeld",
           0.729
          ],
          [
           "A Lysol can got stuck in spray position and we're all slowly suffocating from the trash can that smells like a Febreeze factory. #panic",
           0.729
          ],
          [
           "Anyone else find @Microsoft 'anniversary windows 10 update 1607' a Complete #nightmare",
           0.479
          ],
          [
           "@rsiereilly my heart did the flutter",
           0.562
          ],
          [
           "My roommate talks and laughs in her sleep. It never fails to scare the shit out of me. 🙅🏽😳",
           0.833
          ],
          [
           "My #anxiety is rising tonight and I'm not sure why. Sometimes I wonder if I'm a magnet for any free-floating anxiety in the universe.",
           0.917
          ],
          [
           "It's simple I get after two shots of espresso 'Grande, decaf, 130 degrees soy americano with extra foam' #barista ",
           0.125
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "Action is the foundational key to all success ~Pablo Picasso #inspiring #quote #action #hustle  #dosomething #success",
           0.229
          ],
          [
           "@Just_Alasia I agree. Btw, have u seen Ep22, Granger, O?  That was the episode when I knew Anna was coming back, the conversation at start.",
           0.312
          ],
          [
           "@ExpressScripts u shd b embrrssd. u jack up my bp meds twice and it will still take 3-5 days? Not express at all. #expressscripts #horrible",
           0.562
          ],
          [
           "@rkuuleiq Fear is best/beast product of God/s. :) #aTheism #theism #biBle  #christianity #hell #heaven #purgatory #psychology #jesus",
           0.37
          ],
          [
           "I am beyond mad that I lost track of a brown spider in my brown carpet. Where did you go? 🕷 will be sneaking up on me #frightened",
           0.875
          ],
          [
           "Scott Dann injured aka my worst nightmare",
           0.688
          ],
          [
           "If Monday had a face I would punch it #monday  #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow",
           0.396
          ],
          [
           "@WunderlistHelp are you guys still down? When can we go up? #panic",
           0.75
          ],
          [
           "Research has determined 70% of #laughter is actually .",
           0.25
          ],
          [
           "#India right of reply at #UNGA - #Pakistan preaching of human rights is by a country which is itself the global epicentre of ",
           0.479
          ],
          [
           "Why is it when you nap during the day you are so comfortable but sleeping at night you'll never be as comfortable #nightmare",
           0.519
          ],
          [
           "Im not a #nervouswreck, Im a  #pileup. #GoingCrazy #HelpMe #Insane #Antisocial",
           0.875
          ],
          [
           "Ever been really lonely and your phone keeps blowing up, but you just can’t pick it up and respond to people? #anxiety #recluse  #issues",
           0.893
          ],
          [
           "Gahh...BT, in queue for 30 minutes.. Now put through to BT Sport dept to cancel... back in a queue again... #shocking",
           0.5
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography ",
           0.312
          ],
          [
           "An adviser to the #European #Union’s top #court said #Hamas and the #Tamil #Tigers should be taken off the EU’s #terror list.#lka",
           0.5
          ],
          [
           "The moment you bring her to meet your best friend and you're nervous af! 😬😆 #nervous #thefriendtest",
           0.771
          ],
          [
           "@mikefreemanNFL \\nIsn't OBrien supposed to be some sort of offensive genius #awful",
           0.479
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation #awful",
           0.271
          ],
          [
           "@BuzzFeed so this houses will get into my instestines and scare my poop and I'll shit my pants?",
           0.7
          ],
          [
           "also i had an awful nightmare involving being sick where worms were involved i was so disgusted when i woke up",
           0.896
          ],
          [
           "On @Varneyco/@FoxBusiness to talk latest on #Chelsea Bombing + #Ahmad_Khan_Rahami's trips to #Afghanistan/#Pakistan #tcot ",
           0.604
          ],
          [
           "When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help  #heart #HeartRacing",
           0.73
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock #terrible",
           0.246
          ],
          [
           "Dunno y am going to the Yorkshire scare grounds when I only lasted a minute in the Alton towers one before running out a fire exit crying",
           0.812
          ],
          [
           "@CesarSampao @thisisbolton don't get me started on town centre. Used to go every week.... not been for 18 months ",
           0.458
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "OOkQQZQ0K0EcsTVB0KEtQQGJMkHX9zNBK1o0QWfUF0GcdD5B2eg4QUxhHEFDhjxBDJ9TQUJ4FUGkaCJBefg0Qe9zEEGsMxxBa+41QYKwOEF+ly5BugEaQb3lTEGaTxlB45oyQcDCMkERqD9Bxj9VQVBzVkGGoiFBnfNOQa0mJ0FroQ9BO88yQTKFLEFBNyZBlN4pQVb7UkEkTCVBw2Q8QVaSF0FjBTRBDVUrQT6pEUFe5D1Bs9QjQR8sS0H40lZB/hEpQVo9IUEX2R9BV+MSQemPH0F7XVdBK+UwQVcxHkEDaBVBlMUrQVgdKUHxO1RBFyExQf2gG0GanixBlHwTQQ==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "eLbCQDbbD0CiZidArmv3Pys/sUCXIe4/SI0IQCYNBEBWUbJAJrciQP2z0kAowstA4OmbQKn3nkALVbE/vQbFPynkUkBDPFVAbiUHQP4kM0DMc7lAp9DSQJQVqkB3AGpA6svhP6EUnEDd5B9A8riKQCGHn0ATGXNA8VWqQCzchj+oJMFA10ZCQIjwqD8Umbs/2p+AQIBRlkBVGD1ATKl/QKdr0EA776s/LACPPwQNrkAahb1A7JuWPxqwjkDk2J1Avq/DP9R7qj/rlrI/plbJQK/WJkDump1ASWvPP6HT2EBvCNBA2iaIP7yguz9We6dAcXKuP0NH10Blvfc/Onq6QA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "backed pats -2.5 10/11 just before ",
           0.32
          ],
          [
           "And you as well! #sparkling @cherebork @MelissaJoyRD @SarahKoszykRD @eat4performance @rustnutrition @jenhaugen",
           0.444
          ],
          [
           "Am I watching #BacheloretteAU or Zoolander ? #hilarious #samvrhys",
           0.646
          ],
          [
           "Watch this amazing live.ly broadcast by @brooks_swaggysquad #lively #musically",
           0.479
          ],
          [
           "Update: I have yet to hang out with @MisElizaJane, but I'm still hopeful! ",
           0.396
          ],
          [
           "I was cheering for NA team. Now I just want this is over and Gaudreau comes back in one piece. It is getting way too risky",
           0.192
          ],
          [
           "No, just tweet pictures of four fictional characters who describe you. One should be an animated character. @sunshinessp411",
           0.271
          ],
          [
           "Watch this amazing live.ly broadcast by @swagrman_fan #lively #musically",
           0.481
          ],
          [
           "don't put famous dex in a tweet with breezy lol chris is that guy dex a bitch lmao n music ass",
           0.354
          ],
          [
           "When u /only/ talk 2 me or ask me 'how r things' just 2 get 2 say something u want, 4give me if I'm not elated 2 start a conversation with u",
           0.12
          ],
          [
           "Benefit out exhilaration called online backing off: JkUVmvQXY",
           0.462
          ],
          [
           "Online now !!!:) all day come play with me !! I'm happy happy horny playful sweet sour;)",
           0.875
          ],
          [
           "@MaxVenator We've had no foreign policy but have had goofy Secretary of State John Kerry with his devil may care pose and jaunty blue scarf.",
           0.1
          ],
          [
           "second day on the job and i already got a 45 dollar tip from a dude whose was constantly twitching his eye LOLOLOL ",
           0.812
          ],
          [
           "@LPDonovan this is why I think his pre prepped debate answers have the potential for hilarity",
           0.458
          ],
          [
           "The object of literature is to make man a wiser and happier being. The poet makes us happy because he tells us how we may become so.",
           0.58
          ],
          [
           "@PeteSpencer007 Are you always so relentlessly positive? Your constantly cheerful optimistic disposition starts to grate after a while.",
           0.34
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "@iamnotatwit Or did I lie and cut 5 years off my age to be young and spry and hire-able in Hollywood? #thegoldbergs",
           0.36
          ],
          [
           "Trying to loveee somebody, just wanna love somebody right now, guess there's just no pleasing me",
           0.354
          ],
          [
           "Why have I only just started watching glee this week I am now addicted 🙄 #glee #GLEEK",
           0.625
          ],
          [
           "backed pats -2.5 10/11 just before #pleasing",
           0.327
          ],
          [
           "#smile is the #respect we give everyone.",
           0.583
          ],
          [
           "@Singaholic121 Good morning, love! Happy first day of fall. Let's make some awesome #autumnmemories #annabailey  ",
           0.86
          ],
          [
           "There is something v satisfying about  opening an old 'to do'.doc file and being able to check off all the things you have done ",
           0.602
          ],
          [
           "@melsey6 oh good girl hope she is cheerful",
           0.417
          ],
          [
           "@HillaryClinton did you see the gleeful look on @realDonaldTrump 's face when criminal Don King used the 'n' word to denigrate Blacks?",
           0.2
          ],
          [
           "Watch this amazing live.ly broadcast by @jaredhorgan #lively #musically",
           0.48
          ],
          [
           "@Matalan when the lady in Xmas dept answers your call as 'hello mrs Xmas' yep true story #winning #Xmas #cheer #goodcustomerservice ❤ 📞👍😊",
           0.74
          ],
          [
           "@philjame5 @spoke_bros wow! that looks bright",
           0.438
          ],
          [
           "@doubtcaspar babe :(( remember I'm ALWAYS here if u need a little cheering up or talk, ily lots💘",
           0.417
          ],
          [
           "Never make a #decision when you're #angry and never make a #promise when you're . #wisewords",
           0.271
          ],
          [
           "noah fence but i want a harley quinn or blake lively layout",
           0.207
          ],
          [
           "Rojo is so bad it's hilarious.",
           0.6
          ],
          [
           "Hey @AppleSupport, would be nice to have “click to pause” or “pause when window inactive” on animated GIFs for macOS Messages app",
           0.208
          ],
          [
           "only time I am ever cheering for you Johnny",
           0.34
          ],
          [
           "@chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. 😂",
           0.7
          ],
          [
           "4-2 Canada final tomorrow #WCH #Predictions #optimism #Canadian 🇨🇦",
           0.42
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day. #laughter #challenge #kashmir #baloch",
           0.7
          ],
          [
           "Our tone of voice: we're like One Direction, we're thoughtful and timid, yet playful",
           0.423
          ],
          [
           "@len_snart Mick nods. 'I would like that.' He went back to his food, smiling as he finished it.",
           0.62
          ],
          [
           "@yungdoujin wouldn't that basically be sparkling water",
           0.32
          ],
          [
           "Chris would take full responsibility and would want us all to rejoice in the memories we all had with him.",
           0.28
          ],
          [
           "It feels good to get outside for a minute and get some fresh air.  It's hard to stay cooped up inside all day ",
           0.58
          ],
          [
           "If yiu don't respond .o an email within 7 days, you willxbe killed by an animated gif of the girl froa The Ri.g.",
           0.22
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "yvsVQYtiK0EgKERBUkIoQRDDLUHoxRtBaFIzQZ0sKkGzLDBB0rdAQUHkK0G49y1B23lKQaqeG0HmKkhBW9MbQeYxMEEgvxlBIsQrQfZYNUEjERVB/eMXQYtvKkFXrDVB3T4gQYPgLEEmPEhBw+0pQRckGEEfFChBeyY5QSEZO0EDbzhBjToqQYQrIEE3TjlBCOQtQfGGHkHx3VFByWkzQTz1I0H25StB3U0UQdY1JUEf5UBB",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "zEWaQMLcbkCJoZJAKqaRQJvPP0CWD5ZALhGEQM8VkkA2vMZAuWpJQGUpZEDZwF1A3MedQNx7gUCWMZRAV3UwQJ+xi0DzEkBA3TCgQJppI0A6gG9AJ9KXQLylUUAFEFlAKnZRQENhWkCLL7RA4PKOQK2NiUB6WHxAKPJQQOtfwkBo74FAf0WwQAOWx0AmRIFApQSvQFpwk0BE2ZdA8SctQMdtZkCcWIFAmcZLQP5BXECClihA",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "BLUES with BOB HADDRELL &amp; Guests\\nFri 23rd Sep 8:30pm - 11:00pm #blues #free #TunbridgeWells",
           0.25
          ],
          [
           "@PottzGaming hmu need players for lans next year. DM me. Need serious players. Im under org",
           0.125
          ],
          [
           "Wanna pop some pills, sedate myself, and wake up tomorrow.",
           0.729
          ],
          [
           "So I tried to give her time to sober up, while waiting at the our friend's house. 2 hours later, gal wake up out her nap to vomit again.",
           0.438
          ],
          [
           "now playing yung fav song ni chavs #sober 😂",
           0.229
          ],
          [
           "Candice's pout gets more preposterous by the week. This week it's gone a bit Jack Nicholson's Joker. #GBBO",
           0.397
          ],
          [
           "If you sober better roll another Dutch or if u don't smoke nigga better pour another cup 🍁🍾...",
           0.312
          ],
          [
           "@keyshamackie it's fucking dreadful for live footy matches",
           0.571
          ],
          [
           "Some #people already talks about #Halloween \\nYou'll get some #dark #music to go with it\\n#gothic #bloody #HalloweenHorrorNights",
           0.333
          ],
          [
           "Never switched up, stayed down this the same person since day one.",
           0.347
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday ☺ #GBBO",
           0.188
          ],
          [
           "@Markgatiss I'm surrounded by those Trump voters. You're right, it is fucking terrifying. #redstate #despair",
           0.833
          ],
          [
           "Leeds surely to drop the prices for that cup tie, rather than the dismal attendance last night..",
           0.479
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "#FF \\n\\n@The_Family_X \\n\\n#soul #blues &amp; #rock #band\\n\\n#music from the #heart\\n\\nWith soul &amp; #passion \\n\\nXx 🎶 xX",
           0.25
          ],
          [
           "The word happiness would lose its meaning if it were not balanced by sadness.",
           0.479
          ],
          [
           "I'm getting use to not having a phone it's sad ..",
           0.68
          ],
          [
           "@TxDMV @ArkansasBBB i filled out the report on #baitswitch by @Carvana lets go get them fines levied. #badbusiness #honoryourdeal #unhappy",
           0.542
          ],
          [
           "TONIGHT - Fulford Arms, York \\nTOMORROW - Bank Top Tavern, Oldham\\nNEXT SATURDAY- Big Hands, Manchester \\n\\n#livemusic #punk #blues #rockandroll",
           0.188
          ],
          [
           "This pretentious dick in Night Gallery just fucking, used a towel to dry off his sink",
           0.396
          ],
          [
           "I haven't watched my favorite youtubers in months and it's honestly made my depression so much worse",
           0.667
          ],
          [
           "@patthemanager how could I work with @chancetherapper . ? #serious",
           0.354
          ],
          [
           "Some of these people at this protest are just there for the adrenaline rush. #depressing",
           0.583
          ],
          [
           "whenever i pout i just want Adrian to appear and tell me to stop pouting or else",
           0.583
          ],
          [
           "these grown ass lil boys yeah i can't take them serious.",
           0.235
          ],
          [
           "A pessimist is someone who, when opportunity knocks, complains about the noise.",
           0.396
          ],
          [
           "I don't think it's fully sunk in that Val is gone yet",
           0.654
          ],
          [
           "Has anyone noticed that @npr stories in recent days all paint positive accomplishments for Trump and challenges for Hillary? #surprised ",
           0.333
          ],
          [
           "@wabermes The @RavalliRepublic had a good one but then the reporter quit. #sad",
           0.708
          ],
          [
           "@DeltaAssist Tried 2 get earlier flt 2day  @BWI Turnd away bcuz it was 2 late Then agent let other pas on #silvereliteleftbehind #unhappy",
           0.667
          ],
          [
           "It's so gloomy outside. I wish it was as cold as it looked",
           0.542
          ],
          [
           "@DoubleEph sadly his best days are behind him",
           0.583
          ],
          [
           "My prayers are with the family, friends &amp; members of @VCFD  as you mourn the loss of Engineer Ryan Osler. #LODD #RIP",
           0.771
          ],
          [
           "@petercoffin So safe blues are ok. Are reds ok as well? Obviously, battleground states would not.",
           0.263
          ],
          [
           "@SWP_Roads   How dull.",
           0.521
          ],
          [
           "It feel like we lost a family member🙄😂",
           0.708
          ],
          [
           "My life went from happy to unhappy..",
           0.812
          ],
          [
           "@OHSOVICTORIOUS_ @FaZeAdapt We all seen it coming.. it's sad. But her Instagram comments on her pics are funny. Adapts fans blew it up 😂😂😂",
           0.354
          ],
          [
           "amateur author Twitter might be the most depressing thing I've ever seen",
           0.688
          ],
          [
           "Don't be disheartened if you didn't get the cards you wanted, it's not the end of the world......E-Eh...? Y-You want me to cheer you up?",
           0.438
          ],
          [
           "[ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **",
           0.562
          ],
          [
           "@Eeevah14 don't I know it, try not to fret my sweet little pupper",
           0.333
          ],
          [
           "Wow just watched Me Before You and it was seriously one of the most depressing movies of my life",
           0.667
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "cuYOQbYOI0FAxB1BA2wpQcOwIUGZdjVBUE8lQfNFGkFAICRB9Zo0QQGIIEHVhRlBREoSQZQpMkEbZhBBw4cXQe7kD0Gy7BNBT7kPQVg1LkFtrwxBS7AmQbaUG0GmWDtBpsg1QTJOFUEmuhFBtsNKQWaFIEEZ5hRBXtUTQa1AJUEpeBJBF80+QcWXGkGm0RBBVa4RQQ4VIkHWOBhBZX09QRYKQEFjijtBMY8MQQ==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "bN+aQOgzmkCIyRRA8mEnQFLhh0DX7pVAE7GFQAmGw0C9MRpALBdvQM83YkD7hLZAF9akQEJezUBR/I5A4IwqQPDfMkANO9VAPFiXQIC+10CcFVlAbYOeQHmeokCXJ3FAeKjKQPwUJEA6oVdAlNGxQAv4q0DqetJAoNQfQK51nkDlGWJAFDWYQLHOqUASSWBAScQ2QJc+pECOhaxAm40/QAD5TUB/J0VAPdhqQA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D UMAP Projection of Text Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# 合併訓練和測試數據\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# 為 UMAP 準備嵌入向量\n",
    "# 將嵌入向量列表轉換為 2D numpy 陣列\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# 應用 UMAP 進行維度縮減\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# 為繪製創建 DataFrame\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# 使用 Plotly 可視化嵌入向量\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # 按 'emotion' 列著色點\n",
    "    hover_data=['text', 'intensity'],  # 懸停時顯示文本和強度\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap.\n",
    "\n",
    "我們可以看到，即使使用 Gemini 的詞嵌入，我們的資料類別在二維空間中似乎也無法清楚地劃分出聚類。這可能是因為情感通常並非離散的。文本可能包含複雜的情感（例如，「苦樂參半」），或使用相似的語言來表達不同的情感，導致它們的詞嵌入在語義空間中自然接近。此外，將高維詞嵌入投影到二維視覺化過程中不可避免地會失去一些訊息，這可能會導致不同的聚類看起來重疊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph.\n",
    "\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> 練習 4（家庭作業）：**](#toc0_)\n",
    "\n",
    "對相同的嵌入應用 UMAP 演算法，將維度降低到 3D 向量，並繪製 3D 圖，討論其與 2D 圖的異同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\研究所必看\\研究所課程\\114-1\\資料探勘與應用\\DM2025Labs\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! ",
           0.604
          ],
          [
           "The best revenge is massive success.",
           0.312
          ],
          [
           "@tmz @HarveyLevinTMZ   Hell hath no fury like a women scorned.    It's the affair.  Not the parenting",
           0.667
          ],
          [
           "Happiness is the best revenge",
           0.25
          ],
          [
           "@MHChat sadness with resentment is the past, sadness with fear is the future. try to live in the now #MHchat",
           0.172
          ],
          [
           "it makes me so fucking irate jesus. nobody is calling ppl who like hajime abusive stop with the strawmen lmao",
           0.75
          ],
          [
           "Inner conflict happens when we are at odds with ourselves. Honor your values and priorities.  #innerconflict #conflict #values",
           0.5
          ],
          [
           "Projection is perception. See it in someone else? You also at some level have that within you. #anger #worry",
           0.417
          ],
          [
           "@XemitSellsMagic add tracking but resent them",
           0.688
          ],
          [
           "@healeyraine I'm offended, I actually am",
           0.479
          ],
          [
           "I'm about to block everyone everywhere posting about the storm. I think everyone is aware of the damn rain and what not so quit. #damn #rage",
           0.708
          ],
          [
           "Like if you aggravate me constantly, byeeeeeeee",
           0.562
          ],
          [
           "I think they may be ",
           0.229
          ],
          [
           "@PrincessCasGirl @DaddyEllis__ tiff you better hurry cause 👀",
           0.458
          ],
          [
           "So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted ",
           0.896
          ],
          [
           "I get so angry at people that don't know that you don't have a stop sign on Francis and you do at Foster #road ",
           0.792
          ],
          [
           "Take public opinion on revenge with Pakistan if govt is unable to decide. @aajtak @TimesNow @narendramodi",
           0.458
          ],
          [
           "You a fuck boy if you run drag routes back to back in madden",
           0.646
          ],
          [
           "@HebertofNH any time a man who got paid to throw temper tantrums speaks up, you gotta listen.",
           0.521
          ],
          [
           "I don't talk about politics because people nowadays get offended easily!",
           0.479
          ],
          [
           "I mean I'm not done watching the pilot, but it's nice to see a group of actors perform without story lines dripping relentless nihilism.",
           0.458
          ],
          [
           "As your own lives in order to complete our amazing life journey successfully, it is there. ",
           0.357
          ],
          [
           "I blame the whole season on Natalie! The season would have been so different had she not turned her back on her alliance! #pissed ",
           0.792
          ],
          [
           "Wont use using @mothercareuk @Mothercarehelp again!! These guys cant get nothing right!! #fuming",
           0.854
          ],
          [
           "if we let that in id be fuming poor keeping",
           0.562
          ],
          [
           "@brian5or6 turn that shit off!   Home Button under Accessibility. \\n\\nWhen did innovation become mind fuckery? . #iphonePhoneHome",
           0.688
          ],
          [
           "@CI  I don't think Monalisa has respect for anyone but herself! I think she'll ruffle a few feathers. #TheJail",
           0.625
          ],
          [
           "Fake people irritate me",
           0.562
          ],
          [
           "remember when that guy got #angry that i kept saying gary sanchez was the best baseball player in the world... lmao",
           0.417
          ],
          [
           "@jaybusbee Well, not Archie. No offense but he's kinda old.",
           0.396
          ],
          [
           "@coltonflurry @StrangeFacesLA I cancelled by CBS all access live feeds before JC even said Vic won AFP. Paul.should have won IMO #bitter",
           0.517
          ],
          [
           "Why does @dapperlaughs have to come to Glasgow on a night I am working. I am fucking gutted, been waiting for an appearance for ages #raging",
           0.938
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Delete this shit Josh just screenshotted my snap me",
           0.583
          ],
          [
           "British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!",
           0.479
          ],
          [
           "@ezlisteningdisc it doesn't offend me but it's just,,, Weird.",
           0.188
          ],
          [
           "Well @AprilDRyan Trump's rabid base needs 2 hear this &amp; U can always find an overseer like King to say it.\\n@JoyAnnReid @SMShow @frangeladuo",
           0.458
          ],
          [
           "@JBCrewdotcom how his own fans insult him",
           0.417
          ],
          [
           "Realest ever, relentless ever, inevitable that I win.",
           0.415
          ],
          [
           "Having a baby born too soon is #lifechanging 6 years on and it feels like only yesterday #sad #happy #angry #emotionalrollercoaster",
           0.375
          ],
          [
           "@fluffysoftlouis no no. I insist that you give me your best insult first",
           0.562
          ],
          [
           "Eat my ass' is no longer an insult",
           0.438
          ],
          [
           "Hate when guys cant control their anger 🙃🙃",
           0.646
          ],
          [
           "Just watched Django Unchained, Other people may frown, but I titter in delight! 2/5",
           0.229
          ],
          [
           "Might just leave and aggravate bae",
           0.417
          ],
          [
           "Note to self ~ Stop laughing at things that offend you, it's ok to get mad at people \\n#NoteToSelf #offended #mad #upset",
           0.542
          ],
          [
           "(Sam) Brown's Law: Never offend people with style when you can fake that, you have to break us in this Island.",
           0.333
          ],
          [
           "@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended",
           0.417
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "GkWsQfHvokErC6RBTBafQSxmpUG8RaxBA+qoQYRNqkGAV65Bp32pQaJKr0HpYKxB7smhQdjNnkFEw69BuoyvQVy/pkGfw7BBIuujQcP7qEH3C5lB2G+hQWcqrUGJn6tBdpSrQdJGsEHoV6pB7omuQYhBrEExmKVBsO+qQVOuq0GGtqtBTjmxQSqpqEEcXadBtV2gQV22p0G5wKRBTImdQYjhqkFAF69Bq8ewQahKmEEKBKlBl1WuQW1bqUEELqhB",
          "dtype": "f4"
         },
         "y": {
          "bdata": "w1Zrv1nFCUCo3fY+e78JQASL1j/CvzI/OLTaPwAPzD+Dqhi/AlAfP7AsWD2pNHo/FOvUPyMH2z5t9FG+V65MP4lqIT6uE6g+qCR0PehQXD9YvNM/+e0IQPhqpr6c/ly/zAenvEQgtb7bYjQ8S+WJP+FmDT51TTA+C/EUv04OhL482/a+bQuGvu0fCz9kqCw/bAmBPuISxb0oWwJAMTXmP3sxmD4x+tQ+KMlRP73Jlz+Rk7s/2vaHP7UHiT90mzs+",
          "dtype": "f4"
         },
         "z": {
          "bdata": "YWKdQcago0HcMqpBZnihQSyXlUFSPqZBvcGVQWb3lkGIPKBBB6qoQVXBpEEn+6NBZsCgQW08okGM56JBV06nQQpotEFV76NB1AiqQR3GqkG5nqBBpkSiQViYpkHmup1BJvOfQcBRokFJjKhBGKajQTRFq0F5J6dB4QOmQetsn0EJTqdBLUiiQQynsEFM4qdB+0SsQQOEqUH2saNBKj6YQeHjqUGEeaRBHJmlQSxUoEHYyKFByY2oQe2fp0FLI6dB",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "Swear to God don't get a smart meter from your power company, 8 months of daft bills, 6 visits from British Gas #nightmare #stressed",
           0.688
          ],
          [
           "someone come to fright world w me🤗🤗",
           0.458
          ],
          [
           "You make me breathless.",
           0.312
          ],
          [
           "Tomorrow is going to be a challenge, I have to talk at a freshers fair to STRANGERS 😁and pick up my new flat keys ",
           0.58
          ],
          [
           "@GSchwartz_ it wasn't a joke . #bully",
           0.5
          ],
          [
           "She was so posh it frightened me. I'm still scared.",
           0.81
          ],
          [
           "@nigglydz lydiaaaa, we were the only ones that were supposed to know that you make me nervous 😶",
           0.75
          ],
          [
           "My study skills are terrible 😒",
           0.562
          ],
          [
           "Jeans with fake pockets ",
           0.125
          ],
          [
           "you make my heart shake, bend and break.'",
           0.473
          ],
          [
           "@Cory_Bonini AP didn't have a productive week 1 or 1st half against GB and Kalil is horrible! @Vikings D is its strongest asset currently.",
           0.396
          ],
          [
           "When my life became such a concern to irrelevant ass people I'll never know",
           0.521
          ],
          [
           "@humeraslam @MehrTarar @sherryrehman , yes, already he spoke so many lies with timid body language. Baluchistan could have been his own trap",
           0.294
          ],
          [
           "#ntfc mourinho is worried,  bringing Ibra  and Rushford on. ",
           0.5
          ],
          [
           "my boyfriend once forcibly stopped all of my anxiety coping methods at once (holding me, forcing my hands down that kinda stuff) and I --",
           0.74
          ],
          [
           ".@Tolumanda love it! so true. As @Deedeey_ taught me, fear can be an illusion. #coaching  #courage",
           0.375
          ],
          [
           "I lost my blinders .... ",
           0.333
          ],
          [
           "yesterday i finished watching penny dreadful and from all the beautiful things i saw one question remains: were the writers HIM's fans?",
           0.354
          ],
          [
           "People’s deepest passions often scare them too much to admit, even to themselves.",
           0.521
          ],
          [
           "When the sadness leaves you broken in your bed, I will hold you in the depths of your despair, and it's all in the name of love 🎶",
           0.479
          ],
          [
           "@mcdermo11 @rogerc32 u gave Laura so much constructive criticism she blocked u 'Lazy Give Up Now No Hope Retire' same with Heather ",
           0.458
          ],
          [
           "@DeionSandersJr @DeionSanders so bad...Slash prices or send them to refugee camps, like team gear after they lose championships. #awful",
           0.396
          ],
          [
           "@GucciShade @KellyannePolls @ABC So?  Who cares?  Who cares about tax forms, too.  I believe terrorism and jobs are what is important.",
           0.438
          ],
          [
           "Thoroughly enjoying AHS tonight. #ahs #horror #americanhorrorstory",
           0.271
          ],
          [
           "“ My courage always rises at every attempt to intimidate me.”\\n-Elizabeth Bennett (Pride and Prejudice)\\n#Quotes #Courage #FaceYourFears",
           0.42
          ],
          [
           "@falklands_utd @mauriciomacri \\nbecause distrust in life , Argentina has a lot of heart and this President is worth every vote.",
           0.312
          ],
          [
           "When someone tells you they're going to 'tear you apart' and all they have to say is 'why are you so tall?' ",
           0.354
          ],
          [
           "Is it terrorism to intimidate a populace? What case held 'coercion by people in uniform is per se intimidation'?",
           0.562
          ],
          [
           "After Nawaz Sharif's speech on terrorism, Kejriwal is expected to talk on Governance.",
           0.28
          ],
          [
           "@FraserKeegan just had a steak pie supper ",
           0.083
          ],
          [
           "After #terror our leaders say, 'Don't jump to conclusions,' but [in matters of #racial unrest], they are silent. Why is that? @greggutfeld",
           0.729
          ],
          [
           "A Lysol can got stuck in spray position and we're all slowly suffocating from the trash can that smells like a Febreeze factory. #panic",
           0.729
          ],
          [
           "Anyone else find @Microsoft 'anniversary windows 10 update 1607' a Complete #nightmare",
           0.479
          ],
          [
           "@rsiereilly my heart did the flutter",
           0.562
          ],
          [
           "My roommate talks and laughs in her sleep. It never fails to scare the shit out of me. 🙅🏽😳",
           0.833
          ],
          [
           "My #anxiety is rising tonight and I'm not sure why. Sometimes I wonder if I'm a magnet for any free-floating anxiety in the universe.",
           0.917
          ],
          [
           "It's simple I get after two shots of espresso 'Grande, decaf, 130 degrees soy americano with extra foam' #barista ",
           0.125
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "Action is the foundational key to all success ~Pablo Picasso #inspiring #quote #action #hustle  #dosomething #success",
           0.229
          ],
          [
           "@Just_Alasia I agree. Btw, have u seen Ep22, Granger, O?  That was the episode when I knew Anna was coming back, the conversation at start.",
           0.312
          ],
          [
           "@ExpressScripts u shd b embrrssd. u jack up my bp meds twice and it will still take 3-5 days? Not express at all. #expressscripts #horrible",
           0.562
          ],
          [
           "@rkuuleiq Fear is best/beast product of God/s. :) #aTheism #theism #biBle  #christianity #hell #heaven #purgatory #psychology #jesus",
           0.37
          ],
          [
           "I am beyond mad that I lost track of a brown spider in my brown carpet. Where did you go? 🕷 will be sneaking up on me #frightened",
           0.875
          ],
          [
           "Scott Dann injured aka my worst nightmare",
           0.688
          ],
          [
           "If Monday had a face I would punch it #monday  #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow",
           0.396
          ],
          [
           "@WunderlistHelp are you guys still down? When can we go up? #panic",
           0.75
          ],
          [
           "Research has determined 70% of #laughter is actually .",
           0.25
          ],
          [
           "#India right of reply at #UNGA - #Pakistan preaching of human rights is by a country which is itself the global epicentre of ",
           0.479
          ],
          [
           "Why is it when you nap during the day you are so comfortable but sleeping at night you'll never be as comfortable #nightmare",
           0.519
          ],
          [
           "Im not a #nervouswreck, Im a  #pileup. #GoingCrazy #HelpMe #Insane #Antisocial",
           0.875
          ],
          [
           "Ever been really lonely and your phone keeps blowing up, but you just can’t pick it up and respond to people? #anxiety #recluse  #issues",
           0.893
          ],
          [
           "Gahh...BT, in queue for 30 minutes.. Now put through to BT Sport dept to cancel... back in a queue again... #shocking",
           0.5
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography ",
           0.312
          ],
          [
           "An adviser to the #European #Union’s top #court said #Hamas and the #Tamil #Tigers should be taken off the EU’s #terror list.#lka",
           0.5
          ],
          [
           "The moment you bring her to meet your best friend and you're nervous af! 😬😆 #nervous #thefriendtest",
           0.771
          ],
          [
           "@mikefreemanNFL \\nIsn't OBrien supposed to be some sort of offensive genius #awful",
           0.479
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation #awful",
           0.271
          ],
          [
           "@BuzzFeed so this houses will get into my instestines and scare my poop and I'll shit my pants?",
           0.7
          ],
          [
           "also i had an awful nightmare involving being sick where worms were involved i was so disgusted when i woke up",
           0.896
          ],
          [
           "On @Varneyco/@FoxBusiness to talk latest on #Chelsea Bombing + #Ahmad_Khan_Rahami's trips to #Afghanistan/#Pakistan #tcot ",
           0.604
          ],
          [
           "When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help  #heart #HeartRacing",
           0.73
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock #terrible",
           0.246
          ],
          [
           "Dunno y am going to the Yorkshire scare grounds when I only lasted a minute in the Alton towers one before running out a fire exit crying",
           0.812
          ],
          [
           "@CesarSampao @thisisbolton don't get me started on town centre. Used to go every week.... not been for 18 months ",
           0.458
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "juyrQVp5okG14KVBipakQXTJqkEbVqpBRGWnQZ2HoUGeHK1BIFynQZ8BpkGjrK5BCjOnQQGaoEEX0KpBiTCqQUU6nEGhEJZBdmypQbRFo0FSgapBMvypQTtho0E0wpZBwfuqQVc+pEE6SatB3qStQetOpkGZ25lBBomiQfRIq0Ew0atBi/KeQcg+qkERSahBJPmfQdC6qEFCaaRBIICgQWP9qkH6fKpBQ6WqQc8ZqkEIeKxBk0OqQaWbpUHpw6ZBpHWpQUlYqEHFJahBhHCqQSCXnkGeBqVBTgGnQVV2p0GbX6xBMVKsQYEOqkE/+qNBUvenQdDHpkHnVKVBLxWpQQ==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "vNFBv/sjyz4A3tI/g+IfPzV77zuFhwY/BspCP6THgT8PdJg/7kyyP+RRXL+iPB8/TJQdPphXCL/sd4g/RvqcP215rz9usog/TDyWP9hTsD8gVIG+AfR1vxgtyj6RMIk/+G6tP8tqFb6w22I/AyGGP+Q2bz4Dcas/oL9NPun6xz46kxO/KlCeP2M7gT6fmW4/X6e1P+Vtw7wBLRJACAsFPwK0i7/t5nY/DEgDP7t1tb71XZI/N4MHP4nnQz8G4RM+hu8tPfE1Sz9S5nc/i+OFvyfdPT+vhAQ+Bb00P6XEeb/WYpa/MJV7PsnjHTwzviU+9V9fP4Iuhb9ovT8+q3M7vw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "j5iaQS3GlkHgE51B+jWUQT4MrEHHy5ZBTdCVQRRElUH6bqJBVyGcQWz0o0Gle6FBi32zQY/Wn0HsLJJBwBeVQaYsmkHQb55Bg26XQf2XnEEtoapBbQ2jQXNBsUHqaZ9BLjKVQRyPqUEDWptBAbuVQTmbtEETrKZB86SyQWQlkkH015hBEiagQdbkk0Fxf5FBrm6mQQ8UskF4BaNBZVioQbbLn0G+6pNBeFiSQShclkFPA6VBLd+QQfijsEGle7RBdE6UQTDckEEYopBB9wWcQUHImEFNd7VBZdOTQdqPpEF0G51ByzCUQVGIk0EAq7RBPqCSQQiBpEE8ZpVBqmmdQQ==",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "backed pats -2.5 10/11 just before ",
           0.32
          ],
          [
           "And you as well! #sparkling @cherebork @MelissaJoyRD @SarahKoszykRD @eat4performance @rustnutrition @jenhaugen",
           0.444
          ],
          [
           "Am I watching #BacheloretteAU or Zoolander ? #hilarious #samvrhys",
           0.646
          ],
          [
           "Watch this amazing live.ly broadcast by @brooks_swaggysquad #lively #musically",
           0.479
          ],
          [
           "Update: I have yet to hang out with @MisElizaJane, but I'm still hopeful! ",
           0.396
          ],
          [
           "I was cheering for NA team. Now I just want this is over and Gaudreau comes back in one piece. It is getting way too risky",
           0.192
          ],
          [
           "No, just tweet pictures of four fictional characters who describe you. One should be an animated character. @sunshinessp411",
           0.271
          ],
          [
           "Watch this amazing live.ly broadcast by @swagrman_fan #lively #musically",
           0.481
          ],
          [
           "don't put famous dex in a tweet with breezy lol chris is that guy dex a bitch lmao n music ass",
           0.354
          ],
          [
           "When u /only/ talk 2 me or ask me 'how r things' just 2 get 2 say something u want, 4give me if I'm not elated 2 start a conversation with u",
           0.12
          ],
          [
           "Benefit out exhilaration called online backing off: JkUVmvQXY",
           0.462
          ],
          [
           "Online now !!!:) all day come play with me !! I'm happy happy horny playful sweet sour;)",
           0.875
          ],
          [
           "@MaxVenator We've had no foreign policy but have had goofy Secretary of State John Kerry with his devil may care pose and jaunty blue scarf.",
           0.1
          ],
          [
           "second day on the job and i already got a 45 dollar tip from a dude whose was constantly twitching his eye LOLOLOL ",
           0.812
          ],
          [
           "@LPDonovan this is why I think his pre prepped debate answers have the potential for hilarity",
           0.458
          ],
          [
           "The object of literature is to make man a wiser and happier being. The poet makes us happy because he tells us how we may become so.",
           0.58
          ],
          [
           "@PeteSpencer007 Are you always so relentlessly positive? Your constantly cheerful optimistic disposition starts to grate after a while.",
           0.34
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "@iamnotatwit Or did I lie and cut 5 years off my age to be young and spry and hire-able in Hollywood? #thegoldbergs",
           0.36
          ],
          [
           "Trying to loveee somebody, just wanna love somebody right now, guess there's just no pleasing me",
           0.354
          ],
          [
           "Why have I only just started watching glee this week I am now addicted 🙄 #glee #GLEEK",
           0.625
          ],
          [
           "backed pats -2.5 10/11 just before #pleasing",
           0.327
          ],
          [
           "#smile is the #respect we give everyone.",
           0.583
          ],
          [
           "@Singaholic121 Good morning, love! Happy first day of fall. Let's make some awesome #autumnmemories #annabailey  ",
           0.86
          ],
          [
           "There is something v satisfying about  opening an old 'to do'.doc file and being able to check off all the things you have done ",
           0.602
          ],
          [
           "@melsey6 oh good girl hope she is cheerful",
           0.417
          ],
          [
           "@HillaryClinton did you see the gleeful look on @realDonaldTrump 's face when criminal Don King used the 'n' word to denigrate Blacks?",
           0.2
          ],
          [
           "Watch this amazing live.ly broadcast by @jaredhorgan #lively #musically",
           0.48
          ],
          [
           "@Matalan when the lady in Xmas dept answers your call as 'hello mrs Xmas' yep true story #winning #Xmas #cheer #goodcustomerservice ❤ 📞👍😊",
           0.74
          ],
          [
           "@philjame5 @spoke_bros wow! that looks bright",
           0.438
          ],
          [
           "@doubtcaspar babe :(( remember I'm ALWAYS here if u need a little cheering up or talk, ily lots💘",
           0.417
          ],
          [
           "Never make a #decision when you're #angry and never make a #promise when you're . #wisewords",
           0.271
          ],
          [
           "noah fence but i want a harley quinn or blake lively layout",
           0.207
          ],
          [
           "Rojo is so bad it's hilarious.",
           0.6
          ],
          [
           "Hey @AppleSupport, would be nice to have “click to pause” or “pause when window inactive” on animated GIFs for macOS Messages app",
           0.208
          ],
          [
           "only time I am ever cheering for you Johnny",
           0.34
          ],
          [
           "@chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. 😂",
           0.7
          ],
          [
           "4-2 Canada final tomorrow #WCH #Predictions #optimism #Canadian 🇨🇦",
           0.42
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day. #laughter #challenge #kashmir #baloch",
           0.7
          ],
          [
           "Our tone of voice: we're like One Direction, we're thoughtful and timid, yet playful",
           0.423
          ],
          [
           "@len_snart Mick nods. 'I would like that.' He went back to his food, smiling as he finished it.",
           0.62
          ],
          [
           "@yungdoujin wouldn't that basically be sparkling water",
           0.32
          ],
          [
           "Chris would take full responsibility and would want us all to rejoice in the memories we all had with him.",
           0.28
          ],
          [
           "It feels good to get outside for a minute and get some fresh air.  It's hard to stay cooped up inside all day ",
           0.58
          ],
          [
           "If yiu don't respond .o an email within 7 days, you willxbe killed by an animated gif of the girl froa The Ri.g.",
           0.22
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "m6ygQVHYnEFOmqdB26eaQc3DnkF3BqFBuDujQbvImkE9sK9BbwqmQQQ9nUE+hJxBEK6kQcGdmUEZBqRBHrmeQSaNokEV1JxBSd2kQSA3pEEuWZdBkxmeQQkdn0FPdJ9Bt8abQWmTnUE2RqFBZYGaQSDcm0HHxZ5BUnGiQY3Nr0HO8KNBM2yoQT16r0FaL6RBTSSoQWtkn0GyZqdBQgKkQbPumkFUv55BjfGaQXQem0EinqtB",
          "dtype": "f4"
         },
         "y": {
          "bdata": "MbZLv6F6pD/G5sC72SWDPpdpPD8lmRm+W5m4PxxmaD6cjuS94qqKP770zz8FyZo/VXQVPyefiz/hiD8/wtoLQCUUkD/f4gFAV3BRPqdy2D9oiFM/j6cPvxxh7D80FJE/kwgDQKEAqj/1p1g++XJ/PhdRgj8psXg/zTaJP2VHkT9RUrY/g5jxvg1MEr9pd2o/LriPvo5V6r1oBZ8+yaDJP26IvT8rKKg/upTaP25g5j+xdIc/",
          "dtype": "f4"
         },
         "z": {
          "bdata": "CA+jQTENpkGizq5BhD6lQXXrnUHog6BBbD2nQVDEpUHUTadBesKeQXD1okHzzqJBObCvQT1QoUFZ+K5B/GmfQc0Vp0F13Z1B2XClQddYm0FyEp5Bp9SjQShQpEHJR6NBN/GhQVLqokEZk69B32alQScHpEHP1KZB5T6gQUobp0F45adBbMSoQTGwn0FmpqNBo6usQd84oEEmB7NBi5OdQTNEpkE4PKhBe0icQRVQokFTJ5xB",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "BLUES with BOB HADDRELL &amp; Guests\\nFri 23rd Sep 8:30pm - 11:00pm #blues #free #TunbridgeWells",
           0.25
          ],
          [
           "@PottzGaming hmu need players for lans next year. DM me. Need serious players. Im under org",
           0.125
          ],
          [
           "Wanna pop some pills, sedate myself, and wake up tomorrow.",
           0.729
          ],
          [
           "So I tried to give her time to sober up, while waiting at the our friend's house. 2 hours later, gal wake up out her nap to vomit again.",
           0.438
          ],
          [
           "now playing yung fav song ni chavs #sober 😂",
           0.229
          ],
          [
           "Candice's pout gets more preposterous by the week. This week it's gone a bit Jack Nicholson's Joker. #GBBO",
           0.397
          ],
          [
           "If you sober better roll another Dutch or if u don't smoke nigga better pour another cup 🍁🍾...",
           0.312
          ],
          [
           "@keyshamackie it's fucking dreadful for live footy matches",
           0.571
          ],
          [
           "Some #people already talks about #Halloween \\nYou'll get some #dark #music to go with it\\n#gothic #bloody #HalloweenHorrorNights",
           0.333
          ],
          [
           "Never switched up, stayed down this the same person since day one.",
           0.347
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday ☺ #GBBO",
           0.188
          ],
          [
           "@Markgatiss I'm surrounded by those Trump voters. You're right, it is fucking terrifying. #redstate #despair",
           0.833
          ],
          [
           "Leeds surely to drop the prices for that cup tie, rather than the dismal attendance last night..",
           0.479
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "#FF \\n\\n@The_Family_X \\n\\n#soul #blues &amp; #rock #band\\n\\n#music from the #heart\\n\\nWith soul &amp; #passion \\n\\nXx 🎶 xX",
           0.25
          ],
          [
           "The word happiness would lose its meaning if it were not balanced by sadness.",
           0.479
          ],
          [
           "I'm getting use to not having a phone it's sad ..",
           0.68
          ],
          [
           "@TxDMV @ArkansasBBB i filled out the report on #baitswitch by @Carvana lets go get them fines levied. #badbusiness #honoryourdeal #unhappy",
           0.542
          ],
          [
           "TONIGHT - Fulford Arms, York \\nTOMORROW - Bank Top Tavern, Oldham\\nNEXT SATURDAY- Big Hands, Manchester \\n\\n#livemusic #punk #blues #rockandroll",
           0.188
          ],
          [
           "This pretentious dick in Night Gallery just fucking, used a towel to dry off his sink",
           0.396
          ],
          [
           "I haven't watched my favorite youtubers in months and it's honestly made my depression so much worse",
           0.667
          ],
          [
           "@patthemanager how could I work with @chancetherapper . ? #serious",
           0.354
          ],
          [
           "Some of these people at this protest are just there for the adrenaline rush. #depressing",
           0.583
          ],
          [
           "whenever i pout i just want Adrian to appear and tell me to stop pouting or else",
           0.583
          ],
          [
           "these grown ass lil boys yeah i can't take them serious.",
           0.235
          ],
          [
           "A pessimist is someone who, when opportunity knocks, complains about the noise.",
           0.396
          ],
          [
           "I don't think it's fully sunk in that Val is gone yet",
           0.654
          ],
          [
           "Has anyone noticed that @npr stories in recent days all paint positive accomplishments for Trump and challenges for Hillary? #surprised ",
           0.333
          ],
          [
           "@wabermes The @RavalliRepublic had a good one but then the reporter quit. #sad",
           0.708
          ],
          [
           "@DeltaAssist Tried 2 get earlier flt 2day  @BWI Turnd away bcuz it was 2 late Then agent let other pas on #silvereliteleftbehind #unhappy",
           0.667
          ],
          [
           "It's so gloomy outside. I wish it was as cold as it looked",
           0.542
          ],
          [
           "@DoubleEph sadly his best days are behind him",
           0.583
          ],
          [
           "My prayers are with the family, friends &amp; members of @VCFD  as you mourn the loss of Engineer Ryan Osler. #LODD #RIP",
           0.771
          ],
          [
           "@petercoffin So safe blues are ok. Are reds ok as well? Obviously, battleground states would not.",
           0.263
          ],
          [
           "@SWP_Roads   How dull.",
           0.521
          ],
          [
           "It feel like we lost a family member🙄😂",
           0.708
          ],
          [
           "My life went from happy to unhappy..",
           0.812
          ],
          [
           "@OHSOVICTORIOUS_ @FaZeAdapt We all seen it coming.. it's sad. But her Instagram comments on her pics are funny. Adapts fans blew it up 😂😂😂",
           0.354
          ],
          [
           "amateur author Twitter might be the most depressing thing I've ever seen",
           0.688
          ],
          [
           "Don't be disheartened if you didn't get the cards you wanted, it's not the end of the world......E-Eh...? Y-You want me to cheer you up?",
           0.438
          ],
          [
           "[ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **",
           0.562
          ],
          [
           "@Eeevah14 don't I know it, try not to fret my sweet little pupper",
           0.333
          ],
          [
           "Wow just watched Me Before You and it was seriously one of the most depressing movies of my life",
           0.667
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "tDegQflonUFiJaJBEvOcQf0Sm0G30aZBquObQdxyrEFXaZ9B9CKjQV0AmUFWAaxBDNajQaZ9sEFdB55B4UOeQUKDnkHhA6tBIUSfQXSxsEG2tpxBhGucQTqjpkGIIadBD2+wQVhOo0GW0JpBVZOhQY8TpEGGlqtBntCfQQqZokFu65pBKuWjQR5Up0Gff5tBs5qdQVeMoEGn9aVBPxSkQazapkEd2aJB6i+dQQ==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "s1f9vu4jKb66lME/a3xHPyBVvT68VpQ+lb8JP2Q/Nb+Lj7I+SPbkP2fPsz+oX/O9kw4Mv79ZCT5Gr2q+iUkGQLdprD91nY6/EoLavqXPCr4rEqY/Il5cvqu33j0mpX8/seMcPwHH9z/Nk7M/8laLPjG86jxJ+JK/UM/5P3lbZz5C4JA/HD1TP8mlmL5mG6Q/HIbmP2nLFL4CsTO+vjeLPwVZWD9poWY/wAmMPw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "ozyaQetKo0HceJhB0gadQWgVn0HYeKtBg3agQdTYn0E7eZdBBKOkQYgpo0GtgJpBlA+cQSu+pEHF6ZpBcwScQT3Xl0HbbqBBe8CaQccXo0HUPJdBW92jQYXunUHdn6JBkKekQecYmkH+/JpBAuKwQWb7oUEzsp5BHnuZQWAko0F0DJxBDe+sQY6jnkE56ppBaqmYQSMQpkHFe5xBiU6eQaqSnkH2Tp1BlZaWQQ==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D UMAP Projection of Text Embeddings"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 確保導入必要的模組\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# 合併訓練和測試數據\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# 為 UMAP 準備嵌入向量\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# 應用 UMAP 進行 3D 維度縮減\n",
    "reducer_3d = umap.UMAP(n_components=3, metric='cosine', random_state=28)\n",
    "embedding_3d = reducer_3d.fit_transform(X_embeddings)\n",
    "\n",
    "# 為繪製創建 DataFrame\n",
    "df_plot_3d = pd.DataFrame(embedding_3d, columns=['UMAP1', 'UMAP2', 'UMAP3'])\n",
    "df_plot_3d['emotion'] = combined_df['emotion']\n",
    "df_plot_3d['intensity'] = combined_df['intensity']\n",
    "df_plot_3d['text'] = combined_df['text']\n",
    "\n",
    "# 使用 Plotly 可視化 3D 嵌入向量\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_plot_3d,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    z='UMAP3',\n",
    "    color='emotion',\n",
    "    hover_data=['text', 'intensity'],\n",
    "    title='3D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig_3d.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 討論：2D vs 3D UMAP\n",
    "在進行二維與三維 UMAP 分析時，可以觀察到兩者在整體結構上有明顯的相似之處。這讓兩者在視覺化上呈現出類似的情感分布模式，各情感類別大多呈現連續而非離散的形態，也反映了情感表達中固有的模糊與重疊特性，因而無法形成清晰可分的聚類。\n",
    "\n",
    "三維版本相較於二維在表現上仍有一些差異。增加的維度賦予了模型更大的空間自由度，使資料點之間的關係能以更細緻的方式呈現。因為在降維過程中保留了更多高維資訊，三維投影通常能展示出較豐富的語意結構。從視覺化角度來看，三維圖形還具備可旋轉的互動特性，能從不同角度探索資料點之間的相對位置與距離，進一步提升對潛在關係的理解。\n",
    "\n",
    "雖然三維 UMAP 在展現資料的複雜語意結構上略有優勢，能提供更立體的觀察視角，情感類別間仍然難以完全分離，顯示自然語言中的情感表達並非單純的分類問題，而是具有高度語義重疊與連續性的現象。\n",
    "\n",
    "### Discussion: 2D vs 3D UMAP\n",
    "\n",
    "When conducting 2D and 3D UMAP analyses, significant similarities in their overall structure can be observed. This results in similar sentiment distribution patterns in visualization, with sentiment categories mostly exhibiting continuous rather than discrete forms. This also reflects the inherent ambiguity and overlap in sentiment expression, making it difficult to form clearly separable clusters.\n",
    "\n",
    "The 3D version still differs somewhat from the 2D version in its representation. The added dimension gives the model greater spatial freedom, allowing the relationships between data points to be presented in a more detailed way. Because more high-dimensional information is preserved during dimensionality reduction, 3D projections can usually display richer semantic structures. From a visualization perspective, 3D graphics also possess rotatable interactive properties, allowing exploration of the relative positions and distances between data points from different angles, further enhancing the understanding of potential relationships.\n",
    "\n",
    "While 3D UMAP has a slight advantage in displaying the complex semantic structure of data and provides a more three-dimensional observation perspective, sentiment categories are still difficult to completely separate, showing that sentiment expression in natural language is not a simple classification problem, but a phenomenon with high semantic overlap and continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)\n",
    "\n",
    "---\n",
    "\n",
    "### <a id='toc1_5_9_'></a>[**2.5 檢索增強產生 (RAG)**](#toc0_)\n",
    "\n",
    "`注意：本節內容（包括練習）現在被視為加分項，不計入主成績。 `\n",
    "\n",
    "RAG（檢索增強生成）是一種將文件檢索與文字生成結合的語言模型技術。在 RAG 中，檢索系統首先尋找相關的文件或文字區塊，然後語言模型利用檢索到的資訊產生更準確、更豐富的答案。這種方法透過使模型的答案基於真實的外部數據，增強了模型回答問題的能力。\n",
    "\n",
    "在下面的程式碼中，我們將載入一個網頁作為文檔，從而可以從 URL 檢索文字。載入內容後，我們將文件分割成更小、更易於管理的文字區塊，以便模型更輕鬆地處理。然後，我們將使用指定的 LLM 模型（Gemini 嵌入模型）為這些文字區塊產生嵌入向量。這些嵌入向量將被儲存在向量資料庫中，使我們能夠進行相似性搜尋。透過建構這個檢索系統，我們可以使用 RAG 鏈來回答問題。檢索器根據查詢從文件中找到相關的文字區塊，而 LLM 模型則透過整合這些檢索到的資訊產生回應，使答案更加可靠和準確。\n",
    "\n",
    "在本例中，我們使用了 langchain 函式庫。有關該庫更多功能的文檔，您可以查看以下連結：[LangChain 教程](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# 函式：載入、分割和檢索文檔\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() # 將載入會用作資料源的 URL\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) # 將 URL 分割成文本塊以便在向量空間中更容易比較\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) # 可以列印此項以查看 URL 中的塊如何被分割\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) # 我們用於比較的向量空間\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) # 以有序方式格式化檢索到的文檔以進行提示\n",
    "\n",
    "# 定義 Gemini LLM 函式\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    print(f\"Retrieved context: \\n{context}\\n\\n\") # 可以列印此項以觀察檢索到的上下文\n",
    "    return response\n",
    "\n",
    "\n",
    "# 定義 RAG 鏈\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 726, 'output_tokens': 60}\n",
      "Retrieved context: \n",
      "to realizing the vision of truly general artificial intelligence. The Potential Impacts of AGI and Ensuring a Positive Future   Speculating on the Future Timeline for Achieving AGI Predicting when Artificial General Intelligence (AGI) will be developed is difficult. Experts have different opinions, with some thinking it could happen in a few decades and others believing it will take much longer. Progress towards AGI will depend on improvements in machine learning, computational power, and data availability. Transformative Effects of AGI on Various Sectors AGI has the potential to completely change many industries: Healthcare AGI could greatly improve healthcare in the following ways:  Better diagnoses More effective treatment plans Enhanced patient care  Advanced AI systems, such as Robotic Process Automation (RPA), can analyze large amounts of medical information to find patterns and suggest personalized treatment options. This helps healthcare workers automate repetitive\n",
      "\n",
      "to realizing the vision of truly general artificial intelligence. The Potential Impacts of AGI and Ensuring a Positive Future   Speculating on the Future Timeline for Achieving AGI Predicting when Artificial General Intelligence (AGI) will be developed is difficult. Experts have different opinions, with some thinking it could happen in a few decades and others believing it will take much longer. Progress towards AGI will depend on improvements in machine learning, computational power, and data availability. Transformative Effects of AGI on Various Sectors AGI has the potential to completely change many industries: Healthcare AGI could greatly improve healthcare in the following ways:  Better diagnoses More effective treatment plans Enhanced patient care  Advanced AI systems, such as Robotic Process Automation (RPA), can analyze large amounts of medical information to find patterns and suggest personalized treatment options. This helps healthcare workers automate repetitive\n",
      "\n",
      "Benefits that AGI Could Bring to Society Here are some key advantages of AGI:  Enhanced Productivity: AGI could automate complex tasks across industries, leading to significant productivity gains. For instance, in healthcare, claims processing could be streamlined, reducing time and errors. Innovative Solutions: With its ability to understand and solve problems across domains, AGI could drive innovation in fields ranging from medicine to environmental conservation. Improved Decision-Making: AGI systems can analyze vast amounts of data quickly and accurately, aiding in more informed decision-making for businesses and governments. Personalized Experiences: From personalized learning in education to customized services in retail, AGI could enhance user experiences by understanding individual needs and preferences.  Potential Drawbacks and Risks Associated with AGI Advancement While the benefits are promising, there are also significant risks and challenges:  Ethical Concerns: The\n",
      "\n",
      "Benefits that AGI Could Bring to Society Here are some key advantages of AGI:  Enhanced Productivity: AGI could automate complex tasks across industries, leading to significant productivity gains. For instance, in healthcare, claims processing could be streamlined, reducing time and errors. Innovative Solutions: With its ability to understand and solve problems across domains, AGI could drive innovation in fields ranging from medicine to environmental conservation. Improved Decision-Making: AGI systems can analyze vast amounts of data quickly and accurately, aiding in more informed decision-making for businesses and governments. Personalized Experiences: From personalized learning in education to customized services in retail, AGI could enhance user experiences by understanding individual needs and preferences.  Potential Drawbacks and Risks Associated with AGI Advancement While the benefits are promising, there are also significant risks and challenges:  Ethical Concerns: The\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The provided text does not explicitly list the key challenges in realizing AGI's full potential. However, it does mention that progress towards AGI depends on improvements in machine learning, computational power, and data availability. It also highlights potential drawbacks and risks associated with AGI advancement, including ethical concerns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# 建立檢索器\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# 使用 RAG 鏈\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGI's Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n",
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**URL 中的實際答案：**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**URL 中可能因語意相似而被納入產生答案的內容：**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "來源：https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage.\n",
    "\n",
    "---\n",
    "\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> 附加練習 5（家庭作業）：**](#toc0_)\n",
    "\n",
    "`註：此練習為附加練習，不計入總成績，僅作為額外加分項。 `\n",
    "\n",
    "你的任務是使用你選擇的 URL 測試 RAG 系統並分析其效能。\n",
    "\n",
    "1. 找到一個包含有趣文字內容的網頁 URL，用來測試 RAG 流程。\n",
    "\n",
    "2. 根據你選擇的網頁內容提出一個問題。\n",
    "\n",
    "3. 討論模型對問題的回答質量，以及模型是否遺漏了與你的問題相關的重要資訊。\n",
    "\n",
    "4. 展示網頁上實際答案的截圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 368, 'output_tokens': 222}\n",
      "Retrieved context: \n",
      "What are applications of large language models?\n",
      "\n",
      "How are large language models trained?\n",
      "\n",
      "Why are large language models important?\n",
      "\n",
      "Large language models are incredibly flexible. One model can perform completely different tasks such as answering questions, summarizing documents, translating languages and completing sentences. LLMs have the potential to disrupt content creation and the way people use search engines and virtual assistants.\n",
      "While not perfect, LLMs are demonstrating a remarkable ability to make predictions based on a relatively small number of prompts or inputs. LLMs can be used for generative AI (artificial intelligence) to produce content based on input prompts in human language.\n",
      "LLMs are big, very big. They can consider billions of parameters and have many possible uses. Here are some examples:\n",
      "\n",
      "Read more about generative AI »\n",
      "Read more about foundation models »\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How do large language models work?\n",
      "\n",
      "A key factor in how LLMs work is the way they represent words. Earlier forms of machine learning used a numerical table to represent each word. But, this form of representation could not recognize relationships between words such as words with similar meanings. This limitation was overcome by using multi-dimensional vectors, commonly referred to as word embeddings, to represent words so that words with similar contextual meanings or other relationships are close to each other in the vector space.\n",
      "Using word embeddings, transformers can pre-process text as numerical representations through the encoder and understand the context of words and phrases with similar meanings as well as other relationships between words such as parts of speech. It is then possible for LLMs to apply this knowledge of the language through the decoder to produce a unique output.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Large Language Models (LLMs) are incredibly flexible AI models capable of performing a wide range of tasks, including answering questions, summarizing documents, translating languages, and completing sentences. They are characterized by their large size, often considering billions of parameters, and their ability to make predictions based on limited input. LLMs are a type of generative AI, meaning they can produce content in human language based on prompts.\n",
       "\n",
       "A key aspect of how LLMs work is their method of representing words. Unlike earlier machine learning approaches that used numerical tables, LLMs utilize multi-dimensional vectors called \"word embeddings.\" This allows them to recognize relationships between words, such as similar meanings, by placing words with related contextual meanings or other connections close to each other in a vector space.\n",
       "\n",
       "These word embeddings are processed by a component called a \"transformer,\" which uses an encoder to understand the context of words and phrases, including their relationships and parts of speech. Subsequently, a decoder applies this learned knowledge of language to generate a unique output.\n",
       "\n",
       "LLMs have the potential to significantly impact content creation, search engines, and virtual assistants."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "url=\"https://aws.amazon.com/what-is/large-language-model/?nc1=h_ls\"\n",
    "# 建立檢索器\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# 使用 RAG 鏈\n",
    "result = rag_chain(question=\"What are Large Language Models?\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  討論模型對問題的回答質量\n",
    "RAG大語言模型對「大型語言模型（LLMs）」的回答品質相當好且完整，它清晰地解釋了LLMs的主要功能、特點、運作方式和潛在影響。它清晰地指出LLMs是具備極大彈性的AI模型，能夠執行回答問題、摘要文件、翻譯、補全句子等多樣化任務，強調了數十億參數這個關鍵特徵，並將LLMs歸類為生成式AI。尤其在解釋運作機制時，它介紹了詞嵌入（word embeddings）這個核心概念，說明多維向量如何讓模型識別詞彙間的語義關係，這比僅僅提及編碼器/解碼器更具解釋力，極大地提高了實用性和可讀性。\n",
    "\n",
    "然而，與原始網站的說明相比，RAG的回答在技術細節上遺漏了幾個重要資訊。第一，它沒有明確提及LLMs的基礎是經過大量數據預訓練的深度學習模型，也沒有提到無監督訓練或自主學習這個訓練階段的關鍵術語。第二，原始網站明確指出Transformer架構相較於舊的循環神經網路（RNN）的優勢，即它能平行處理整個序列，從而利用GPU大幅縮短訓練時間；RAG的回答雖然提到了Transformer，但沒有對其平行處理能力和訓練效率的提升進行比較或說明。第三，它未具體列出LLMs訓練數據的來源與規模。因此，RAG的回答在概念和應用層面非常出色，但在底層技術架構（與RNN的比較）和訓練過程（具體方法和資料來源）的深度資訊方面有所遺漏。\n",
    "\n",
    "### Discussing the quality of the model's response to the question\n",
    "\n",
    "RAG's answer to the question \"Large Language Models (LLMs)\" is of high quality and comprehensive, clearly explaining the main functions, characteristics, operation, and potential impact of LLMs. It clearly points out that LLMs are highly flexible AI models capable of performing diverse tasks such as answering questions, summarizing documents, translating, and completing sentences, emphasizing the key feature of billions of parameters and classifying LLMs as generative AI. Particularly in explaining the operational mechanism, it introduces the core concept of word embeddings, explaining how multi-dimensional vectors allow the model to recognize semantic relationships between words. This is more explanatory than simply mentioning encoders/decoders, greatly improving practicality and readability.\n",
    "\n",
    "However, compared to the original website's explanation, RAG's answer omits several important pieces of information regarding technical details. First, it does not explicitly mention that LLMs are based on deep learning models pre-trained on a large amount of data, nor does it mention the key terminology of unsupervised training or autonomous learning in the training phase. Second, the original website clearly points out the advantages of the Transformer architecture compared to older recurrent neural networks (RNNs): its ability to process the entire sequence in parallel, thus significantly reducing training time using GPUs. While RAG's answer mentions the Transformer, it doesn't compare or explain its improved parallel processing capabilities and training efficiency. Third, it doesn't specify the source and scale of the LLMs training data. Therefore, while RAG's answer is excellent at the conceptual and application levels, it lacks in-depth information on the underlying technical architecture (comparison with RNNs) and the training process (specific methods and data sources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 網站截圖 Website screenshot\n",
    "![Exercise 5](./pics/Exercise%205.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <a id='toc1_5_10_'></a>[**2.6 少樣本提示分類：**](#toc0_)\n",
    "\n",
    "少樣本提示是一種技術，它向大型語言模型 (LLM) 提供少量標籤的提示範例，以指導其分類。這使得模型能夠以最少的資料執行新任務，避免進行大量的微調。\n",
    "\n",
    "在本實驗中，我們將使用 Gemini API 執行零樣本、單樣本和五樣本情緒分類：\n",
    "\n",
    "* **零樣本：** 模型在沒有任何先驗範例的情況下對文字進行分類。\n",
    "\n",
    "* **單一樣本：** 模型在分類前針對每種情緒提供一個範例。\n",
    "\n",
    "* **五樣本：** 模型針對每種情緒提供五個範例，以獲得更好的上下文資訊。\n",
    "\n",
    "為了使我們的實現更加穩健高效，我們加入了兩個關鍵特性：\n",
    "\n",
    "1. **結構化輸出：** 我們為 Gemini 模型提供了一個特定的輸出模式（`Emotions` 類別）。這指示模型*僅*返回有效的情緒標籤（例如，`joy`），從而使輸出結果可預測且可靠，最大限度地減少錯誤。\n",
    "\n",
    "2. **API 速率控制：** 程式碼包含一個用於管理 Gemini API 每分鐘請求數限制的函數。\n",
    "\n",
    "我們將使用每個情緒類別 20 個文字的小樣本測試模型的效能，以確保流程運作快速。如果模型傳回無效回應，程式碼將自動重試請求，直到收到有效的分類結果為止。\n",
    "\n",
    "**提示結構：**\n",
    "\n",
    "`系統說明 -> 任務描述 -> 範例（如果不是零樣本） -> 待分類文字`\n",
    "\n",
    "<span style=\"color:green\">本節練習無需重新運行單元格，您可以使用先前儲存到對應目錄的資料。 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩陣可視化函式\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    此函式修改自: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# 定義情感標籤\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# 定義用於少樣本提示的模型\n",
    "\n",
    "# 輸出的架構，如果我們想要通過選擇其中之一來分類文本，可以使用類型枚舉來建立選項池\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# 函式：處理 gemini 模型的速率限制\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # 在新視窗的第一個請求上初始化計時器\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # 如果達到速率限制\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # 為新視窗重設\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# 函式：按情感類別取樣範例\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# 函式：根據範例數（少樣本、1-樣本、零樣本）建立提示\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" # 以與分類文本相同的格式顯示範例\n",
    "                if num_shots == 1:  # 如果是 1-樣本，在每個情感的第一個範例後中斷\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# 函式：使用 LLM 進行分類，在不正確的回應時進行重試\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" # 分類文本將會留下由 LLM 填入的情感標籤\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # 在溫度為 0.0 時給出空回應的情況下，我們設定更高的溫度以尋求不同的回應\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # 如果結果是正確的格式，可以使用 json 進行解析\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # 如果不是 json 友好的格式\n",
    "                # 刪除可能出現在回應中的 \" 和 ' 字元，含文本的情感類別\n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # 重試請求\n",
    "\n",
    "\n",
    "        if response not in classes:  # 如果不是有效回應則重試\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# 主函式：執行實驗，選擇零樣本、1-樣本或 5-樣本提示\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # 根據 num_shots 為少樣本提示取樣範例\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # 零樣本沒有範例\n",
    "\n",
    "    # 我們分類模型的系統提示：\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # 準備分類測試集\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # 為要分類的測試集取樣每個情感 20 個範例\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # 處理 gemini 速率限制的變數\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite 在文件中設定了此上限\n",
    "    first_request_time = None\n",
    "\n",
    "    # 分類 20 個測試範例（每個類別 5 個）並保存預測\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # 在每個 API 呼叫前檢查和處理速率限制\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # 追加結果資料：\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # 建立 DataFrame 以保存結果資料\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # 提取真實和預測標籤以計算指標\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # 保存結果\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # 將 DataFrame 保存為 CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # 計算準確度\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # 分類報告\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # 繪製混淆矩陣\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`\n",
    "\n",
    "**重要提示：由於 API 速率限制，下一部分運行大約需要 16 分鐘。 **\n",
    "\n",
    "**注意：**一次性執行以下程式碼時，您可能會看到 `429 RESOURCE_EXHAUSTED` 錯誤。這是因為目前的 API 速率限制處理機制無法可靠地取得每個儲存格之間每分鐘剩餘的請求數，Gemini 尚未提供從其伺服器取得此資訊的功能。因此，如果您不想看到此錯誤，可以在一個單元格處理完畢後等待 1 分鐘。但即使出現錯誤也無需擔心，程式碼內部會每 15 秒進行一次重試，直到處理完所有採樣資料。實驗室的設計確保不會達到每日總速率限製配額。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:11<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.46 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.20s/it]\n",
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:07<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:03<00:00,  3.15s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:04<00:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.93 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.84 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [00:59<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:52<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_0.csv\n",
      "Accuracy: 46.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.37      0.55      0.44        20\n",
      "        fear       0.86      0.30      0.44        20\n",
      "         joy       0.48      0.75      0.59        20\n",
      "     sadness       0.42      0.25      0.31        20\n",
      "\n",
      "    accuracy                           0.46        80\n",
      "   macro avg       0.53      0.46      0.45        80\n",
      "weighted avg       0.53      0.46      0.45        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 如果看到 '429 RESOURCE_EXHAUSTED' 錯誤，沒關係，等到資料被處理，它會持續重試直到完成\n",
    "\n",
    "# 使用零樣本提示執行實驗的範例\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: As your own lives in order to complete our amazing life journey successfully, it is there. #bitter\n",
      "Class: anger\n",
      "\n",
      "Text: @jjskeffington @foodbelfast I dread to think!\n",
      "Class: fear\n",
      "\n",
      "Text: @Nick_Offerman I'll be there!! Can't wait for all the #mirth!\n",
      "Class: joy\n",
      "\n",
      "Text: Sister: (Canadian player does something shady.) Jonathan Toews is frowning and he doesn't know why. #WorldCupOfHockey\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:11<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.70 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.18s/it]\n",
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:07<00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.21 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:04<00:00,  3.20s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:03<00:11,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.50 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:03<00:00,  3.18s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.58 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [00:59<00:04,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.80 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:52<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_1.csv\n",
      "Accuracy: 55.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.47      0.80      0.59        20\n",
      "        fear       0.90      0.45      0.60        20\n",
      "         joy       0.57      0.60      0.59        20\n",
      "     sadness       0.47      0.35      0.40        20\n",
      "\n",
      "    accuracy                           0.55        80\n",
      "   macro avg       0.60      0.55      0.54        80\n",
      "weighted avg       0.60      0.55      0.54        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 如果看到 '429 RESOURCE_EXHAUSTED' 錯誤，沒關係，等到資料被處理，它會持續重試直到完成\n",
    "\n",
    "# 使用 1-樣本提示執行實驗的範例\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: Women don't like girls because we resent them for looking so great/we wish we still looked like that  #washed\n",
      "Class: anger\n",
      "\n",
      "Text: Because it was a perfect illusion, but at least now I know what it was. #angry #ladygaga #iscalming#mysoul\n",
      "Class: anger\n",
      "\n",
      "Text: Realizing that holding a grudge for long is immaturity is wisdom\n",
      "Class: anger\n",
      "\n",
      "Text: @JohnKerry can be as indignant as he wants but the world knows Obama will do nothing and Putin will just do what he wants #Aleppo #Syria\n",
      "Class: anger\n",
      "\n",
      "Text: @ArcadianLuthier -- taking out his feelings on Kei unfairly. His lips form a frown as he tries to walk away.\n",
      "Class: anger\n",
      "\n",
      "Text: Ha! @mquirk @joshuahoodbooks Got your book after our 'meeting' at the Starbucks in NOLA. If Josh says it's terrific, I'm all in.\n",
      "Class: fear\n",
      "\n",
      "Text: Not sure that men can handle a woman that's got her crap together. #intimidation #independent\n",
      "Class: fear\n",
      "\n",
      "Text: Everywhere I go, the air I breathe in tastes like home.' - @The_Currys #restless\n",
      "Class: fear\n",
      "\n",
      "Text: Thiza!!! What happens now when you tell him you're pregnant via home test &amp; nurse later tells you it's a false alarm &amp; BaE is too excited🙊\n",
      "Class: fear\n",
      "\n",
      "Text: @pixietangerine @hatersbackoff im so exited!! I am shaking so much 😍😍 and im so pround of Colleen and the fandom! Everyone is amazing 😍\n",
      "Class: fear\n",
      "\n",
      "Text: Getting cable hooked up in new place just in time for @NBCChicagoPD and @NBCChicagoMed premiers is like God smiling down on me. #OneChicago\n",
      "Class: joy\n",
      "\n",
      "Text: @SXMUrbanView @karenhunter @CousinSyl you are so wrong for this!needed levity after that recording\n",
      "Class: joy\n",
      "\n",
      "Text: mirana told me to shut up when i was singing along to glee...\n",
      "Class: joy\n",
      "\n",
      "Text: @govph I would like to know about the source of The President's optimism about running the country. I wonder if he can answer my curiosity.\n",
      "Class: joy\n",
      "\n",
      "Text: @Devilligan It's a beautifully sincere balancing act of grief and hilarity.\n",
      "Class: joy\n",
      "\n",
      "Text: she's always so insensitive whenever i grieve idgi\n",
      "Class: sadness\n",
      "\n",
      "Text: I don't think it's fully sunk in that Val is gone yet\n",
      "Class: sadness\n",
      "\n",
      "Text: these grown ass lil boys yeah i can't take them serious.\n",
      "Class: sadness\n",
      "\n",
      "Text: @greencapt there's something to note in the fact that the mask manufacturer produced her smiling and him frowning.\n",
      "Class: sadness\n",
      "\n",
      "Text: It's interesting the photo of Mono Lisa is crying as well as the whole scene is very depressing #ELE6200\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:11<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:07<00:07,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.26 seconds.\n",
      "Error occurred when generating response, error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Error occurred when generating response, error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:09<00:00,  3.47s/it]\n",
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:09<00:00,  3.47s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:04<00:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 41.79 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  35%|███▌      | 7/20 [00:48<02:15, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 38.283506674s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\\nPlease retry in 38.250932705s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Imagine how sad LA fans are gona be when they get eliminated...Man that's gonna be Nirvana, a religious experience rejoicing in their misery\n",
      "test_text: Imagine how sad LA fans are gona be when they get eliminated...Man that's gonna be Nirvana, a religious experience rejoicing in their misery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:12<00:00,  3.64s/it]\n",
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:12<00:00,  3.64s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 33.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [00:45<00:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.58 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:37<00:00,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_5.csv\n",
      "Accuracy: 58.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.47      0.70      0.56        20\n",
      "        fear       0.75      0.45      0.56        20\n",
      "         joy       0.75      0.75      0.75        20\n",
      "     sadness       0.50      0.45      0.47        20\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.62      0.59      0.59        80\n",
      "weighted avg       0.62      0.59      0.59        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 如果看到 '429 RESOURCE_EXHAUSTED' 錯誤，沒關係，等到資料被處理，它會持續重試直到完成\n",
    "\n",
    "# 使用 5-樣本提示執行實驗的範例\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification.\n",
    "\n",
    "---\n",
    "\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> 練習 6（課後作業）：**](#toc0_)\n",
    "\n",
    "比較並討論零次射擊、一次射擊和五次射擊分類的整體結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "整體表現隨著提供示例數從 0-shot 到 5-shot 穩定上升：整體準確率由 46.25% 提升到 55.00% 再到 58.75%，macro F1 也從 0.45 到 0.54 到 0.59，顯示小樣本示例能有效校正模型決策邊界並提升類別均衡性。\n",
    "\n",
    "類別層面來看，joy 的召回在三種設定都維持高檔（0.75、0.60、0.75），且在 5-shot 時 precision 與 recall 同為 0.75，顯示該類別最易被模型穩定識別；相對地，sadness 的召回最不穩定，雖在 5-shot 有改善但仍落後其他類別，暗示該類別特徵與其他情緒（特別是 anger、joy）的混淆仍明顯。\n",
    "\n",
    "從混淆矩陣觀察，0-shot 時 anger 常被誤判為 joy 或 sadness，而 fear 與 sadness 彼此與 joy 有較多交叉；加入 1-shot 後，anger 的正確預測顯著增加，但 joy 的正確數略降，顯示單一示例偏向強化了對怒的識別模板；進一步到 5-shot，joy 的真陽性回到 15，anger、fear、sadness 的誤分類分佈更平均，總體混淆減少，說明多樣示例有助於校正偏置與邊界模糊區。\n",
    "\n",
    "Overall performance steadily improved as the number of examples provided increased from 0-shot to 5-shot: overall accuracy increased from 46.25% to 55.00% and then to 58.75%, while macro F1 also improved from 0.45 to 0.54 and then to 0.59, demonstrating that smaller sample sizes effectively corrected the model's decision boundaries and improved class balance.\n",
    "\n",
    "At the category level, the recall for \"joy\" remained high across all three settings (0.75, 0.60, 0.75), and both precision and recall were 0.75 at 5-shot, indicating that this category was the most easily and stably identified by the model. Conversely, the recall for \"sadness\" was the least stable; although it improved at 5-shot, it still lagged behind other categories, suggesting that this category's features were still significantly confused with other emotions (especially anger and joy).\n",
    "\n",
    "Observing the confusion matrix, in the 0-shot, anger was often misclassified as joy or sadness, while fear and sadness had more overlap with joy. After adding the 1-shot, the correct prediction of anger increased significantly, but the correct number of joy decreased slightly, indicating that a single example tends to reinforce the recognition template of anger. Further, in the 5-shot, the true positive of joy returned to 15, and the misclassification distribution of anger, fear, and sadness became more even, with overall confusion decreasing, indicating that diverse examples help to correct bias and boundary ambiguity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings.\n",
    "\n",
    "---\n",
    "\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> 練習 7（家庭作業）：**](#toc0_)\n",
    "\n",
    "**案例研究：** 檢查 `results/llm_classification_results` 目錄中的結果文件，找出**隨著樣本數量增加，文本分類效果提升的情況**（預測情緒隨著樣本數量增加而正確），**分類效果沒有提升的情況**（預測情感始終從正確情況變為錯誤）**（情緒預測而下降的**（情緒預測情緒）。為此，你需要使用 pandas 載入結果，並使用其資料框函數處理資料。討論你的發現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 分類效果分析 (Classification Performance Analysis) ===\n",
      "\n",
      "效果提升的案例（0-shot 錯誤 (Wrong) → 1-shot 正確 (Correct)）(Improved cases): 10 個\n",
      "效果未改善的案例（始終錯誤 (Always Wrong)）(No improvement cases): 15 個\n",
      "效果下降的案例（0-shot 正確 (Correct) → 5-shot 錯誤 (Wrong)）(Degraded cases): 12 個\n",
      "\n",
      "--- 效果提升的案例 (Improved Cases - Wrong → Correct) ---\n",
      "文本 (Text)：Might just leave and aggravate bae...\n",
      "  真實 (True)：anger, 0-shot：sadness (錯誤/Wrong), 1-shot：anger (正確/Correct)\n",
      "\n",
      "文本 (Text)：@fluffysoftlouis no no. I insist that you give me ...\n",
      "  真實 (True)：anger, 0-shot：joy (錯誤/Wrong), 1-shot：anger (正確/Correct)\n",
      "\n",
      "文本 (Text)：Everybody talking about 'the first day of fall' bu...\n",
      "  真實 (True)：anger, 0-shot：joy (錯誤/Wrong), 1-shot：anger (正確/Correct)\n",
      "\n",
      "--- 效果未改善的案例（始終錯誤/Always Wrong）(No Improvement Cases) ---\n",
      "文本 (Text)：At school, my classmate is with me at music class ...\n",
      "  真實 (True)：fear, 0-shot：joy (錯誤/Wrong), 1-shot：joy (錯誤/Wrong), 5-shot：anger (錯誤/Wrong)\n",
      "\n",
      "文本 (Text)：@All4 is the android app it designed to be buggy a...\n",
      "  真實 (True)：fear, 0-shot：anger (錯誤/Wrong), 1-shot：anger (錯誤/Wrong), 5-shot：sadness (錯誤/Wrong)\n",
      "\n",
      "文本 (Text)：It really is amazing the money they give to some o...\n",
      "  真實 (True)：fear, 0-shot：joy (錯誤/Wrong), 1-shot：joy (錯誤/Wrong), 5-shot：anger (錯誤/Wrong)\n",
      "\n",
      "--- 效果下降的案例 (Degraded Cases - Correct → Wrong) ---\n",
      "文本 (Text)：@huwellwell One chosen by the CLP members! MP seat...\n",
      "  真實 (True)：anger, 0-shot：anger (正確/Correct), 5-shot：sadness (錯誤/Wrong)\n",
      "\n",
      "文本 (Text)：You're so thirsty for the chance to disagree w/ th...\n",
      "  真實 (True)：anger, 0-shot：anger (正確/Correct), 5-shot：fear (錯誤/Wrong)\n",
      "\n",
      "文本 (Text)：I don't want speak front to him #afraid #intimidat...\n",
      "  真實 (True)：fear, 0-shot：fear (正確/Correct), 5-shot：anger (錯誤/Wrong)\n",
      "\n",
      "=== 整體統計 (Overall Statistics) ===\n",
      "0-shot 準確率 (Accuracy)：46.25%\n",
      "1-shot 準確率 (Accuracy)：55.00%\n",
      "5-shot 準確率 (Accuracy)：58.75%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 讀取所有結果檔案 (Load all results files)\n",
    "results_dir = './results/llm_classification_results'\n",
    "files = sorted([f for f in os.listdir(results_dir) if f.endswith('.csv')])\n",
    "\n",
    "# 合併所有結果 (Merge all results)\n",
    "dfs = {}\n",
    "for file in files:\n",
    "    shot_count = file.split('_')[-1].replace('.csv', '')\n",
    "    df = pd.read_csv(os.path.join(results_dir, file))\n",
    "    dfs[shot_count] = df\n",
    "\n",
    "# 建立比較數據框 (Create comparison DataFrame)\n",
    "comparison = pd.DataFrame()\n",
    "comparison['Index'] = dfs['0'].index\n",
    "comparison['Text'] = dfs['0']['text'].values\n",
    "comparison['True_Emotion'] = dfs['0']['true_emotion'].values\n",
    "comparison['0-shot'] = dfs['0']['predicted_emotion'].values\n",
    "comparison['1-shot'] = dfs['1']['predicted_emotion'].values\n",
    "comparison['5-shot'] = dfs['5']['predicted_emotion'].values\n",
    "\n",
    "# 檢查預測是否正確 (Check if predictions are correct)\n",
    "comparison['0-shot_correct'] = comparison['0-shot'] == comparison['True_Emotion']\n",
    "comparison['1-shot_correct'] = comparison['1-shot'] == comparison['True_Emotion']\n",
    "comparison['5-shot_correct'] = comparison['5-shot'] == comparison['True_Emotion']\n",
    "\n",
    "# 分類案例 (Categorize cases)\n",
    "improved = comparison[(~comparison['0-shot_correct']) & (comparison['1-shot_correct'])]\n",
    "no_improvement = comparison[(~comparison['0-shot_correct']) & (~comparison['1-shot_correct']) & (~comparison['5-shot_correct'])]\n",
    "degraded = comparison[(comparison['0-shot_correct']) & (~comparison['5-shot_correct'])]\n",
    "\n",
    "print(\"=== 分類效果分析 (Classification Performance Analysis) ===\\n\")\n",
    "print(f\"效果提升的案例（0-shot 錯誤 (Wrong) → 1-shot 正確 (Correct)）(Improved cases): {len(improved)} 個\")\n",
    "print(f\"效果未改善的案例（始終錯誤 (Always Wrong)）(No improvement cases): {len(no_improvement)} 個\")\n",
    "print(f\"效果下降的案例（0-shot 正確 (Correct) → 5-shot 錯誤 (Wrong)）(Degraded cases): {len(degraded)} 個\\n\")\n",
    "\n",
    "# 效果提升的案例 (Improved cases)\n",
    "print(\"--- 效果提升的案例 (Improved Cases - Wrong → Correct) ---\")\n",
    "if len(improved) > 0:\n",
    "    for idx, row in improved.head(3).iterrows():\n",
    "        print(f\"文本 (Text)：{row['Text'][:50]}...\")\n",
    "        print(f\"  真實 (True)：{row['True_Emotion']}, 0-shot：{row['0-shot']} (錯誤/Wrong), 1-shot：{row['1-shot']} (正確/Correct)\\n\")\n",
    "\n",
    "# 效果未改善的案例 (No improvement cases)\n",
    "print(\"--- 效果未改善的案例（始終錯誤/Always Wrong）(No Improvement Cases) ---\")\n",
    "if len(no_improvement) > 0:\n",
    "    for idx, row in no_improvement.head(3).iterrows():\n",
    "        print(f\"文本 (Text)：{row['Text'][:50]}...\")\n",
    "        print(f\"  真實 (True)：{row['True_Emotion']}, 0-shot：{row['0-shot']} (錯誤/Wrong), 1-shot：{row['1-shot']} (錯誤/Wrong), 5-shot：{row['5-shot']} (錯誤/Wrong)\\n\")\n",
    "\n",
    "# 效果下降的案例 (Degraded cases)\n",
    "print(\"--- 效果下降的案例 (Degraded Cases - Correct → Wrong) ---\")\n",
    "if len(degraded) > 0:\n",
    "    for idx, row in degraded.head(3).iterrows():\n",
    "        print(f\"文本 (Text)：{row['Text'][:50]}...\")\n",
    "        print(f\"  真實 (True)：{row['True_Emotion']}, 0-shot：{row['0-shot']} (正確/Correct), 5-shot：{row['5-shot']} (錯誤/Wrong)\\n\")\n",
    "\n",
    "# 整體統計 (Overall Statistics)\n",
    "print(\"=== 整體統計 (Overall Statistics) ===\")\n",
    "total = len(comparison)\n",
    "for shot in ['0-shot', '1-shot', '5-shot']:\n",
    "    accuracy = comparison[f'{shot}_correct'].sum() / total * 100\n",
    "    print(f\"{shot} 準確率 (Accuracy)：{accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the model’s data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)\n",
    "\n",
    "### <a id='toc1_5_11_'></a>[**2.7 額外 LLM 相關資料：**](#toc0_)\n",
    "\n",
    "實驗部分到此結束，如果您想進一步探索，這裡還有一些額外的材料：\n",
    "\n",
    "- **如何使用 OpenAI ChatGPT 模型的 API（非免費 API）：** [基礎影片](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [基礎 GitHub 倉庫](https://github.com/gkamradt/langchain-tutorials/blob/mainimmm/Chatm/ [RAG 的基礎影片](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG 的基礎GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **進階主題 - QLoRA（量化低秩適配器）：** QLoRA 是一種用於提高大型語言模型微調效率的方法。它的工作原理是在預訓練模型中添加一個較小的可訓練部分（LoRA），同時保持模型的其餘部分不變。此外，它還使用稱為量化的過程來減小模型的資料量，從而降低模型所需的記憶體。這使得您無需消耗大量運算資源即可微調大型模型，從而更輕鬆地將模型適配到特定任務中。資料：[論文 GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 應用影片](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 應用GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **如何使用 `unsloth` 庫微調和運行本地 LLM：** [unsloth 教程](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google 智能體開發工具包 (ADK) 文件：** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **建立 AI 智能體**使用 LangGraph：** [LangGraph 文件](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
